{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s6Po3ZB1U7-",
        "outputId": "4f362ed5-d755-48ef-f553-c4a224d7b9d5"
      },
      "outputs": [],
      "source": [
        "#!unzip \"/content/drive/MyDrive/SR_DATASET.zip\"\n",
        "#!unzip \"/content/drive/MyDrive/SR_DATASET_SMALLER.zip\"\n",
        "!unzip \"/content/drive/MyDrive/resto_data.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "SgYB4rs11c-9",
        "outputId": "6d895bcc-4e39-409a-e3d6-19ee3268ac16"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "''' paths = {\n",
        "    \"train_x\": \"/content/SR_DATASET/SR_TRAIN/SR_DATA_AUGMENTED\",\n",
        "    \"train_y\":\"/content/SR_DATASET/SR_TRAIN/SR_DATA\",\n",
        "    \"test_x\":\"/content/SR_DATASET/SR_TEST/SR_DATA_AUGMENTED\",\n",
        "    \"test_y\": \"/content/SR_DATASET/SR_TEST/SR_DATA\"\n",
        "} '''\n",
        "\n",
        "''' paths = {\n",
        "    \"train_x\": \"/content/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_AUGMENTED_SMALLER\",\n",
        "    \"train_y\":\"/content/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_SMALLER\",\n",
        "    \"test_x\":\"/content/SR_DATASET_SMALLER/SR_TEST/SR_DATA_AUGMENTED_SMALLER\",\n",
        "    \"test_y\": \"/content/SR_DATASET_SMALLER/SR_TEST/SR_DATA_SMALLER\"\n",
        "}\n",
        " '''\n",
        "paths = {\n",
        "    \"train_x\": \"/content/resto_data/resto_train/resto_augmented\",\n",
        "    \"train_y\": \"/content/resto_data/resto_train/resto\",\n",
        "    \"test_x\": \"/content/resto_data/resto_test/resto_augmented\",\n",
        "    \"test_y\": \"/content/resto_data/resto_test/resto\"\n",
        "}\n",
        "\n",
        "class SuperResolutionDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, paths, batch_size, train=True, size=(256, 256)):\n",
        "        self.paths = paths\n",
        "        self.batch_size = batch_size\n",
        "        self.size = size\n",
        "        self.image_paths_x = self._get_image_paths(paths[\"train_x\"] if train else paths[\"test_x\"])\n",
        "        self.image_paths_y = self._get_image_paths(paths[\"train_y\"] if train else paths[\"test_y\"])\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def _get_image_paths(self, directory):\n",
        "        image_paths = []\n",
        "        for filename in os.listdir(directory):\n",
        "            image_paths.append(os.path.join(directory, filename))\n",
        "        return image_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths_x) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        batch_x = [self.image_paths_x[i] for i in indexes]\n",
        "        batch_y = [self.image_paths_y[i] for i in indexes]\n",
        "        images_x = self._load_images(batch_x)\n",
        "        images_y = self._load_images(batch_y)\n",
        "        images_x = images_x / 255.0\n",
        "        images_y = images_y / 255.0\n",
        "        return images_x, images_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = list(range(len(self.image_paths_x)))\n",
        "        random.shuffle(self.indexes)\n",
        "\n",
        "    def _load_images(self, image_paths):\n",
        "        images = []\n",
        "        for path in image_paths:\n",
        "            image = tf.keras.preprocessing.image.load_img(path, target_size=self.size)\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "            images.append(image)\n",
        "        return np.array(images)\n",
        "\n",
        "high = True\n",
        "batch_size = 4 if high else 1\n",
        "train_data = SuperResolutionDataGenerator(paths, batch_size)\n",
        "test_data = SuperResolutionDataGenerator(paths, batch_size, train=False)\n",
        "\n",
        "def show_example(train_gen):\n",
        "    index = np.random.randint(len(train_gen))\n",
        "    x, y = train_gen.__getitem__(index)\n",
        "    print(x.shape, y.shape, np.min(x), np.max(x), np.min(y), np.max(y))\n",
        "    num_samples = x.shape[0]\n",
        "    x,y = x * 255.0, y * 255.0\n",
        "    sample_indices = np.random.choice(num_samples, size=4, replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        if i < 4:\n",
        "            ax.imshow(x[sample_indices[i]].astype(np.uint8))\n",
        "            ax.set_title(\"Low-res\")\n",
        "        else:\n",
        "            ax.imshow(y[sample_indices[i-4]].astype(np.uint8))\n",
        "            ax.set_title(\"High-res\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_example(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "8xFdbhSuaLiN",
        "outputId": "92260b27-5d7e-4fd8-cfa8-43381a5e2619"
      },
      "outputs": [],
      "source": [
        "show_example(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_GaEN0m1i-9",
        "outputId": "b12e18c1-da63-48a0-bda1-0b598b6da767"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DownBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Submodule of `DownSampleBlock`.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L130)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of input channels.\n",
        "        channel_factor (float): factor by which number of the number of output channels vary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, channel_factor: float, *args, **kwargs) -> None:\n",
        "        super(DownBlock, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.channel_factor = channel_factor\n",
        "\n",
        "        self.average_pool = tf.keras.layers.AveragePooling2D(pool_size=2, strides=2)\n",
        "        self.conv = tf.keras.layers.Conv2D(\n",
        "            int(channels * channel_factor), kernel_size=1, strides=1, padding=\"same\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
        "        return self.conv(self.average_pool(inputs))\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\"channels\": self.channels, \"channel_factor\": self.channel_factor}\n",
        "\n",
        "\n",
        "class DownSampleBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Layer for downsampling feature map for the Multi-scale Residual Block.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L142)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of input channels.\n",
        "        scale_factor (int): number of downsample operations.\n",
        "        channel_factor (float): factor by which number of the number of output channels vary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, channels: int, scale_factor: int, channel_factor: float, *args, **kwargs\n",
        "    ) -> None:\n",
        "        super(DownSampleBlock, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.scale_factor = scale_factor\n",
        "        self.channel_factor = channel_factor\n",
        "\n",
        "        self.layers = []\n",
        "        for _ in range(int(np.log2(scale_factor))):\n",
        "            self.layers.append(DownBlock(channels, channel_factor))\n",
        "            channels = int(channels * channel_factor)\n",
        "\n",
        "    def call(self, x: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"channel_factor\": self.channel_factor,\n",
        "            \"scale_factor\": self.scale_factor,\n",
        "        }\n",
        "\n",
        "class MultiScaleResidualBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Implementation of the Multi-scale Residual Block.\n",
        "\n",
        "    The Multi-scale Residual Block mechanism of collecting multiscale spatial information.\n",
        "    This block forms the core component of the recursive residual design of MIRNet-v2.\n",
        "    The key advantages of MRB are:\n",
        "\n",
        "    - It is capable of generating a spatially-precise output by maintaining high-resolution representations, while receiving rich contextual information from low-resolutions.\n",
        "\n",
        "    - It allows contextualized-information transfer from the low-resolution streams to consolidate the high-resolution features.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L189)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of channels in the feature map.\n",
        "        channel_factor (float): factor by which number of the number of output channels vary.\n",
        "        groups (int): number of groups in which the input is split along the\n",
        "            channel axis in the convolution layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, channels: int, channel_factor: float, groups: int, *args, **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.channel_factor = channel_factor\n",
        "        self.groups = groups\n",
        "\n",
        "        # Residual Context Blocks\n",
        "        self.rcb_top = ResidualContextBlock(\n",
        "            int(channels * channel_factor**0), groups=groups\n",
        "        )\n",
        "        self.rcb_middle = ResidualContextBlock(\n",
        "            int(channels * channel_factor**1), groups=groups\n",
        "        )\n",
        "        self.rcb_bottom = ResidualContextBlock(\n",
        "            int(channels * channel_factor**2), groups=groups\n",
        "        )\n",
        "\n",
        "        # Downsample Blocks\n",
        "        self.down_2 = DownSampleBlock(\n",
        "            channels=int((channel_factor**0) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.down_4_1 = DownSampleBlock(\n",
        "            channels=int((channel_factor**0) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.down_4_2 = DownSampleBlock(\n",
        "            channels=int((channel_factor**1) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "\n",
        "        # UpSample Blocks\n",
        "        self.up21_1 = UpSampleBlock(\n",
        "            channels=int((channel_factor**1) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.up21_2 = UpSampleBlock(\n",
        "            channels=int((channel_factor**1) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.up32_1 = UpSampleBlock(\n",
        "            channels=int((channel_factor**2) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "        self.up32_2 = UpSampleBlock(\n",
        "            channels=int((channel_factor**2) * channels),\n",
        "            scale_factor=2,\n",
        "            channel_factor=channel_factor,\n",
        "        )\n",
        "\n",
        "        # SKFF Blocks\n",
        "        self.skff_top = SelectiveKernelFeatureFusion(\n",
        "            channels=int(channels * channel_factor**0)\n",
        "        )\n",
        "        self.skff_middle = SelectiveKernelFeatureFusion(\n",
        "            channels=int(channels * channel_factor**1)\n",
        "        )\n",
        "\n",
        "        # Convolution\n",
        "        self.conv_out = tf.keras.layers.Conv2D(channels, kernel_size=1, padding=\"same\")\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
        "        x_top = inputs\n",
        "        x_middle = self.down_2(x_top)\n",
        "        x_bottom = self.down_4_2(self.down_4_1(x_top))\n",
        "\n",
        "        x_top = self.rcb_top(x_top)\n",
        "        x_middle = self.rcb_middle(x_middle)\n",
        "        x_bottom = self.rcb_bottom(x_bottom)\n",
        "\n",
        "        x_middle = self.skff_middle([x_middle, self.up32_1(x_bottom)])\n",
        "        x_top = self.skff_top([x_top, self.up21_1(x_middle)])\n",
        "\n",
        "        x_top = self.rcb_top(x_top)\n",
        "        x_middle = self.rcb_middle(x_middle)\n",
        "        x_bottom = self.rcb_bottom(x_bottom)\n",
        "\n",
        "        x_middle = self.skff_middle([x_middle, self.up32_2(x_bottom)])\n",
        "        x_top = self.skff_top([x_top, self.up21_2(x_middle)])\n",
        "\n",
        "        output = self.conv_out(x_top)\n",
        "        output = output + inputs\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"channel_factor\": self.channel_factor,\n",
        "            \"groups\": self.groups,\n",
        "        }\n",
        "\n",
        "\n",
        "class ContextBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Submodule of the Residual Contextual Block.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L57)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of channels in the feature map.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "\n",
        "        self.mask_conv = tf.keras.layers.Conv2D(1, kernel_size=1, padding=\"same\")\n",
        "\n",
        "        self.channel_add_conv_1 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "        self.channel_add_conv_2 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=1)\n",
        "        self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    def modeling(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        _, height, width, channels = [\n",
        "            tf.shape(inputs)[_shape_idx] if _shape is None else _shape\n",
        "            for _shape_idx, _shape in enumerate(inputs.shape.as_list())\n",
        "        ]\n",
        "        reshaped_inputs = tf.expand_dims(\n",
        "            tf.reshape(inputs, (-1, channels, height * width)), axis=1\n",
        "        )\n",
        "\n",
        "        context_mask = self.mask_conv(inputs)\n",
        "        context_mask = tf.reshape(context_mask, (-1, height * width, 1))\n",
        "        context_mask = self.softmax(context_mask)\n",
        "        context_mask = tf.expand_dims(context_mask, axis=1)\n",
        "\n",
        "        context = tf.reshape(\n",
        "            tf.matmul(reshaped_inputs, context_mask), (-1, 1, 1, channels)\n",
        "        )\n",
        "        return context\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
        "        context = self.modeling(inputs)\n",
        "        channel_add_term = self.channel_add_conv_1(context)\n",
        "        channel_add_term = self.leaky_relu(channel_add_term)\n",
        "        channel_add_term = self.channel_add_conv_2(channel_add_term)\n",
        "        return inputs + channel_add_term\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\"channels\": self.channels}\n",
        "\n",
        "\n",
        "class ResidualContextBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Implementation of the Residual Contextual Block.\n",
        "\n",
        "    The Residual Contextual Block is used to extract features in the convolutional\n",
        "    streams and suppress less useful features. The overall process of RCB is\n",
        "    summarized as:\n",
        "\n",
        "    $$F_{RCB} = F_{a} + W(CM(F_{b}))$$\n",
        "\n",
        "    where...\n",
        "\n",
        "    - $F_{a}$ are the input feature maps.\n",
        "\n",
        "    - $F_{b}$ represents feature maps that are obtained by applying two 3x3 group\n",
        "        convolution layers to the input features.\n",
        "\n",
        "    - $CM$ respresents a **contextual modules**.\n",
        "\n",
        "    - $W$ denotes the last convolutional layer with filter size $1 \\times 1$.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L105)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of channels in the feature map.\n",
        "        groups (int): number of groups in which the input is split along the\n",
        "            channel axis in the convolution layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, groups: int, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.groups = groups\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=3, padding=\"same\", groups=groups\n",
        "        )\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(\n",
        "            channels, kernel_size=3, padding=\"same\", groups=groups\n",
        "        )\n",
        "        self.leaky_relu = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "        self.context_block = ContextBlock(channels=channels)\n",
        "\n",
        "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.context_block(x)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = x + inputs\n",
        "        return x\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\"channels\": self.channels, \"groups\": self.groups}\n",
        "\n",
        "\n",
        "class SelectiveKernelFeatureFusion(tf.keras.layers.Layer):\n",
        "    \"\"\"Implementation of the Selective Kernel Feature Fusion Layer.\n",
        "\n",
        "    This layer adaptively adjusts the input receptive fields by using multi-scale\n",
        "    feature generation (in the same layer) followed by feature aggregation and\n",
        "    selection. This is done using two distinct operations:\n",
        "\n",
        "    - **Fuse Operation:** The fuse operator generates global feature descriptors by\n",
        "        combining the information from multiresolution streams.\n",
        "    - **Select Operation:** The select operator uses the feature descriptors\n",
        "        generated by the fuse operator to recalibrate the feature maps\n",
        "        (of different streams) followed by their aggregation.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Selective Kernel Networks](https://arxiv.org/abs/1903.06586)\n",
        "    2. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    3. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L17)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of channels in the feature map.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.hidden_channels = max(int(self.channels / 8), 4)\n",
        "        self.average_pooling = tf.keras.layers.GlobalAveragePooling2D(keepdims=True)\n",
        "\n",
        "        self.conv_channel_downscale = tf.keras.layers.Conv2D(\n",
        "            self.hidden_channels, kernel_size=1, padding=\"same\"\n",
        "        )\n",
        "        self.conv_attention_1 = tf.keras.layers.Conv2D(\n",
        "            self.channels, kernel_size=1, strides=1, padding=\"same\"\n",
        "        )\n",
        "        self.conv_attention_2 = tf.keras.layers.Conv2D(\n",
        "            self.channels, kernel_size=1, strides=1, padding=\"same\"\n",
        "        )\n",
        "        self.softmax = tf.keras.layers.Softmax(axis=-1)\n",
        "\n",
        "    def call(\n",
        "        self, inputs: Tuple[tf.Tensor], training: Optional[bool] = None\n",
        "    ) -> tf.Tensor:\n",
        "        # Fuse operation\n",
        "        combined_input_features = inputs[0] + inputs[1]\n",
        "        channel_wise_statistics = self.average_pooling(combined_input_features)\n",
        "        downscaled_channel_wise_statistics = self.conv_channel_downscale(\n",
        "            channel_wise_statistics\n",
        "        )\n",
        "        attention_vector_1 = self.softmax(\n",
        "            self.conv_attention_1(downscaled_channel_wise_statistics)\n",
        "        )\n",
        "        attention_vector_2 = self.softmax(\n",
        "            self.conv_attention_2(downscaled_channel_wise_statistics)\n",
        "        )\n",
        "\n",
        "        # Select operation\n",
        "        selected_features = (\n",
        "            inputs[0] * attention_vector_1 + inputs[1] * attention_vector_2\n",
        "        )\n",
        "        return selected_features\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\"channels\": self.channels}\n",
        "\n",
        "\n",
        "class UpBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Submodule of `UpSampleBlock`.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L158)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of input channels.\n",
        "        channel_factor (float): factor by which number of the number of output channels vary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, channel_factor: float, *args, **kwargs) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.channel_factor = channel_factor\n",
        "\n",
        "        self.conv = tf.keras.layers.Conv2D(\n",
        "            int(channels // channel_factor), kernel_size=1, strides=1, padding=\"same\"\n",
        "        )\n",
        "        self.upsample = tf.keras.layers.UpSampling2D(size=2, interpolation=\"bilinear\")\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
        "        return self.upsample(self.conv(inputs))\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\"channels\": self.channels, \"channel_factor\": self.channel_factor}\n",
        "\n",
        "\n",
        "class UpSampleBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Layer for upsampling feature map for the Multi-scale Residual Block.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L170)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of input channels.\n",
        "        scale_factor (int): number of downsample operations.\n",
        "        channel_factor (float): factor by which number of the number of output channels vary.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, channels: int, scale_factor: int, channel_factor: float, *args, **kwargs\n",
        "    ) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.scale_factor = scale_factor\n",
        "        self.channel_factor = channel_factor\n",
        "\n",
        "        self.layers = []\n",
        "        for _ in range(int(np.log2(scale_factor))):\n",
        "            self.layers.append(UpBlock(channels, channel_factor))\n",
        "            channels = int(channels // channel_factor)\n",
        "\n",
        "    def call(self, x, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"scale_factor\": self.scale_factor,\n",
        "            \"channel_factor\": self.channel_factor,\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RecursiveResidualGroup(tf.keras.layers.Layer):\n",
        "    \"\"\"Implementation of the Recursive Residual Group.\n",
        "\n",
        "    The Recursive Residual Group forms the basic building block on MirNetV2.\n",
        "    It progressively breaks down the input signal in order to simplify the overall\n",
        "    learning process, and allows the construction of very deep networks.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L242)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of channels in the feature map.\n",
        "        num_mrb_blocks (int): number of multi-scale residual blocks.\n",
        "        channel_factor (float): factor by which number of the number of output channels vary.\n",
        "        groups (int): number of groups in which the input is split along the\n",
        "            channel axis in the convolution layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: int,\n",
        "        num_mrb_blocks: int,\n",
        "        channel_factor: float,\n",
        "        groups: int,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.num_mrb_blocks = num_mrb_blocks\n",
        "        self.channel_factor = channel_factor\n",
        "        self.groups = groups\n",
        "\n",
        "        self.layers = [\n",
        "            MultiScaleResidualBlock(channels, channel_factor, groups)\n",
        "            for _ in range(num_mrb_blocks)\n",
        "        ]\n",
        "        self.layers.append(\n",
        "            tf.keras.layers.Conv2D(channels, kernel_size=3, strides=1, padding=\"same\")\n",
        "        )\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
        "        residual = inputs\n",
        "        for layer in self.layers:\n",
        "            residual = layer(residual)\n",
        "        residual = residual + inputs\n",
        "        return residual\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"num_mrb_blocks\": self.num_mrb_blocks,\n",
        "            \"channel_factor\": self.channel_factor,\n",
        "            \"groups\": self.groups,\n",
        "        }\n",
        "\n",
        "\n",
        "class MirNetv2(tf.keras.Model):\n",
        "    \"\"\"Implementation of the MirNetv2 model.\n",
        "\n",
        "    MirNetv2 is a fully convolutional architecture that learns enriched feature\n",
        "    representations for image restoration and enhancement. It is based on a\n",
        "    **recursive residual design** with the **multi-scale residual block** or **MRB**\n",
        "    at its core. The main branch of the MRB is dedicated to maintaining spatially-precise\n",
        "    high-resolution representations through the entire network and the complimentary set\n",
        "    of parallel branches provide better contextualized features.\n",
        "\n",
        "    Reference:\n",
        "\n",
        "    1. [Learning Enriched Features for Fast Image Restoration and Enhancement](https://www.waqaszamir.com/publication/zamir-2022-mirnetv2/zamir-2022-mirnetv2.pdf)\n",
        "    2. [Official PyTorch implementation of MirNetv2](https://github.com/swz30/MIRNetv2/blob/main/basicsr/models/archs/mirnet_v2_arch.py#L242)\n",
        "\n",
        "    Args:\n",
        "        channels (int): number of channels in the feature map.\n",
        "        channel_factor (float): factor by which number of the number of output channels vary.\n",
        "        num_mrb_blocks (int): number of multi-scale residual blocks.\n",
        "        add_residual_connection (bool): add a residual connection between the inputs and the\n",
        "            outputs or not.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels: int,\n",
        "        channel_factor: float,\n",
        "        num_mrb_blocks: int,\n",
        "        add_residual_connection: bool,\n",
        "        *args,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.channels = channels\n",
        "        self.channel_factor = channel_factor\n",
        "        self.num_mrb_blocks = num_mrb_blocks\n",
        "        self.add_residual_connection = add_residual_connection\n",
        "\n",
        "        self.conv_in = tf.keras.layers.Conv2D(channels, kernel_size=3, padding=\"same\")\n",
        "\n",
        "        self.rrg_block_1 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=1\n",
        "        )\n",
        "        self.rrg_block_2 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=2\n",
        "        )\n",
        "        self.rrg_block_3 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=4\n",
        "        )\n",
        "        self.rrg_block_4 = RecursiveResidualGroup(\n",
        "            channels, num_mrb_blocks, channel_factor, groups=4\n",
        "        )\n",
        "\n",
        "        self.conv_out = tf.keras.layers.Conv2D(3, kernel_size=3, padding=\"same\")\n",
        "\n",
        "    def call(self, inputs: tf.Tensor, training=None, mask=None) -> tf.Tensor:\n",
        "        shallow_features = self.conv_in(inputs)\n",
        "        deep_features = self.rrg_block_1(shallow_features)\n",
        "        deep_features = self.rrg_block_2(deep_features)\n",
        "        deep_features = self.rrg_block_3(deep_features)\n",
        "        deep_features = self.rrg_block_4(deep_features)\n",
        "        output = self.conv_out(deep_features)\n",
        "        output = output + inputs if self.add_residual_connection else output\n",
        "        return output\n",
        "\n",
        "    def save(self, filepath: str, *args, **kwargs) -> None:\n",
        "        input_tensor = tf.keras.Input(shape=[None, None, 3])\n",
        "        saved_model = tf.keras.Model(\n",
        "            inputs=input_tensor, outputs=self.call(input_tensor)\n",
        "        )\n",
        "        saved_model.save(filepath, *args, **kwargs)\n",
        "\n",
        "    def get_config(self) -> Dict:\n",
        "        return {\n",
        "            \"channels\": self.channels,\n",
        "            \"num_mrb_blocks\": self.num_mrb_blocks,\n",
        "            \"channel_factor\": self.channel_factor,\n",
        "            \"add_residual_connection\": self.add_residual_connection,\n",
        "        }\n",
        "\n",
        "\n",
        "model = MirNetv2(\n",
        "    channels=64,\n",
        "    channel_factor=1.5,\n",
        "    num_mrb_blocks=1,\n",
        "    add_residual_connection=False,\n",
        ")\n",
        "model.build([4,256,256,3])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jQ7o5S-1lgz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import optimizer\n",
        "from PIL import Image\n",
        "from keras.callbacks import *\n",
        "from keras import backend as K\n",
        "import scipy.misc\n",
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "def save_eval_results(eval_results, filename):\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(model.metrics_names)\n",
        "        writer.writerow(eval_results)\n",
        "\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    if epoch > 0 and epoch % 2 == 0:\n",
        "        lr *= 0.1\n",
        "        print(\"Learning rate updated to:\", lr)\n",
        "    return lr\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_model', save_best_only=True, monitor=\"loss\"),\n",
        "    EarlyStopping(monitor='loss', patience=2),\n",
        "    TensorBoard(log_dir='logs'),\n",
        "   # ReduceLROnPlateau(monitor='loss', patience=1, factor=0.1),\n",
        "    LearningRateScheduler(lr_scheduler)\n",
        "]\n",
        "\n",
        "def psnr(y_true,y_pred):\n",
        "    return tf.image.psnr(y_true,y_pred,1.0)\n",
        "\n",
        "def ssim(y_true,y_pred):\n",
        "    return tf.image.ssim(y_true,y_pred,1.0)\n",
        "\n",
        "@tf.function\n",
        "def update_fn(p, grad, exp_avg, lr, wd, beta1, beta2):\n",
        "    # stepweight decay\n",
        "\n",
        "    p.assign(p * (1 - lr * wd))\n",
        "\n",
        "    # weight update\n",
        "\n",
        "    update = tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0]*exp_avg + (1 - tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0])*grad\n",
        "    p.assign_add(tf.sign(update) * -lr)\n",
        "\n",
        "    # decay the momentum running average coefficient\n",
        "\n",
        "    exp_avg.assign(exp_avg * beta2 + grad * (1 - beta2))\n",
        "\n",
        "\n",
        "def lerp(start, end, weight):\n",
        "    return start + weight * (end - start)\n",
        "\n",
        "\n",
        "def sparse_lerp(start, end, weight):\n",
        "    # Mathematically equivalent, but you can't subtract a dense Tensor from sparse\n",
        "    # IndexedSlices, so we have to flip it around.\n",
        "    return start + weight * -(start - end)\n",
        "\n",
        "class Lion(optimizer.Optimizer):\n",
        "    \"\"\"Optimizer that implements the Lion algorithm.\n",
        "    Lion was published in the paper \"Symbolic Discovery of Optimization Algorithms\"\n",
        "    which is available at https://arxiv.org/abs/2302.06675\n",
        "    Args:\n",
        "      learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n",
        "        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n",
        "        that takes no arguments and returns the actual value to use. The\n",
        "        learning rate. Defaults to 1e-4.\n",
        "      beta_1: A float value or a constant float tensor, or a callable\n",
        "        that takes no arguments and returns the actual value to use. Factor\n",
        "         used to interpolate the current gradient and the momentum. Defaults to 0.9.\n",
        "      beta_2: A float value or a constant float tensor, or a callable\n",
        "        that takes no arguments and returns the actual value to use. The\n",
        "        exponential decay rate for the momentum. Defaults to 0.99.\n",
        "    Notes:\n",
        "    The sparse implementation of this algorithm (used when the gradient is an\n",
        "    IndexedSlices object, typically because of `tf.gather` or an embedding\n",
        "    lookup in the forward pass) does apply momentum to variable slices even if\n",
        "    they were not used in the forward pass (meaning they have a gradient equal\n",
        "    to zero). Momentum decay (beta2) is also applied to the entire momentum\n",
        "    accumulator. This means that the sparse behavior is equivalent to the dense\n",
        "    behavior (in contrast to some momentum implementations which ignore momentum\n",
        "    unless a variable slice was actually used).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        learning_rate=1e-4,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.99,\n",
        "        weight_decay=None,\n",
        "        clipnorm=None,\n",
        "        clipvalue=None,\n",
        "        global_clipnorm=None,\n",
        "        jit_compile=True,\n",
        "        name=\"Lion\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            name=name,\n",
        "            weight_decay=weight_decay,\n",
        "            clipnorm=clipnorm,\n",
        "            clipvalue=clipvalue,\n",
        "            global_clipnorm=global_clipnorm,\n",
        "            jit_compile=jit_compile,\n",
        "            **kwargs\n",
        "        )\n",
        "        self._learning_rate = self._build_learning_rate(learning_rate)\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    def build(self, var_list):\n",
        "        \"\"\"Initialize optimizer variables.\n",
        "          var_list: list of model variables to build Lion variables on.\n",
        "        \"\"\"\n",
        "        super().build(var_list)\n",
        "        if hasattr(self, \"_built\") and self._built:\n",
        "            return\n",
        "        self._built = True\n",
        "        self._emas = []\n",
        "        for var in var_list:\n",
        "            self._emas.append(\n",
        "                self.add_variable_from_reference(\n",
        "                    model_variable=var, variable_name=\"ema\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def update_step(self, gradient, variable):\n",
        "        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n",
        "        lr = tf.cast(self.learning_rate, variable.dtype)\n",
        "        beta_1 = tf.constant(self.beta_1, shape=(1,))\n",
        "        beta_2 = tf.constant(self.beta_2, shape=(1,))\n",
        "\n",
        "        var_key = self._var_key(variable)\n",
        "        ema = self._emas[self._index_dict[var_key]]\n",
        "\n",
        "        if isinstance(gradient, tf.IndexedSlices):\n",
        "            # Sparse gradients.\n",
        "            lerp_fn = sparse_lerp\n",
        "        else:\n",
        "            # Dense gradients.\n",
        "            lerp_fn = lerp\n",
        "\n",
        "        update = lerp_fn(ema, gradient, 1 - beta_1)\n",
        "        update = tf.sign(update)\n",
        "        variable.assign_sub(update * lr)\n",
        "\n",
        "        ema.assign(lerp_fn(ema, gradient, 1 - beta_2))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "\n",
        "        config.update(\n",
        "            {\n",
        "                \"learning_rate\": self._serialize_hyperparameter(\n",
        "                    self._learning_rate\n",
        "                ),\n",
        "                \"beta_1\": self.beta_1,\n",
        "                \"beta_2\": self.beta_2,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "def fast_check(generator, amount: int = 20):\n",
        "    count = 0\n",
        "    for item in generator:\n",
        "        yield item\n",
        "        count += 1\n",
        "        if count == amount:\n",
        "            break\n",
        "\n",
        "def SSIMLoss(y_true, y_pred):\n",
        "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
        "\n",
        "mae = tf.keras.losses.MeanAbsoluteError()\n",
        "epochs = 5\n",
        "count = 0\n",
        "save = True\n",
        "optimizer = Lion(1e-5)\n",
        "model.compile(optimizer=optimizer, loss=SSIMLoss, metrics=[psnr, ssim])\n",
        "for i in range(epochs):\n",
        "  count += 1\n",
        "  model.fit(train_data, epochs=1)\n",
        "  small_gen = fast_check(test_data)\n",
        "  model.evaluate(small_gen)\n",
        "  if save:\n",
        "    model.save(f\"model_epoch_{str(count)}\", save_format=\"tf\")\n",
        "model.save(\"model\", save_format=\"tf\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKYfSGaW_ucE"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "#shutil.copy(\"model.h5\", \"/content/drive/MyDrive/model_resto.h5\")\n",
        "shutil.move(\"model_epoch_2\", \"/content/drive/MyDrive/model_epoch_2\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7s6Po3ZB1U7-",
    "outputId": "b9493fb8-0af1-4476-dbe6-a7af09720077"
   },
   "outputs": [],
   "source": [
    "# get datasets\n",
    "# different kinds of qualities and sizes\n",
    "\n",
    "#!unzip \"/content/drive/MyDrive/SR_DATASET_SMALLER.zip\" -d \"/content/SR_DATASET_SMALLER_150_X_150\"\n",
    "#!unzip \"/content/drive/MyDrive/SR_DATASET_SMALLER_HYSTO.zip\" -d \"/content/SR_DATASET_SMALLER_HYSTO\"\n",
    "#!unzip \"/content/drive/MyDrive/SR_DATASET_SMALLER_WQ\" -d \"/content/SR_DATASET_SMALLER_WQ\"\n",
    "!unzip \"/content/drive/MyDrive/SR_DATASET_SMALLER_HYSTO_128.zip\" -d \"/content/SR_DATASET_SMALLER_128_X_128\"\n",
    "#!unzip \"/content/drive/MyDrive/restoration_new_12.07.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "SgYB4rs11c-9",
    "outputId": "991442fd-adcc-4603-9a6b-8b43b41c70a2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# paths to different daatasets\n",
    "# original dataset was too big, sr_data_smaller is a subset of it, still including ~25k train images\n",
    "# sr_data_smaller_augmented are the images with worsened quality \n",
    "paths = {\n",
    "    \"train_x\": \"/content/SR_DATASET_SMALLER_150_X_150/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_SMALLER_AUGMENTED\",\n",
    "    \"train_y\": \"/content/SR_DATASET_SMALLER_150_X_150/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_SMALLER\",\n",
    "    \"test_x\": \"/content/SR_DATASET_SMALLER_150_X_150/SR_DATASET_SMALLER/SR_TEST/SR_DATA_SMALLER_AUGMENTED\",\n",
    "    \"test_y\": \"/content/SR_DATASET_SMALLER_150_X_150/SR_DATASET_SMALLER/SR_TEST/SR_DATA_SMALLER\",\n",
    "}\n",
    "\n",
    "paths_128 = {\n",
    "    \"train_x\": \"/content/SR_DATASET_SMALLER_128_X_128/SR_DATASET_SMALLER_HYSTO/SR_TRAIN/SR_DATA_SMALLER_AUGMENTED\",\n",
    "    \"train_y\": \"/content/SR_DATASET_SMALLER_128_X_128/SR_DATASET_SMALLER_HYSTO/SR_TRAIN/SR_DATA_SMALLER\",\n",
    "    \"test_x\": \"/content/SR_DATASET_SMALLER_128_X_128/SR_DATASET_SMALLER_HYSTO/SR_TEST/SR_DATA_SMALLER_AUGMENTED\",\n",
    "    \"test_y\": \"/content/SR_DATASET_SMALLER_128_X_128/SR_DATASET_SMALLER_HYSTO/SR_TEST/SR_DATA_SMALLER\",\n",
    "}\n",
    "\n",
    "paths_hysto = {\n",
    "    \"train_x\": \"/content/SR_DATASET_SMALLER_HYSTO_128/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_AUGMENTED_SMALLER\",\n",
    "    \"train_y\": \"/content/SR_DATASET_SMALLER_HYSTO_128/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_SMALLER\",\n",
    "    \"test_x\": \"/content/SR_DATASET_SMALLER_HYSTO_128/SR_DATASET_SMALLER/SR_TEST/SR_DATA_AUGMENTED_SMALLER\",\n",
    "    \"test_y\": \"/content/SR_DATASET_SMALLER_HYSTO_128/SR_DATASET_SMALLER/SR_TEST/SR_DATA_SMALLER\",\n",
    "}\n",
    "\n",
    "# same dataset but further worsened quality\n",
    "paths_wq = {\n",
    "    \"train_x\": \"/content/SR_DATASET_SMALLER_WQ/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_SMALLER_AUGMENTED\",\n",
    "    \"train_y\": \"/content/SR_DATASET_SMALLER_WQ/SR_DATASET_SMALLER/SR_TRAIN/SR_DATA_SMALLER\",\n",
    "    \"test_x\": \"/content/SR_DATASET_SMALLER_WQ/SR_DATASET_SMALLER/SR_TEST/SR_DATA_SMALLER_AUGMENTED\",\n",
    "    \"test_y\": \"/content/SR_DATASET_SMALLER_WQ/SR_DATASET_SMALLER/SR_TEST/SR_DATA_SMALLER\",\n",
    "}\n",
    "\n",
    "new_paths_128 = {\n",
    "    \"train_x\": \"/content/restoration_new_12.07/train/128x128_wq_resto\",\n",
    "    \"train_y\": \"/content/restoration_new_12.07/train/128x128\",\n",
    "    \"test_x\": \"/content/restoration_new_12.07/test/128x128_wq_resto\",\n",
    "    \"test_y\": \"/content/restoration_new_12.07/test/128x128\",\n",
    "}\n",
    "\n",
    "# generator for the restoration task\n",
    "class RestorationGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, paths, batch_size, train=True, size=(256, 256)):\n",
    "        self.paths = paths\n",
    "        self.batch_size = batch_size\n",
    "        self.size = size\n",
    "        self.image_paths_x = self._get_image_paths(\n",
    "            paths[\"train_x\"] if train else paths[\"test_x\"]\n",
    "        )\n",
    "        self.image_paths_y = self._get_image_paths(\n",
    "            paths[\"train_y\"] if train else paths[\"test_y\"]\n",
    "        )\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def _get_image_paths(self, directory):\n",
    "        image_paths = []\n",
    "        for filename in os.listdir(directory):\n",
    "            image_paths.append(os.path.join(directory, filename))\n",
    "        return image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths_x) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        batch_x = [self.image_paths_x[i] for i in indexes]\n",
    "        batch_y = [self.image_paths_y[i] for i in indexes]\n",
    "        images_x = self._load_images(batch_x)\n",
    "        images_y = self._load_images(batch_y)\n",
    "        images_x = images_x / 255.0\n",
    "        images_y = images_y / 255.0\n",
    "        return images_x, images_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = list(range(len(self.image_paths_x)))\n",
    "        random.shuffle(self.indexes)\n",
    "\n",
    "    def _load_images(self, image_paths):\n",
    "        images = []\n",
    "        for path in image_paths:\n",
    "            image = tf.keras.preprocessing.image.load_img(\n",
    "                path, target_size=self.size, interpolation=\"bicubic\"\n",
    "            )\n",
    "            image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "            images.append(image)\n",
    "        return np.array(images)\n",
    "\n",
    "\n",
    "high = True # depends on image size\n",
    "batch_size = 64 if high else 8\n",
    "train_data = RestorationGenerator(paths_128, batch_size, size=(128, 128))\n",
    "test_data = RestorationGenerator(paths_128, batch_size, train=False, size=(128, 128))\n",
    "\n",
    "# show example images and further information\n",
    "def show_example(train_gen):\n",
    "    index = np.random.randint(len(train_gen))\n",
    "    x, y = train_gen.__getitem__(index)\n",
    "    print(x.shape, y.shape, np.min(x), np.max(x), np.min(y), np.max(y))\n",
    "    num_samples = x.shape[0]\n",
    "    x, y = x * 255.0, y * 255.0\n",
    "    sample_indices = np.random.choice(num_samples, size=4, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < 4:\n",
    "            ax.imshow(x[sample_indices[i]].astype(np.uint8))\n",
    "            ax.set_title(\"Low-res\")\n",
    "        else:\n",
    "            ax.imshow(y[sample_indices[i - 4]].astype(np.uint8))\n",
    "            ax.set_title(\"High-res\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_example(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "8xFdbhSuaLiN",
    "outputId": "ffe0c722-d59b-4d96-e5df-c1d5acd6f133"
   },
   "outputs": [],
   "source": [
    "show_example(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_GaEN0m1i-9",
    "outputId": "4d031bab-215b-4360-9036-e90b335afdff"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Type\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "NAFBLOCK = \"nafblock\"\n",
    "PLAIN = \"plain\"\n",
    "BASELINE = \"baseline\"\n",
    "\n",
    "\n",
    "class SimpleGate(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Simple Gate\n",
    "    It splits the input of size (b,h,w,c) into tensors of size (b,h,w,c//factor) and returns their Hadamard product\n",
    "    Parameters:\n",
    "        factor: the amount by which the channels are scaled down\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, factor: Optional[int] = 2, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor = factor\n",
    "\n",
    "    def call(self, x: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        return tf.reduce_prod(\n",
    "            tf.concat(tf.split(x, num_or_size_splits=self.factor, axis=-2), axis=-1),\n",
    "            axis=-1,\n",
    "        )\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Add factor to the config\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"factor\": self.factor})\n",
    "        return config\n",
    "\n",
    "\n",
    "class ChannelAttention(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Channel Attention layer\n",
    "\n",
    "    Parameters:\n",
    "        channels: number of channels in input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.conv1 = keras.layers.Conv2D(\n",
    "            filters=channels // 2, kernel_size=1, activation=keras.activations.relu\n",
    "        )\n",
    "        self.conv2 = keras.layers.Conv2D(\n",
    "            filters=channels, kernel_size=1, activation=keras.activations.sigmoid\n",
    "        )\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
    "        average_pooling = self.avg_pool(inputs)\n",
    "        feature_descriptor = tf.reshape(\n",
    "            average_pooling, shape=(-1, 1, 1, self.channels)\n",
    "        )\n",
    "        x = self.conv1(feature_descriptor)\n",
    "        return inputs * self.conv2(x)\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Add channels to the config\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"channels\": self.channels})\n",
    "        return config\n",
    "\n",
    "\n",
    "class SimplifiedChannelAttention(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Simplified Channel Attention layer\n",
    "    It is a modification of channel attention without any non-linear activations.\n",
    "    Parameters:\n",
    "        channels: number of channels in input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.avg_pool = keras.layers.GlobalAveragePooling2D()\n",
    "        self.conv = keras.layers.Conv2D(filters=channels, kernel_size=1)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
    "        average_pooling = self.avg_pool(inputs)\n",
    "        feature_descriptor = tf.reshape(\n",
    "            average_pooling, shape=(-1, 1, 1, self.channels)\n",
    "        )\n",
    "        features = self.conv(feature_descriptor)\n",
    "        return inputs * features\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Add channels to the config\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"channels\": self.channels})\n",
    "        return config\n",
    "\n",
    "\n",
    "class NAFBlock(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    NAFBlock (Nonlinear Activation Free Block)\n",
    "\n",
    "    Parameters:\n",
    "        input_channels: number of channels in the input (as NAFBlock retains the input size in the output)\n",
    "        factor: factor by which the channels must be increased before being reduced by simple gate.\n",
    "            (Higher factor denotes higher order polynomial in multiplication. Default factor is 2)\n",
    "        drop_out_rate: dropout rate\n",
    "        balanced_skip_connection: adds additional trainable parameters to the skip connections.\n",
    "            The parameter denotes how much importance should be given to the sub block in the skip connection.\n",
    "        mode: NAFBlock has 3 mode.\n",
    "            'plain' mode uses the PlainBlock.\n",
    "                It is derived from the restormer block, keeping the most common components\n",
    "            'baseline' mode used the BaselineBlock\n",
    "                It is derived by adding layer normalization, channel attention to PlainBlock.\n",
    "                It also replaces ReLU activation with GeLU in PlainBlock.\n",
    "            'nafblock' mode uses the NAFBlock\n",
    "                It derived from BaselineBlock by removing all the non-linear activation.\n",
    "                Non-linear activations are replaced by equivalent matrix multiplication operations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        factor: Optional[int] = 2,\n",
    "        drop_out_rate: Optional[float] = 0.0,\n",
    "        balanced_skip_connection: Optional[bool] = False,\n",
    "        mode: Optional[str] = NAFBLOCK,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.factor = factor\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "        self.balanced_skip_connection = balanced_skip_connection\n",
    "\n",
    "        valid_mode = {PLAIN, BASELINE, NAFBLOCK}\n",
    "        if mode not in valid_mode:\n",
    "            raise ValueError(\"Mode must be one of %r.\" % valid_mode)\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == PLAIN:\n",
    "            self.activation = keras.layers.Activation(\"relu\")\n",
    "        elif self.mode == BASELINE:\n",
    "            self.activation = keras.layers.Activation(\"gelu\")\n",
    "        else:\n",
    "            self.activation = SimpleGate(factor)\n",
    "\n",
    "        self.dropout1 = keras.layers.Dropout(drop_out_rate)\n",
    "\n",
    "        self.dropout2 = keras.layers.Dropout(drop_out_rate)\n",
    "\n",
    "        self.layer_norm1 = None\n",
    "        self.layer_norm2 = None\n",
    "        if self.mode in [NAFBLOCK, BASELINE]:\n",
    "            self.layer_norm1 = keras.layers.LayerNormalization()\n",
    "            self.layer_norm2 = keras.layers.LayerNormalization()\n",
    "\n",
    "    def get_dw_channel(self, input_channels: int) -> int:\n",
    "        if self.mode == NAFBLOCK:\n",
    "            return input_channels * self.factor\n",
    "        else:\n",
    "            return input_channels\n",
    "\n",
    "    def get_ffn_channel(self, input_channels: int) -> int:\n",
    "        return input_channels * self.factor\n",
    "\n",
    "    def get_attention_layer(\n",
    "        self, input_shape: tf.TensorShape\n",
    "    ) -> Optional[keras.layers.Layer]:\n",
    "        input_channels = input_shape[-1]\n",
    "        if self.mode == NAFBLOCK:\n",
    "            return SimplifiedChannelAttention(input_channels)\n",
    "        elif self.mode == BASELINE:\n",
    "            return ChannelAttention(input_channels)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def build(self, input_shape: tf.TensorShape) -> None:\n",
    "        input_channels = input_shape[-1]\n",
    "        dw_channel = self.get_dw_channel(input_channels)\n",
    "\n",
    "        self.conv1 = keras.layers.Conv2D(filters=dw_channel, kernel_size=1, strides=1)\n",
    "        self.dconv2 = keras.layers.Conv2D(\n",
    "            filters=dw_channel,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            strides=1,\n",
    "            groups=dw_channel,\n",
    "        )\n",
    "\n",
    "        self.attention = self.get_attention_layer(input_shape)\n",
    "\n",
    "        self.conv3 = keras.layers.Conv2D(\n",
    "            filters=input_channels, kernel_size=1, strides=1\n",
    "        )\n",
    "\n",
    "        ffn_channel = self.get_ffn_channel(input_channels)\n",
    "\n",
    "        self.conv4 = keras.layers.Conv2D(filters=ffn_channel, kernel_size=1, strides=1)\n",
    "        self.conv5 = keras.layers.Conv2D(\n",
    "            filters=input_channels, kernel_size=1, strides=1\n",
    "        )\n",
    "\n",
    "        self.beta = tf.Variable(\n",
    "            tf.ones((1, 1, 1, input_channels)), trainable=self.balanced_skip_connection\n",
    "        )\n",
    "        self.gamma = tf.Variable(\n",
    "            tf.ones((1, 1, 1, input_channels)), trainable=self.balanced_skip_connection\n",
    "        )\n",
    "\n",
    "    def call_block1(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        x = inputs\n",
    "        if self.layer_norm1 != None:\n",
    "            x = self.layer_norm1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.dconv2(x)\n",
    "        x = self.activation(x)\n",
    "        if self.attention != None:\n",
    "            x = self.attention(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout1(x)\n",
    "        return x\n",
    "\n",
    "    def call_block2(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        y = inputs\n",
    "        if self.layer_norm2 != None:\n",
    "            y = self.layer_norm2(y)\n",
    "        y = self.conv4(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.conv5(y)\n",
    "        y = self.dropout2(y)\n",
    "        return y\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
    "        # Block 1\n",
    "        x = self.call_block1(inputs)\n",
    "\n",
    "        # Residual connection\n",
    "        x = inputs + self.beta * x\n",
    "\n",
    "        # Block 2\n",
    "        y = self.call_block2(x)\n",
    "\n",
    "        # Residual connection\n",
    "        y = x + self.gamma * y\n",
    "\n",
    "        return y\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Add constructor arguments to the config\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"factor\": self.factor,\n",
    "                \"drop_out_rate\": self.drop_out_rate,\n",
    "                \"balanced_skip_connection\": self.balanced_skip_connection,\n",
    "                \"mode\": self.mode,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class PixelShuffle(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    PixelShuffle Layer\n",
    "\n",
    "    Given input of size (H,W,C), it will generate an output\n",
    "    of size\n",
    "    (\n",
    "        H*pixel_shuffle_factor,\n",
    "        W*pixel_shuffle_factor,\n",
    "        channels//(pixel_shuffle_factor**2)\n",
    "    )\n",
    "\n",
    "    Wrapper Class for tf.nn.depth_to_space\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, upscale_factor: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
    "        return tf.nn.depth_to_space(inputs, self.upscale_factor)\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Add upscale factor to the config\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"upscale_factor\": self.upscale_factor})\n",
    "        return config\n",
    "\n",
    "\n",
    "class UpScale(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    UpScale Layer\n",
    "\n",
    "    Given channels and pixel_shuffle_factor as input, it will generate an output\n",
    "    of size\n",
    "    (\n",
    "        H*pixel_shuffle_factor,\n",
    "        W*pixel_shuffle_factor,\n",
    "        channels//(pixel_shuffle_factor**2)\n",
    "    )\n",
    "    While giving input, make sure that (pixel_shuffle_factor**2) divides channels\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, pixel_shuffle_factor: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.channels = channels\n",
    "        self.pixel_shuffle_factor = pixel_shuffle_factor\n",
    "\n",
    "        if channels % (pixel_shuffle_factor**2) != 0:\n",
    "            raise ValueError(\n",
    "                f\"Number of channels must divide square of pixel_shuffle_factor\"\n",
    "                f\"In the constructor {channels} channels and \"\n",
    "                f\"{pixel_shuffle_factor} pixel_shuffle_factor was passed\"\n",
    "            )\n",
    "\n",
    "        self.conv = keras.layers.Conv2D(\n",
    "            channels, kernel_size=1, strides=1, use_bias=False\n",
    "        )\n",
    "        self.pixel_shuffle = PixelShuffle(pixel_shuffle_factor)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
    "        return self.pixel_shuffle(self.conv(inputs))\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Add channels and pixel_shuffle_factor to the config\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"channels\": self.channels,\n",
    "                \"pixel_shuffle_factor\": self.pixel_shuffle_factor,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "class NAFNet(keras.models.Model):\n",
    "    \"\"\"\n",
    "    NAFNet\n",
    "\n",
    "    The input channels will be mapped to the number of filters passed.\n",
    "    After each down block, the number of filters will increase by a factor of 2.\n",
    "    After each up block, the number of filters will decrease by a factor of 2.\n",
    "    And finally the filters will be mapped back to the initial input size.\n",
    "\n",
    "    Overwrite create_encoder_and_down_blocks, create_decoder_and_up_blocks, create_middle_blocks\n",
    "    to add your own implementation for these blocks. Overwrite get_blocks to use your custom block\n",
    "    in NAFNet. But make sure to follow the restrictions on these methods and blocks.\n",
    "\n",
    "    Parameters:\n",
    "        filters: denotes the starting filter size.\n",
    "        middle_block_num: (int) denotes the number of middle blocks.\n",
    "            Each middle block is a single NAFBlock unit.\n",
    "        encoder_block_nums: (tuple) the tuple size denotes the number of encoder blocks.\n",
    "            Each tuple entry denotes the number of NAFBlocks in the corresponding encoder block.\n",
    "            len(encoder_block_nums) should be the same as the len(decoder_block_nums)\n",
    "        decoder_block_nums: (tuple) the tuple size denotes the number of decoder blocks.\n",
    "            Each tuple entry denotes the number of NAFBlocks in the corresponding decoder block.\n",
    "            len(decoder_block_nums) should be the same as the len(encoder_block_nums)\n",
    "        block_type: (str) denotes what block to use in NAFNet\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filters: Optional[int] = 16,\n",
    "        middle_block_num: Optional[int] = 1,\n",
    "        encoder_block_nums: Optional[Tuple[int]] = (1, 1, 1, 1),\n",
    "        decoder_block_nums: Optional[Tuple[int]] = (1, 1, 1, 1),\n",
    "        block_type: Optional[str] = NAFBLOCK,\n",
    "        drop_out_rate: Optional[float] = 0.0,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.filters = filters\n",
    "        self.middle_block_num = middle_block_num\n",
    "        self.encoder_block_nums = encoder_block_nums\n",
    "        self.decoder_block_nums = decoder_block_nums\n",
    "        self.block_type = block_type\n",
    "        self.drop_out_rate = drop_out_rate\n",
    "\n",
    "        self.intro = keras.layers.Conv2D(filters=filters, kernel_size=3, padding=\"same\")\n",
    "\n",
    "        self.encoders = []\n",
    "        self.decoders = []\n",
    "        self.ups = []\n",
    "        self.downs = []\n",
    "\n",
    "        if len(encoder_block_nums) != len(decoder_block_nums):\n",
    "            raise ValueError(\n",
    "                \"The number of encoder blocks should match the number of decoder blocks\"\n",
    "                f\"In the constructor {len(encoder_block_nums)} encoder blocks\"\n",
    "                f\" and {len(decoder_block_nums)} were passed.\"\n",
    "            )\n",
    "\n",
    "        channels = filters\n",
    "        channels = self.create_encoder_and_down_blocks(channels, encoder_block_nums)\n",
    "\n",
    "        if len(self.encoders) != len(self.downs):\n",
    "            raise ValueError(\n",
    "                \"The number of encoder blocks should match the number of down blocks\"\n",
    "                f\"In `create_encoder_and_down_blocks` {len(self.encoders)} encoder blocks\"\n",
    "                f\" and {len(self.downs)} down blocks were created.\"\n",
    "            )\n",
    "\n",
    "        self.create_middle_blocks(middle_block_num)\n",
    "\n",
    "        self.create_decoder_and_up_blocks(channels, decoder_block_nums)\n",
    "\n",
    "        if len(self.decoders) != len(self.ups):\n",
    "            raise ValueError(\n",
    "                \"The number of decoder blocks should match the number of up blocks\"\n",
    "                f\"In `create_decoder_and_up_blocks` {len(self.decoders)} decoder blocks\"\n",
    "                f\" and {len(self.ups)} up blocks were created.\"\n",
    "            )\n",
    "\n",
    "        if len(encoder_block_nums) != len(decoder_block_nums):\n",
    "            raise ValueError(\n",
    "                \"The number of encoder blocks should match the number of decoder blocks\"\n",
    "                f\"In `create_encoder_and_down_blocks` {len(self.encoders)} encoder blocks were created.\"\n",
    "                f\"In `create_decoder_and_up_blocks` {len(self.decoders)} decoder blocks were created.\"\n",
    "            )\n",
    "\n",
    "        # The height and width of the image should be a\n",
    "        #  multiple of self.expected_image_scale\n",
    "        # If that is not the case, it will be fixed in the call(...) method.\n",
    "        self.expected_image_scale = 2 ** len(self.encoders)\n",
    "\n",
    "    def build(self, input_shape: tf.TensorShape) -> None:\n",
    "        input_channels = input_shape[-1]\n",
    "        self.ending = keras.layers.Conv2DTranspose(\n",
    "            filters=input_channels, kernel_size=3, padding=\"same\"\n",
    "        )\n",
    "\n",
    "    def get_block(self) -> keras.layers.Layer:\n",
    "        \"\"\"\n",
    "        Returns the block to be used in NAFNet\n",
    "        Can be overriden to use custom blocks in NAFNet\n",
    "        \"\"\"\n",
    "        return NAFBlock(mode=self.block_type, drop_out_rate=self.drop_out_rate)\n",
    "\n",
    "    def create_encoder_and_down_blocks(\n",
    "        self,\n",
    "        channels: int,\n",
    "        encoder_block_nums: Optional[Tuple[int]],\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Creates equal number of encoder blocks and down blocks.\n",
    "        \"\"\"\n",
    "\n",
    "        for num in encoder_block_nums:\n",
    "            self.encoders.append(\n",
    "                keras.models.Sequential([self.get_block() for _ in range(num)])\n",
    "            )\n",
    "            self.downs.append(\n",
    "                keras.layers.Conv2D(2 * channels, kernel_size=2, strides=2)\n",
    "            )\n",
    "            channels *= 2\n",
    "        return channels\n",
    "\n",
    "    def create_middle_blocks(self, middle_block_num: int) -> None:\n",
    "        \"\"\"\n",
    "        Creates middle blocks in NAFNet\n",
    "        \"\"\"\n",
    "        self.middle_blocks = keras.models.Sequential(\n",
    "            [self.get_block() for _ in range(middle_block_num)]\n",
    "        )\n",
    "\n",
    "    def create_decoder_and_up_blocks(\n",
    "        self,\n",
    "        channels: int,\n",
    "        decoder_block_nums: Optional[Tuple[int]],\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Creates equal number of decoder blocks and up blocks.\n",
    "        \"\"\"\n",
    "        for num in decoder_block_nums:\n",
    "            self.ups.append(UpScale(2 * channels, pixel_shuffle_factor=2))\n",
    "            channels = channels // 2\n",
    "            self.decoders.append(\n",
    "                keras.models.Sequential([self.get_block() for _ in range(num)])\n",
    "            )\n",
    "        return channels\n",
    "\n",
    "    def call(self, inputs: tf.Tensor, *args, **kwargs) -> tf.Tensor:\n",
    "        _, H, W, _ = inputs.shape\n",
    "        # Scale the image to the next nearest multiple of self.expected_image_scale\n",
    "        inputs = self.fix_input_shape(inputs)\n",
    "\n",
    "        x = self.intro(inputs)\n",
    "\n",
    "        encoder_outputs = []\n",
    "        for encoder, down in zip(self.encoders, self.downs):\n",
    "            x = encoder(x)\n",
    "            encoder_outputs.append(x)\n",
    "            x = down(x)\n",
    "\n",
    "        x = self.middle_blocks(x)\n",
    "\n",
    "        for decoder, up, encoder_output in zip(\n",
    "            self.decoders, self.ups, encoder_outputs[::-1]\n",
    "        ):\n",
    "            x = up(x)\n",
    "            # Residual connection of encoder blocks with decoder blocks\n",
    "            x = x + encoder_output\n",
    "            x = decoder(x)\n",
    "\n",
    "        x = self.ending(x)\n",
    "        # Residual connection of inputs with output\n",
    "        x = x + inputs\n",
    "\n",
    "        # Crop back to the original size\n",
    "        return x[:, :H, :W, :]\n",
    "\n",
    "    def fix_input_shape(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Fixes input shape for NAFNet\n",
    "        This is because NAFNet can only work with images whose shape is\n",
    "         multiple of 2**(no. of encoder blocks)\n",
    "        Hence the image is padded to match that shape\n",
    "        \"\"\"\n",
    "        _, H, W, _ = inputs.shape\n",
    "\n",
    "        if H is None:\n",
    "            H = 256\n",
    "\n",
    "        # Calculating how much padding is required\n",
    "        height_padding, width_padding = 0, 0\n",
    "        if H % self.expected_image_scale != 0:\n",
    "            height_padding = self.expected_image_scale - H % self.expected_image_scale\n",
    "        if W % self.expected_image_scale != 0:\n",
    "            width_padding = self.expected_image_scale - W % self.expected_image_scale\n",
    "\n",
    "        paddings = tf.constant(\n",
    "            [[0, 0], [0, height_padding], [0, width_padding], [0, 0]]\n",
    "        )\n",
    "        return tf.pad(inputs, paddings)\n",
    "\n",
    "    def get_config(self) -> dict:\n",
    "        \"\"\"Add upscale factor to the config\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"filters\": self.filters,\n",
    "                \"middle_block_num\": self.middle_block_num,\n",
    "                \"encoder_block_nums\": self.encoder_block_nums,\n",
    "                \"decoder_block_nums\": self.decoder_block_nums,\n",
    "                \"block_type\": self.block_type,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "def create_NAFNet(\n",
    "    filters: Optional[int] = 16,\n",
    "    middle_block_num: Optional[int] = 1,\n",
    "    encoder_block_nums: Optional[tuple] = (1, 1, 1, 1),\n",
    "    decoder_block_nums: Optional[tuple] = (1, 1, 1, 1),\n",
    "    block_type: Optional[str] = NAFBLOCK,\n",
    "    drop_out_rate: Optional[float] = 0.0,\n",
    "    input_shape: Optional[tuple] = (1, 256, 256, 3),\n",
    "    summary: Optional[bool] = True,\n",
    "):\n",
    "    model = NAFNet(\n",
    "        filters=filters,\n",
    "        middle_block_num=middle_block_num,\n",
    "        encoder_block_nums=encoder_block_nums,\n",
    "        decoder_block_nums=decoder_block_nums,\n",
    "        block_type=block_type,\n",
    "        drop_out_rate=drop_out_rate,\n",
    "    )\n",
    "    if summary:\n",
    "        dummy = tf.ones(input_shape)\n",
    "        model(dummy)\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_NAFNet(\n",
    "    filters=32,\n",
    "    middle_block_num=2,\n",
    "    encoder_block_nums=(1, 1, 1, 28),\n",
    "    input_shape=(1, 128, 128, 3),\n",
    "    drop_out_rate=0.1,\n",
    "    decoder_block_nums=(1, 1, 1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "1jQ7o5S-1lgz",
    "outputId": "39d99ae7-da2d-4813-85eb-25877ae0c5e9"
   },
   "outputs": [],
   "source": [
    "#!pip install import-ipynb\n",
    "#!unzip /content/drive/MyDrive/mirnet_v2\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import optimizer\n",
    "import time\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "\n",
    "# also tested with mirnet_v2\n",
    "# import import_ipynb\n",
    "# from mirnet_v2 import get_mirnet\n",
    "\n",
    "# metrics\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, 1.0)\n",
    "\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, 1.0)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def update_fn(p, grad, exp_avg, lr, wd, beta1, beta2):\n",
    "    # stepweight decay\n",
    "\n",
    "    p.assign(p * (1 - lr * wd))\n",
    "\n",
    "    # weight update\n",
    "\n",
    "    update = (\n",
    "        tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0] * exp_avg\n",
    "        + (1 - tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0]) * grad\n",
    "    )\n",
    "    p.assign_add(tf.sign(update) * -lr)\n",
    "\n",
    "    # decay the momentum running average coefficient\n",
    "\n",
    "    exp_avg.assign(exp_avg * beta2 + grad * (1 - beta2))\n",
    "\n",
    "\n",
    "def lerp(start, end, weight):\n",
    "    return start + weight * (end - start)\n",
    "\n",
    "\n",
    "def sparse_lerp(start, end, weight):\n",
    "    # Mathematically equivalent, but you can't subtract a dense Tensor from sparse\n",
    "    # IndexedSlices, so we have to flip it around.\n",
    "    return start + weight * -(start - end)\n",
    "\n",
    "# lion optimizer\n",
    "class Lion(optimizer.Optimizer):\n",
    "    \"\"\"Optimizer that implements the Lion algorithm.\n",
    "    Lion was published in the paper \"Symbolic Discovery of Optimization Algorithms\"\n",
    "    which is available at https://arxiv.org/abs/2302.06675\n",
    "    Args:\n",
    "      learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n",
    "        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n",
    "        that takes no arguments and returns the actual value to use. The\n",
    "        learning rate. Defaults to 1e-4.\n",
    "      beta_1: A float value or a constant float tensor, or a callable\n",
    "        that takes no arguments and returns the actual value to use. Factor\n",
    "         used to interpolate the current gradient and the momentum. Defaults to 0.9.\n",
    "      beta_2: A float value or a constant float tensor, or a callable\n",
    "        that takes no arguments and returns the actual value to use. The\n",
    "        exponential decay rate for the momentum. Defaults to 0.99.\n",
    "    Notes:\n",
    "    The sparse implementation of this algorithm (used when the gradient is an\n",
    "    IndexedSlices object, typically because of `tf.gather` or an embedding\n",
    "    lookup in the forward pass) does apply momentum to variable slices even if\n",
    "    they were not used in the forward pass (meaning they have a gradient equal\n",
    "    to zero). Momentum decay (beta2) is also applied to the entire momentum\n",
    "    accumulator. This means that the sparse behavior is equivalent to the dense\n",
    "    behavior (in contrast to some momentum implementations which ignore momentum\n",
    "    unless a variable slice was actually used).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=1e-4,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.99,\n",
    "        weight_decay=None,\n",
    "        clipnorm=None,\n",
    "        clipvalue=None,\n",
    "        global_clipnorm=None,\n",
    "        jit_compile=True,\n",
    "        name=\"Lion\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            weight_decay=weight_decay,\n",
    "            clipnorm=clipnorm,\n",
    "            clipvalue=clipvalue,\n",
    "            global_clipnorm=global_clipnorm,\n",
    "            jit_compile=jit_compile,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self._learning_rate = self._build_learning_rate(learning_rate)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "    def build(self, var_list):\n",
    "        \"\"\"Initialize optimizer variables.\n",
    "        var_list: list of model variables to build Lion variables on.\n",
    "        \"\"\"\n",
    "        super().build(var_list)\n",
    "        if hasattr(self, \"_built\") and self._built:\n",
    "            return\n",
    "        self._built = True\n",
    "        self._emas = []\n",
    "        for var in var_list:\n",
    "            self._emas.append(\n",
    "                self.add_variable_from_reference(\n",
    "                    model_variable=var, variable_name=\"ema\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def update_step(self, gradient, variable):\n",
    "        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n",
    "        lr = tf.cast(self.learning_rate, variable.dtype)\n",
    "        beta_1 = tf.constant(self.beta_1, shape=(1,))\n",
    "        beta_2 = tf.constant(self.beta_2, shape=(1,))\n",
    "\n",
    "        var_key = self._var_key(variable)\n",
    "        ema = self._emas[self._index_dict[var_key]]\n",
    "\n",
    "        if isinstance(gradient, tf.IndexedSlices):\n",
    "            # Sparse gradients.\n",
    "            lerp_fn = sparse_lerp\n",
    "        else:\n",
    "            # Dense gradients.\n",
    "            lerp_fn = lerp\n",
    "\n",
    "        update = lerp_fn(ema, gradient, 1 - beta_1)\n",
    "        update = tf.sign(update)\n",
    "        variable.assign_sub(update * lr)\n",
    "\n",
    "        ema.assign(lerp_fn(ema, gradient, 1 - beta_2))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "\n",
    "        config.update(\n",
    "            {\n",
    "                \"learning_rate\": self._serialize_hyperparameter(self._learning_rate),\n",
    "                \"beta_1\": self.beta_1,\n",
    "                \"beta_2\": self.beta_2,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "def fast_check(generator, amount: int = 20):\n",
    "    count = 0\n",
    "    for item in generator:\n",
    "        yield item\n",
    "        count += 1\n",
    "        if count == amount:\n",
    "            break\n",
    "\n",
    "# Loss functions\n",
    "class SSIMLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "\n",
    "class PSNRLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"Implementation of Negative PSNR Loss\n",
    "\n",
    "    References:\n",
    "\n",
    "    1. [HINet: Half Instance Normalization Network for Image Restoration](https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Chen_HINet_Half_Instance_Normalization_Network_for_Image_Restoration_CVPRW_2021_paper.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_val: float = 1.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return -tf.image.psnr(y_true, y_pred, max_val=self.max_val)\n",
    "\n",
    "\n",
    "class CharbonnierLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"The Charbonnier implemented as a `tf.keras.losses.Loss`.\n",
    "\n",
    "    The Charbonnier loss, also known as the \"smooth L1 loss,\" is a loss function that is used in\n",
    "    image processing and computer vision tasks to balance the trade-off between the Mean Squared\n",
    "    Error (MSE) and the Mean Absolute Error (MAE). It is defined as\n",
    "\n",
    "    $$L=\\sqrt{\\left(\\left(x^{\\wedge} 2+\\varepsilon^{\\wedge} 2\\right)\\right)}$$\n",
    "\n",
    "    where x is the error and Îµ is a small positive constant (typically on the order of 0.001). It\n",
    "    is less sensitive to outliers than the mean squared error and less computationally expensive\n",
    "    than the mean absolute error.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): a small positive constant.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon: float, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epsilon = tf.convert_to_tensor(epsilon)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        squared_difference = tf.square(y_true - y_pred)\n",
    "        return tf.reduce_mean(tf.sqrt(squared_difference + tf.square(self.epsilon)))\n",
    "\n",
    "# combination loss with weighted \"counter loss\"\n",
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    def __init__(\n",
    "        self,\n",
    "        counter_loss_weight: float = 0.2,\n",
    "        charbonnier_loss_weight: float = 0.8,\n",
    "        psnr_max_val: float = 1.0,\n",
    "        charbonnier_epsilon: float = 1e-3,\n",
    "        counter_loss_fn: str = \"ssim\",\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.psnr_loss = PSNRLoss(max_val=psnr_max_val)\n",
    "        self.ssim_loss = SSIMLoss()\n",
    "        self.charbonnier_loss = CharbonnierLoss(\n",
    "            epsilon=charbonnier_epsilon, reduction=tf.keras.losses.Reduction.SUM\n",
    "        )\n",
    "        self.counter_loss_weight = counter_loss_weight\n",
    "        self.charbonnier_loss_weight = charbonnier_loss_weight\n",
    "        self.counter_loss_fn = counter_loss_fn\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        counter_loss = (\n",
    "            self.psnr_loss(y_true, y_pred)\n",
    "            if self.counter_loss_fn == \"psnr\"\n",
    "            else self.ssim_loss(y_true, y_pred)\n",
    "        )\n",
    "        charbonnier_loss = self.charbonnier_loss(y_true, y_pred)\n",
    "        combined_loss = (\n",
    "            self.counter_loss_weight * counter_loss\n",
    "            + self.charbonnier_loss_weight * charbonnier_loss\n",
    "        )\n",
    "        return combined_loss\n",
    "\n",
    "\n",
    "# usage of tf.GradientTape() because of model contraints fitting generator\n",
    "@tf.function\n",
    "def train_step(model, optimizer, loss_fn, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss, psnr_metric(y, y_pred), ssim_metric(y, y_pred)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(model, loss_fn, x, y):\n",
    "    y_pred = model(x, training=False)\n",
    "    loss = loss_fn(y, y_pred)\n",
    "    return loss, psnr_metric(y, y_pred), ssim_metric(y, y_pred)\n",
    "\n",
    "\n",
    "def metric_avg(psnr, ssim, loss, decimal_places):\n",
    "    avg_psnr = tf.reduce_mean(psnr)\n",
    "    avg_ssim = tf.reduce_mean(ssim)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    avg_psnr_rounded = tf.round(avg_psnr * 10**decimal_places) / (\n",
    "        10**decimal_places\n",
    "    )\n",
    "    avg_ssim_rounded = tf.round(avg_ssim * 10**decimal_places) / (\n",
    "        10**decimal_places\n",
    "    )\n",
    "    loss_rounded = tf.round(loss * 10**decimal_places) / (10**decimal_places)\n",
    "    return avg_psnr_rounded, avg_ssim_rounded, loss_rounded\n",
    "\n",
    "# quick prediction during training\n",
    "def quick_pred(data_gen, amount: int = 1, display: bool = True):\n",
    "    predictions = []\n",
    "    for i in range(amount):\n",
    "        for x, y in data_gen:\n",
    "            for j in range(len(x) if len(x) <= 24 else 24):\n",
    "                input_data = np.expand_dims(x[j], axis=0)\n",
    "                pred = model.predict(input_data)\n",
    "                pred = np.clip(pred * 255, 0, 255).astype(\"uint8\")\n",
    "                predictions.append(pred)\n",
    "            break\n",
    "    if display:\n",
    "        for i in range(len(x) if len(x) <= 24 else 24):\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "            axs[0].imshow(x[i])\n",
    "            axs[0].set_title(\"Input\")\n",
    "            axs[1].imshow(y[i])\n",
    "            axs[1].set_title(\"Ground Truth\")\n",
    "            axs[2].imshow(predictions[i][0])\n",
    "            axs[2].set_title(\"Prediction\")\n",
    "            plt.show()\n",
    "    return predictions\n",
    "\n",
    "# write training progress to csv\n",
    "def write_to_csv(\n",
    "    loss_total,\n",
    "    psnr_total,\n",
    "    ssim_total,\n",
    "    loss_epoch=None,\n",
    "    psnr_epoch=None,\n",
    "    ssim_epoch=None,\n",
    "    train=True,\n",
    "    name=\"results.csv\",\n",
    "):\n",
    "    with open(name, \"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"epoch\", \"loss\", \"psnr\", \"ssim\"])\n",
    "        for i in range(len(loss_total)):\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    i + 1,\n",
    "                    loss_total[i],\n",
    "                    psnr_total[i],\n",
    "                    ssim_total[i],\n",
    "                ]\n",
    "            )\n",
    "        if train:\n",
    "            writer.writerow([\"epoch\", \"loss\", \"psnr\", \"ssim\"])\n",
    "            for i in range(len(loss_epoch)):\n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        i + 1,\n",
    "                        loss_epoch[i],\n",
    "                        psnr_epoch[i],\n",
    "                        ssim_epoch[i],\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "# training loop\n",
    "count = 0\n",
    "save = True\n",
    "optimizer = Lion(1e-5, weight_decay=1e-6)\n",
    "loss_fn = CharbonnierLoss(epsilon=1e-3, reduction=tf.keras.losses.Reduction.SUM)\n",
    "num_epochs = 5\n",
    "loss_fn = CombinedLoss(\n",
    "    counter_loss_weight=0.3,\n",
    "    charbonnier_loss_weight=0.7,\n",
    "    psnr_max_val=1.0,\n",
    "    charbonnier_epsilon=1e-3,\n",
    ")\n",
    "max_steps = len(train_data)\n",
    "decimal_places = 4\n",
    "epoch_start_time = time.time()\n",
    "# initialize lists to save training progress\n",
    "loss_total, psnr_total, ssim_total, loss_epoch, psnr_epoch, ssim_epoch = (\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    ")\n",
    "save_all = True\n",
    "save = True\n",
    "for epoch in range(num_epochs):\n",
    "    step = 0\n",
    "    for x, y in train_data:\n",
    "        step += 1\n",
    "        if epoch > 1 and loss_epoch[-1] > loss_epoch[-2]:\n",
    "            optimizer.learning_rate = optimizer.learning_rate * 0.9\n",
    "            print(\"changed lr to \", optimizer.learning_rate * 0.9)\n",
    "        loss, psnr, ssim = train_step(model, optimizer, loss_fn, x, y)\n",
    "        avg_psnr, avg_ssim, avg_loss = metric_avg(psnr, ssim, loss, decimal_places)\n",
    "        if save_all and step % 10 == 0:\n",
    "            loss_total.append(avg_loss)\n",
    "            psnr_total.append(avg_psnr)\n",
    "            ssim_total.append(avg_ssim)\n",
    "        res = list(map(lambda x: x.numpy(), [loss, avg_psnr, avg_ssim]))\n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - epoch_start_time\n",
    "        average_time_per_step = elapsed_time / step\n",
    "        remaining_steps = max_steps - step\n",
    "        remaining_time = remaining_steps * average_time_per_step\n",
    "        print(\n",
    "            f\"\\rEpoch: {epoch + 1}/{num_epochs}, Loss: {res[0]:.{decimal_places}f}, PSNR: {res[1]:.{decimal_places}f}, SSIM: {res[2]:.{decimal_places}f}, Step: {step}/{max_steps}, Remaining Time: {remaining_time:.2f} seconds/ {remaining_time/60:.2f} minutes -- elapsed: {elapsed_time:.1f} seconds\",\n",
    "            end=\" \" * 5,\n",
    "            flush=True,\n",
    "        )\n",
    "    loss_epoch.append(avg_loss)\n",
    "    psnr_epoch.append(avg_psnr)\n",
    "    ssim_epoch.append(avg_ssim)\n",
    "    for x, y in test_data:\n",
    "        loss_e, psnr_e, ssim_e = test_step(model, loss_fn, x, y)\n",
    "        loss_e, psnr_e, ssim_e = metric_avg(psnr_e, ssim_e, loss_e, decimal_places)\n",
    "    print(\n",
    "        f\"\\nEpoch: {epoch + 1}, Eval Loss: {loss_e:.{decimal_places}f}, Eval PSNR: {psnr_e:.{decimal_places}f}, Eval SSIM: {ssim_e:.{decimal_places}f}\"\n",
    "    )\n",
    "    quick_pred(test_data, amount=2, display=True)\n",
    "    if save:\n",
    "        model.save(f\"NafNet_{str(epoch + 1)}_2\", save_format=\"tf\")\n",
    "        print(\"Model saved after epoch\", epoch + 1)\n",
    "    write_to_csv([loss_e], [psnr_e], [ssim_e], train=False, name=\"results_eval.csv\")\n",
    "model.save(\"NafNet\", save_format=\"tf\")\n",
    "write_to_csv(loss_total, psnr_total, ssim_total, loss_epoch, psnr_epoch, ssim_epoch)\n",
    "print(\"Training complete, model saved, results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MKYfSGaW_ucE",
    "outputId": "9d73d3a3-cca2-4ba1-91ce-86acdf3c894a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/NafNet_new_13.07_5E6F'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move models to drive\n",
    "import shutil\n",
    "\n",
    "# shutil.copy(\"model.h5\", \"/content/drive/MyDrive/model_resto.h5\")\n",
    "# shutil.move(\"NafNet_5\", \"/content/drive/MyDrive/NafNet_5_mixed_wq_fine\")\n",
    "# shutil.move(\"NafNet\", \"/content/drive/MyDrive/NafNet_mixed_wq_fine\")\n",
    "shutil.move(\"NafNet_2_2\", \"/content/drive/MyDrive/NafNet_new_13.07_5E6F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oO6sm9RNr2Yq",
    "outputId": "ddc84c3d-6fe7-41ee-f05e-5386b1a0d58a"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"/content/drive/MyDrive/NafNet_new_13.07_5E6F\")\n",
    "model.compile(optimizer, loss_fn, metrics=[psnr_metric, ssim_metric])\n",
    "loss_e, psnr_e, ssim_e = model.evaluate(test_data)\n",
    "loss_e, psnr_e, ssim_e = metric_avg(psnr_e, ssim_e, loss_e, decimal_places)\n",
    "write_to_csv([loss_e], [psnr_e], [ssim_e], train=False, name=\"results_eval.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

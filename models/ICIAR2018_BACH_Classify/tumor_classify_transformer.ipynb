{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Qp52fTBUfRT",
    "outputId": "8d5e9be4-59ce-48c4-b6dd-40659b252594"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wv7Tf8G5UlSe",
    "outputId": "0de9f247-74d2-49ec-a6b5-7ea661278d35"
   },
   "outputs": [],
   "source": [
    "#!wget \"https://zenodo.org/record/3632035/files/ICIAR2018_BACH_Challenge.zip?download=1\"\n",
    "#!wget \"https://zenodo.org/record/3632035/files/ICIAR2018_BACH_Challenge_TestDataset.zip?download=1\"\n",
    "!unzip \"/content/drive/MyDrive/ICIAR2018_BACH.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bFMfhcQU8S6"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# metrics\n",
    "def auc(y_true, y_pred):\n",
    "    # First, we need to convert the one-hot encoded labels and predicted probabilities\n",
    "    # into a single label and probability for each sample.\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    y_pred = y_pred[:, 1:]\n",
    "\n",
    "    # Then we can use the roc_auc_score function to compute the AUC for each class\n",
    "    auc_scores = []\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        auc_scores.append(roc_auc_score(y_true, y_pred[:, i]))\n",
    "\n",
    "    # Return the average AUC across all classes\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def dice_score(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1, 2))\n",
    "    sum_ = tf.reduce_sum(y_true + y_pred, axis=(1, 2))\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    jd = (1 - jac) * smooth\n",
    "    return tf.reduce_mean(jd)\n",
    "\n",
    "\n",
    "def tf_mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.5):\n",
    "        y_pred_ = tf.cast(y_pred > t, tf.int32)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        prec.append(score)\n",
    "    val = K.mean(K.stack(prec), axis=0)\n",
    "    return [val, up_opt]\n",
    "\n",
    "\n",
    "def cross_entropy_balanced(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    count_neg = tf.reduce_sum(1.0 - y_true)\n",
    "    count_pos = tf.reduce_sum(y_true)\n",
    "\n",
    "    beta = count_neg / (count_pos + count_neg)\n",
    "\n",
    "    pos_weight = beta / (1 - beta)\n",
    "\n",
    "    cost = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        logits=y_pred, labels=y_true, pos_weight=pos_weight\n",
    "    )\n",
    "\n",
    "    cost = tf.reduce_mean(cost * (1 - beta))\n",
    "\n",
    "    return tf.where(tf.equal(count_pos, 0.0), 0.0, cost)\n",
    "\n",
    "\n",
    "def pixel_error(y_true, y_pred):\n",
    "    pred = tf.cast(tf.greater(y_pred, 0.5), tf.int32)\n",
    "    error = tf.cast(tf.not_equal(pred, tf.cast(y_true, tf.int32)), tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "4juusIVfSeEP",
    "outputId": "d1ea8528-0d4f-4de2-a7c3-50f27c9da36b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    load_img,\n",
    "    img_to_array,\n",
    ")\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "# Define parameters for image resizing and augmentation\n",
    "\n",
    "parent_folder_path = \"/content/ICIAR2018_BACH_Challenge_JPG/\"\n",
    "\n",
    "num_augmented_images = 6 # number of augmented images per original image\n",
    "target_size = (256, 256)\n",
    "test_ratio = 0.2  # ratio compared to the original dataset size\n",
    "\n",
    "for class_name in os.listdir(parent_folder_path):\n",
    "    class_folder_path = os.path.join(parent_folder_path, class_name)\n",
    "    if not os.path.isdir(class_folder_path):\n",
    "        continue\n",
    "\n",
    "    test_class_folder_path = os.path.join(\n",
    "        parent_folder_path, \"..\", \"ICIAR2018_BACH_Challenge_JPG_test\", class_name\n",
    "    )\n",
    "    os.makedirs(test_class_folder_path, exist_ok=True)\n",
    "\n",
    "    img_names = [\n",
    "        img_name\n",
    "        for img_name in os.listdir(class_folder_path)\n",
    "        if img_name.lower().endswith((\".tif\", \".png\", \".jpg\", \".jpeg\"))\n",
    "    ]\n",
    "    random.shuffle(img_names)\n",
    "    num_test_images = int(len(img_names) * test_ratio)\n",
    "\n",
    "    for img_name in img_names[:num_test_images]:\n",
    "        img = Image.open(os.path.join(class_folder_path, img_name))\n",
    "        img = img.resize(target_size)\n",
    "        img.save(os.path.join(test_class_folder_path, img_name))\n",
    "        os.remove(os.path.join(class_folder_path, img_name))\n",
    "\n",
    "    for img_name in img_names[num_test_images:]:\n",
    "        img = Image.open(os.path.join(class_folder_path, img_name))\n",
    "        img = img.resize(target_size)\n",
    "\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.Rotate(limit=20),\n",
    "                A.HorizontalFlip(),\n",
    "                A.VerticalFlip(),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "                A.OneOf(\n",
    "                    [\n",
    "                        A.ShiftScaleRotate(\n",
    "                            shift_limit=0.18, scale_limit=0.18, rotate_limit=18, p=0.25\n",
    "                        ),\n",
    "                        A.ShiftScaleRotate(\n",
    "                            shift_limit=0.18,\n",
    "                            scale_limit=0.18,\n",
    "                            rotate_limit=18,\n",
    "                            border_mode=cv2.BORDER_CONSTANT,\n",
    "                            value=0,\n",
    "                            interpolation=cv2.INTER_NEAREST,\n",
    "                            p=0.25,\n",
    "                        ),\n",
    "                    ],\n",
    "                    p=0.4,\n",
    "                ),\n",
    "                A.RGBShift(p=0.2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i in range(num_augmented_images):\n",
    "            transformed = transform(image=np.array(img))\n",
    "            transformed_image = Image.fromarray(transformed[\"image\"])\n",
    "            transformed_image.save(\n",
    "                os.path.join(class_folder_path, f\"aug_{i}_{img_name}\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGk7rrVoJQSH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_path = \"/content/ICIAR2018_BACH_Challenge_JPG\"\n",
    "test_path = \"/content/ICIAR2018_BACH_Challenge_JPG_test\"\n",
    "\n",
    "# Check the number of images in each class\n",
    "def check_nums(dataset_path):\n",
    "    class_folders = os.listdir(dataset_path)\n",
    "    for class_folder in class_folders:\n",
    "        class_folder_path = os.path.join(dataset_path, class_folder)\n",
    "        if os.path.isdir(class_folder_path):\n",
    "            num_images = len(os.listdir(class_folder_path))\n",
    "            print(f\"Class {class_folder} has {num_images} images.\")\n",
    "\n",
    "\n",
    "check_nums(train_path)\n",
    "check_nums(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLin27PDVXhM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# data generator following the Keras Sequence structure\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        directory,\n",
    "        batch_size,\n",
    "        target_size=(150, 150),\n",
    "        shuffle=True,\n",
    "        augmentations=None,\n",
    "    ):\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentations = augmentations\n",
    "        self.class_names = sorted(os.listdir(directory))\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.samples = []\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(self.directory, class_name)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                self.samples.append((os.path.join(class_dir, filename), i))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.samples) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_samples = self.samples[\n",
    "            idx * self.batch_size : (idx + 1) * self.batch_size\n",
    "        ]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for sample in batch_samples:\n",
    "            image = cv2.imread(sample[0])\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, self.target_size)\n",
    "            label = sample[1]\n",
    "            if self.augmentations is not None:\n",
    "                augmented = self.augmentations(image=image)\n",
    "                image = augmented[\"image\"]\n",
    "            batch_images.append(image)\n",
    "            batch_labels.append(label)\n",
    "        return np.array(batch_images) / 255.0, tf.keras.utils.to_categorical(\n",
    "            batch_labels, num_classes=self.num_classes\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.samples)\n",
    "\n",
    "# further augmentations if needed\n",
    "train_augmentations = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.3, brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.ColorJitter(p=0.2),\n",
    "        A.GaussianBlur(p=0.25, blur_limit=(3, 7)),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=(-20, 20), p=0.5, interpolation=cv2.INTER_NEAREST),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                # different border modes for more variety\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.18,\n",
    "                    scale_limit=0.18,\n",
    "                    rotate_limit=18,\n",
    "                    border_mode=cv2.BORDER_CONSTANT,\n",
    "                    value=0,\n",
    "                    interpolation=cv2.INTER_NEAREST,\n",
    "                ),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.25,\n",
    "                    scale_limit=0.25,\n",
    "                    rotate_limit=25,\n",
    "                    interpolation=cv2.INTER_NEAREST,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.4,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "image_size = 256\n",
    "\n",
    "# get the data generators\n",
    "def get_fold_generator(\n",
    "    fold_path,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    shuffle=True,\n",
    "    augmentations=train_augmentations,\n",
    "    mode=\"TRAIN\",\n",
    "):\n",
    "    if mode == \"TRAIN\":\n",
    "        generator = CustomDataGenerator(\n",
    "            directory=fold_path,\n",
    "            batch_size=batch_size,\n",
    "            target_size=target_size,\n",
    "            shuffle=shuffle,\n",
    "            augmentations=augmentations,\n",
    "        )\n",
    "    elif mode == \"VAL\":\n",
    "        generator = CustomDataGenerator(\n",
    "            directory=fold_path,\n",
    "            batch_size=batch_size,\n",
    "            target_size=target_size,\n",
    "            shuffle=shuffle,\n",
    "            augmentations=augmentations,\n",
    "        )\n",
    "    elif mode == \"TEST\":\n",
    "        generator = CustomDataGenerator(\n",
    "            directory=fold_path,\n",
    "            batch_size=batch_size,\n",
    "            target_size=target_size,\n",
    "            shuffle=False,\n",
    "            augmentations=None,\n",
    "        )\n",
    "    return generator\n",
    "\n",
    "\n",
    "train_generator = get_fold_generator(\n",
    "    \"/content/ICIAR2018_BACH_Challenge_JPG/\", mode=\"TRAIN\"\n",
    ")\n",
    "test_generator = get_fold_generator(\n",
    "    \"/content/ICIAR2018_BACH_Challenge_JPG_test/\", mode=\"TEST\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12mTiChgVZy6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get sample batch\n",
    "batch_x, batch_y = train_generator.__getitem__(0)\n",
    "batch_x1, batch_y1 = test_generator.__getitem__(0)\n",
    "\n",
    "# check data integrity\n",
    "def check(x, y):\n",
    "    print(f\"shapes: x: {x.shape}, y: {y.shape}\")\n",
    "    print(f\"norms: x: {np.min(x), np.max(x)}, y: {np.min(y), np.max(y)}\")\n",
    "    print(f\"types: x: {type(x)}, y; {type(y)}\")\n",
    "\n",
    "\n",
    "check(batch_x, batch_y)\n",
    "check(batch_x1, batch_y1)\n",
    "\n",
    "\n",
    "# display images\n",
    "def dis_gen(x, y):\n",
    "    n = len(x)\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=n, figsize=(30, 30))\n",
    "    for i in range(n):\n",
    "        axs[i].imshow(x[i])\n",
    "        axs[i].set_title(f\"Label: {y[i]}\")\n",
    "        axs[i].axis(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dis_gen(batch_x, batch_y)\n",
    "dis_gen(batch_x1, batch_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSfo1T2HVfYV"
   },
   "outputs": [],
   "source": [
    "# get the model\n",
    "# @leondgarse https://github.com/leondgarse/keras_cv_attention_model\n",
    "\n",
    "!pip install -U keras-cv-attention-models\n",
    "import keras_cv_attention_models\n",
    "import tensorflow as tf\n",
    "\n",
    "model = keras_cv_attention_models.tinyvit.TinyViT_5M(\n",
    "    input_shape=(256, 256, 3), num_classes=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDja-urXVstX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "# from tensorflow.keras.utils import array_to_image\n",
    "import csv\n",
    "from keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    TensorBoard,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Optional, Callable\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import optimizer\n",
    "\n",
    "!pip install git+https://github.com/artemmavrin/focal-loss.git\n",
    "from focal_loss import SparseCategoricalFocalLoss\n",
    "from keras.models import load_model\n",
    "\n",
    "# Define the callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"accuracy\"),\n",
    "    EarlyStopping(monitor=\"loss\", patience=2),\n",
    "    TensorBoard(log_dir=\"logs\"),\n",
    "    ReduceLROnPlateau(monitor=\"loss\", patience=1, factor=0.1),\n",
    "]\n",
    "\n",
    "# functions\n",
    "\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=4.0):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        Notice: y_pred is probability after softmax\n",
    "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
    "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
    "        Focal Loss for Dense Object Detection\n",
    "        https://arxiv.org/abs/1708.02002\n",
    "        Arguments:\n",
    "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
    "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
    "        Keyword Arguments:\n",
    "            gamma {float} -- (default: {2.0})\n",
    "            alpha {float} -- (default: {4.0})\n",
    "        Returns:\n",
    "            [tensor] -- loss.\n",
    "        \"\"\"\n",
    "        epsilon = 1.0e-9\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1.0, model_out), gamma))\n",
    "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return tf.reduce_mean(reduced_fl)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "\n",
    "# update functions\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def update_fn(p, grad, exp_avg, lr, wd, beta1, beta2):\n",
    "    # stepweight decay\n",
    "\n",
    "    p.assign(p * (1 - lr * wd))\n",
    "\n",
    "    # weight update\n",
    "\n",
    "    update = (\n",
    "        tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0] * exp_avg\n",
    "        + (1 - tf.raw_ops.LinSpace(start=1.0, stop=0.0, num=1, name=None)[0]) * grad\n",
    "    )\n",
    "    p.assign_add(tf.sign(update) * -lr)\n",
    "\n",
    "    # decay the momentum running average coefficient\n",
    "\n",
    "    exp_avg.assign(exp_avg * beta2 + grad * (1 - beta2))\n",
    "\n",
    "\n",
    "# class\n",
    "def lerp(start, end, weight):\n",
    "    return start + weight * (end - start)\n",
    "\n",
    "\n",
    "def sparse_lerp(start, end, weight):\n",
    "    # Mathematically equivalent, but you can't subtract a dense Tensor from sparse\n",
    "    # IndexedSlices, so we have to flip it around.\n",
    "    return start + weight * -(start - end)\n",
    "\n",
    "\n",
    "class Lion(optimizer.Optimizer):\n",
    "    \"\"\"Optimizer that implements the Lion algorithm.\n",
    "    Lion was published in the paper \"Symbolic Discovery of Optimization Algorithms\"\n",
    "    which is available at https://arxiv.org/abs/2302.06675\n",
    "    Args:\n",
    "      learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n",
    "        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n",
    "        that takes no arguments and returns the actual value to use. The\n",
    "        learning rate. Defaults to 1e-4.\n",
    "      beta_1: A float value or a constant float tensor, or a callable\n",
    "        that takes no arguments and returns the actual value to use. Factor\n",
    "         used to interpolate the current gradient and the momentum. Defaults to 0.9.\n",
    "      beta_2: A float value or a constant float tensor, or a callable\n",
    "        that takes no arguments and returns the actual value to use. The\n",
    "        exponential decay rate for the momentum. Defaults to 0.99.\n",
    "    Notes:\n",
    "    The sparse implementation of this algorithm (used when the gradient is an\n",
    "    IndexedSlices object, typically because of `tf.gather` or an embedding\n",
    "    lookup in the forward pass) does apply momentum to variable slices even if\n",
    "    they were not used in the forward pass (meaning they have a gradient equal\n",
    "    to zero). Momentum decay (beta2) is also applied to the entire momentum\n",
    "    accumulator. This means that the sparse behavior is equivalent to the dense\n",
    "    behavior (in contrast to some momentum implementations which ignore momentum\n",
    "    unless a variable slice was actually used).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=1e-4,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.99,\n",
    "        weight_decay=None,\n",
    "        clipnorm=None,\n",
    "        clipvalue=None,\n",
    "        global_clipnorm=None,\n",
    "        jit_compile=True,\n",
    "        name=\"Lion\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            weight_decay=weight_decay,\n",
    "            clipnorm=clipnorm,\n",
    "            clipvalue=clipvalue,\n",
    "            global_clipnorm=global_clipnorm,\n",
    "            jit_compile=jit_compile,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self._learning_rate = self._build_learning_rate(learning_rate)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "    def build(self, var_list):\n",
    "        \"\"\"Initialize optimizer variables.\n",
    "        var_list: list of model variables to build Lion variables on.\n",
    "        \"\"\"\n",
    "        super().build(var_list)\n",
    "        if hasattr(self, \"_built\") and self._built:\n",
    "            return\n",
    "        self._built = True\n",
    "        self._emas = []\n",
    "        for var in var_list:\n",
    "            self._emas.append(\n",
    "                self.add_variable_from_reference(\n",
    "                    model_variable=var, variable_name=\"ema\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def update_step(self, gradient, variable):\n",
    "        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n",
    "        lr = tf.cast(self.learning_rate, variable.dtype)\n",
    "        beta_1 = tf.constant(self.beta_1, shape=(1,))\n",
    "        beta_2 = tf.constant(self.beta_2, shape=(1,))\n",
    "\n",
    "        var_key = self._var_key(variable)\n",
    "        ema = self._emas[self._index_dict[var_key]]\n",
    "\n",
    "        if isinstance(gradient, tf.IndexedSlices):\n",
    "            # Sparse gradients.\n",
    "            lerp_fn = sparse_lerp\n",
    "        else:\n",
    "            # Dense gradients.\n",
    "            lerp_fn = lerp\n",
    "\n",
    "        update = lerp_fn(ema, gradient, 1 - beta_1)\n",
    "        update = tf.sign(update)\n",
    "        variable.assign_sub(update * lr)\n",
    "\n",
    "        ema.assign(lerp_fn(ema, gradient, 1 - beta_2))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "\n",
    "        config.update(\n",
    "            {\n",
    "                \"learning_rate\": self._serialize_hyperparameter(self._learning_rate),\n",
    "                \"beta_1\": self.beta_1,\n",
    "                \"beta_2\": self.beta_2,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "# train the model\n",
    "model.compile(\n",
    "    optimizer=Lion(learning_rate=6e-6),\n",
    "    loss=focal_loss(),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        f1_m,\n",
    "        precision_m,\n",
    "        recall_m,\n",
    "        tf.keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "    ],\n",
    ")\n",
    "history = model.fit(train_generator, epochs=70, callbacks=callbacks)\n",
    "model.save(\"tumor_model.h5\")\n",
    "evals = model.evaluate(test_generator)\n",
    "\n",
    "\n",
    "def save_eval_results(eval_results, filename):\n",
    "    # Open the file in write mode and write the evaluation results to it\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(model.metrics_names)\n",
    "        writer.writerow(eval_results)\n",
    "\n",
    "\n",
    "# plot the training history as a graph\n",
    "def plot_history(history, call=None):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(history.history), figsize=(20, 5))\n",
    "\n",
    "    for i, metric in enumerate(history.history.keys()):\n",
    "        axs[i].plot(history.history[metric])\n",
    "        axs[i].set_title(metric)\n",
    "        axs[i].set_xlabel(\"Epoch\")\n",
    "        axs[i].set_ylabel(metric)\n",
    "    plt.savefig(f\"{str(history)}_{call}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_m(model_name):\n",
    "    model = load_model(\n",
    "        model_name,\n",
    "        custom_objects={\n",
    "            \"focal_loss_fixed\": focal_loss,\n",
    "            \"Lion\": Lion,\n",
    "            \"f1_m\": f1_m,\n",
    "            \"precision_m\": precision_m,\n",
    "            \"recall_m\": recall_m,\n",
    "        },\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def quick_test(test_generator, model, img_size):\n",
    "    # Get a batch of test data\n",
    "    batch_x, batch_y = test_generator.__getitem__(0)\n",
    "\n",
    "    # Generate predictions for the test data\n",
    "    pred_y = model.predict(batch_x)\n",
    "\n",
    "    # Create a pred folder if it doesn't exist\n",
    "    if not os.path.exists(\"pred\"):\n",
    "        os.makedirs(\"pred\")\n",
    "\n",
    "    # Loop through the test data and save each image and its predicted label to the pred folder\n",
    "    for i in range(batch_x.shape[0]):\n",
    "        # Convert the image array to a PIL image\n",
    "        img = array_to_img(batch_x[i])\n",
    "\n",
    "        # Get the predicted label for the image\n",
    "        pred_label = np.argmax(pred_y[i])\n",
    "\n",
    "        # Save the image with its predicted label as the filename\n",
    "        img.save(f\"pred/{pred_label}_{i}.jpg\")\n",
    "\n",
    "# load already trained model\n",
    "best_model = load_m(\"/content/best_model.h5\")\n",
    "best_model.compile(\n",
    "    optimizer=Lion(learning_rate=1e-4, weight_decay=1e-5),\n",
    "    loss=focal_loss(),\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        f1_m,\n",
    "        precision_m,\n",
    "        recall_m,\n",
    "        tf.keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "    ],\n",
    ")\n",
    "save_eval_results(evals, \"pannuke_results\")\n",
    "plot_history(history)\n",
    "quick_test(test_generator, model, (256, 256))\n",
    "quick_test(test_generator, best_model, (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bux4KwvVWE--"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# move the models to Google Drive\n",
    "shutil.move(\"/content/best_model.h5\", \"/content/drive/MyDrive/tumor_transformer_b.h5\")\n",
    "shutil.move(\"/content/tumor_model.h5\", \"/content/drive/MyDrive/tumor_transformer.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

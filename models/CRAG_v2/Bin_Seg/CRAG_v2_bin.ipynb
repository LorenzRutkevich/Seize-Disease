{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uult9c2ji1D1"
   },
   "outputs": [],
   "source": [
    "# model architecture to use\n",
    "ARCHITECTURE = \"HYSTO_SEG\"\n",
    "assert ARCHITECTURE in [\"HYSTO_SEG\", \"VITAE_V2\", \"VITAE_V2_OCR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwADgQvfaiyh",
    "outputId": "542fb3e6-0755-475a-a187-22bb7d03ba97"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "# mount google drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3O08-K2af2g",
    "outputId": "e5f7111a-3312-4f06-cdfd-8d0debcb2aea"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "# %%capture # uncomment to mute unzip\n",
    "!unzip /content/drive/MyDrive/CRAG.zip\n",
    "#!unzip /content/drive/MyDrive/valid_ori_crag.zip -d /content/valid_ori_crag/\n",
    "if ARCHITECTURE == \"VITAE_V2\":\n",
    "    !unzip /content/drive/MyDrive/vitae_v2_sem_seg.zip\n",
    "elif ARCHITECTURE == \"VITAE_V2_OCR\":\n",
    "    !unzip /content/drive/MyDrive/vitae_v2_sem_seg_ocr.zip\n",
    "elif ARCHITECTURE == \"HYSTO_SEG\":\n",
    "    !unzip /content/drive/MyDrive/histo_seg_pt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wbp0MTQGj8Ah",
    "outputId": "94c1caa3-55dd-4ecb-ebac-e061d3a492ce"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# cuda and torch version\n",
    "versions = torch.__version__\n",
    "parts = versions.split(\"+\")\n",
    "version = parts[0].strip()\n",
    "cuda_version = parts[1].strip()\n",
    "print(version, cuda_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWPZ5CTZcJTG",
    "outputId": "574dc4b3-bfcc-4f59-c1fd-b9370b6dab3c"
   },
   "outputs": [],
   "source": [
    "# check libraries\n",
    "\n",
    "missing_libraries = []\n",
    "try:\n",
    "    import albumentations as A\n",
    "except ImportError:\n",
    "    missing_libraries.append(\"albumentations\")\n",
    "try:\n",
    "    from thop import profile\n",
    "except ImportError:\n",
    "    missing_libraries.append(\"thop\")\n",
    "if ARCHITECTURE == \"VITAE_V2\" or ARCHITECTURE == \"VITAE_V2_OCR\":\n",
    "    try:\n",
    "        from functools import partial\n",
    "    except ImportError:\n",
    "        missing_libraries.append(\"functools\")\n",
    "    try:\n",
    "        from timm.models.layers import trunc_normal_\n",
    "\n",
    "        # from vitae_v2_sem_seg.vitaev2 import ViTAEv2, CustomSegmentationHead\n",
    "        from vitae_v2_sem_seg_ocr.vitaev2 import ViTAEv2_OCR\n",
    "    except ImportError:\n",
    "        missing_libraries.append(\"timm\")\n",
    "    try:\n",
    "        from einops import rearrange\n",
    "    except ImportError:\n",
    "        missing_libraries.append(\"einops\")\n",
    "    try:\n",
    "        from mmcv.cnn import ConvModule\n",
    "    except ImportError:\n",
    "        missing_libraries.append(\"mmcv-full\")\n",
    "elif ARCHITECTURE == \"HISTO_SEG\":\n",
    "    pass\n",
    "\n",
    "# install missing libraries if any\n",
    "if missing_libraries:\n",
    "    print(\"The following libraries are missing: \" + \", \".join(missing_libraries))\n",
    "    print(\"Installing missing libraries...\")\n",
    "    if \"timm\" in missing_libraries:\n",
    "        !pip install timm\n",
    "        import timm\n",
    "        from timm.models.layers import trunc_normal_\n",
    "    if \"functools\" in missing_libraries:\n",
    "        !pip install functools\n",
    "        from functools import partial\n",
    "    if \"albumentations\" in missing_libraries:\n",
    "        !pip install albumentations\n",
    "        import albumentations as A\n",
    "    if \"einops\" in missing_libraries:\n",
    "        !pip install einops\n",
    "        from einops import rearrange\n",
    "    if \"mmcv-full\" in missing_libraries:\n",
    "        !pip install openmim -U\n",
    "        #!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/{cuda_vesion}/{version}/index.html\n",
    "        !mim install mmcv\n",
    "        from mmcv.cnn import ConvModule\n",
    "    if \"thop\" in missing_libraries:\n",
    "        !pip install thop\n",
    "        from thop import profile\n",
    "try:\n",
    "    if ARCHITECTURE == \"VITAE_V2\":\n",
    "        from vitae_v2_sem_seg.vitaev2 import ViTAEv2, CustomSegmentationHead\n",
    "    elif ARCHITECTURE == \"VITAE_V2_OCR\":\n",
    "        from vitae_v2_sem_seg_ocr.vitaev2 import ViTAEv2_OCR as seg_model\n",
    "    elif ARCHITECTURE == \"HYSTO_SEG\":\n",
    "        from histo_seg_pt.histo_seg_pytorch import HistoSeg_ as seg_model\n",
    "except ImportError:\n",
    "    raise Exception(\"Could not import model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LtYmx5jRaZxV",
    "outputId": "21695208-bcd5-4379-d235-438fc9a53d9f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "paths = {\n",
    "    \"train_x\": \"/content/CRAG/train/Images\",\n",
    "    \"train_y\": \"/content/CRAG/train/Annotation\",\n",
    "    \"test_x\": \"/content/CRAG/test/Images\",\n",
    "    \"test_y\": \"/content/CRAG/test/Annotation\",\n",
    "}\n",
    "\n",
    "\"\"\" test_original = {\n",
    "    'test_x': '/content/valid_ori_crag/Images_ori',\n",
    "    'test_y': '/content/valid_ori_crag/Annotation_ori'\n",
    "} \"\"\"\n",
    "\n",
    "# data generator class following pytorch's Dataset class\n",
    "class DataGen(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, paths, train=True, info=True, target_size=(256, 256), task=\"bin\"\n",
    "    ):\n",
    "        assert task in [\"bin\", \"inst\"], \"Task must be one of ['bin', 'inst']\"\n",
    "        self.task = task\n",
    "        self.paths = paths\n",
    "        self.train = train\n",
    "        self.info = info\n",
    "        self.x = (\n",
    "            self._get_image_paths(self.paths[\"train_x\"])\n",
    "            if self.train\n",
    "            else self._get_image_paths(self.paths[\"test_x\"])\n",
    "        )\n",
    "        self.y = (\n",
    "            self._get_image_paths(self.paths[\"train_y\"])\n",
    "            if self.train\n",
    "            else self._get_image_paths(self.paths[\"test_y\"])\n",
    "        )\n",
    "        self.len = len(self.x)\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def _get_image_paths(self, directory):\n",
    "        image_paths = []\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "                image_paths.append(os.path.join(directory, filename))\n",
    "        print(f\"Found {len(image_paths)} images in {directory}\") if self.info else None\n",
    "        return image_paths\n",
    "\n",
    "    def _encode_mask(self, mask, task=\"bin\"):\n",
    "        assert task in [\"bin\", \"inst\"], \"task must be one of ['bin', 'inst']\"\n",
    "        if task == \"bin\":\n",
    "            mask[mask > 0] = 255\n",
    "            encoded_mask = mask\n",
    "        elif task == \"inst\":\n",
    "            unique_labels = np.unique(mask)\n",
    "            encoded_mask = np.zeros_like(mask)\n",
    "            for idx, label in enumerate(unique_labels):\n",
    "                if label == 0:  # Skip the background\n",
    "                    continue\n",
    "                encoded_mask[mask == label] = idx\n",
    "        return encoded_mask.astype(np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.x[idx], cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, self.target_size)\n",
    "        mask = (\n",
    "            cv2.imread(self.y[idx], cv2.IMREAD_GRAYSCALE)\n",
    "            if self.task == \"bin\"\n",
    "            else cv2.imread(self.y[idx], cv2.IMREAD_COLOR)\n",
    "        )\n",
    "        mask = cv2.resize(mask, self.target_size)\n",
    "        encoded_mask = self._encode_mask(mask, task=self.task)\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        mask = torch.tensor(\n",
    "            encoded_mask, dtype=torch.int64\n",
    "        )  # Create the mask as an integer tensor\n",
    "        image = image.permute(\n",
    "            2, 0, 1\n",
    "        )  # Permute dimensions to (channels, height, width)\n",
    "        mask = mask.unsqueeze(0)  # Add a channel dimension for the mask\n",
    "        image = image / 255.0\n",
    "        mask = mask / (np.max(encoded_mask) + 1)  # Normalize the mask labels\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "train_dataset = DataGen(paths, train=True)\n",
    "test_dataset = DataGen(paths, train=False)\n",
    "\n",
    "# display test images and masks\n",
    "def display_image_mask(image, mask):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(mask, cmap=\"jet\")\n",
    "    axes[1].set_title(\"Mask\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# check data integrity\n",
    "for i in range(1):\n",
    "    image, mask = train_dataset[random.randint(0, len(train_dataset) - 1)]\n",
    "    print(f\"Image shape: {image.shape}, Min: {image.min()}, Max: {image.max()}\")\n",
    "    print(\n",
    "        f\"Mask shape: {mask.shape}, Min: {mask.min()}, Max: {mask.max()}, Classes: {len(np.unique(mask))}\"\n",
    "    )\n",
    "    display_image_mask(image.permute(1, 2, 0).numpy(), mask.squeeze().numpy())\n",
    "\n",
    "for i in range(1):\n",
    "    image, mask = test_dataset[random.randint(0, len(test_dataset) - 1)]\n",
    "    print(f\"Image shape: {image.shape}, Min: {image.min()}, Max: {image.max()}\")\n",
    "    print(\n",
    "        f\"Mask shape: {mask.shape}, Min: {mask.min()}, Max: {mask.max()}, Classes: {len(np.unique(mask))}\"\n",
    "    )\n",
    "    display_image_mask(image.permute(1, 2, 0).numpy(), mask.squeeze().numpy())\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "gen_params_train = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 0,\n",
    "}\n",
    "\n",
    "gen_params_test = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 0,\n",
    "}\n",
    "\n",
    "# create data generators\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, **gen_params_train)\n",
    "test_generator = torch.utils.data.DataLoader(test_dataset, **gen_params_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYpkPWDBaZxZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Lion(Optimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr: float = 1e-4,\n",
    "        betas: tuple = (0.9, 0.99),\n",
    "        weight_decay: float = 0.0,\n",
    "    ):\n",
    "        assert lr > 0.0\n",
    "        assert all([0.0 <= beta <= 1.0 for beta in betas])\n",
    "        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in filter(lambda p: p.grad is not None, group[\"params\"]):\n",
    "                # parameter\n",
    "                grad, lr, wd, beta1, beta2, state = (\n",
    "                    p.grad,\n",
    "                    group[\"lr\"],\n",
    "                    group[\"weight_decay\"],\n",
    "                    *group[\"betas\"],\n",
    "                    self.state[p],\n",
    "                )\n",
    "                if len(state) == 0:\n",
    "                    state[\"exp_avg\"] = torch.zeros_like(p)\n",
    "                exp_avg = state[\"exp_avg\"]\n",
    "\n",
    "                # Lion optimizer\n",
    "                p.data.mul_(1 - lr * wd)\n",
    "                update = exp_avg.clone().lerp_(grad, 1 - beta1)\n",
    "                p.add_(torch.sign(update), alpha=-lr)\n",
    "                exp_avg.lerp_(grad, 1 - beta2)\n",
    "        return loss\n",
    "\n",
    "# metrics\n",
    "# value methods are used to get the value of the metric after each epoch\n",
    "# for the training loop\n",
    "class DiceCoef:\n",
    "    def __init__(self) -> None:\n",
    "        self._value = None\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_true_f = y_true.flatten()\n",
    "        y_pred_f = y_pred.flatten()\n",
    "        intersection = torch.sum(y_true_f * y_pred_f)\n",
    "        smooth = 0.0001\n",
    "        self._value = (2.0 * intersection + smooth) / (\n",
    "            torch.sum(y_true_f) + torch.sum(y_pred_f) + smooth\n",
    "        )\n",
    "        return self._value\n",
    "\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "\n",
    "class Recall:\n",
    "    def __init__(self) -> None:\n",
    "        self._value = None\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_true_f = y_true.flatten()\n",
    "        y_pred_f = y_pred.flatten()\n",
    "        intersection = torch.sum(y_true_f * y_pred_f)\n",
    "        smooth = 0.0001\n",
    "        self._value = (intersection + smooth) / (torch.sum(y_true_f) + smooth)\n",
    "        return self._value\n",
    "\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "\n",
    "class Precision:\n",
    "    def __init__(self) -> None:\n",
    "        self._value = None\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_true_f = y_true.flatten()\n",
    "        y_pred_f = y_pred.flatten()\n",
    "        intersection = torch.sum(y_true_f * y_pred_f)\n",
    "        smooth = 0.0001\n",
    "        self._value = (intersection + smooth) / (torch.sum(y_pred_f) + smooth)\n",
    "        return self._value\n",
    "\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "\n",
    "class PrecisionTorchMetrics:\n",
    "    def __init__(self) -> None:\n",
    "        self._value = None\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        y_pred_f = y_pred.flatten()\n",
    "        y_true_f = y_true.flatten()\n",
    "        self._value = torchmetrics.Precision(task=\"binary\")(y_pred_f, y_true_f)\n",
    "        return self._value\n",
    "\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "\n",
    "class F1Score:\n",
    "    def __init__(self) -> None:\n",
    "        self._value = None\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_true_f = y_true.flatten()\n",
    "        y_pred_f = y_pred.flatten()\n",
    "        intersection = torch.sum(y_true_f * y_pred_f)\n",
    "        smooth = 0.0001\n",
    "        precision = (intersection + smooth) / (torch.sum(y_pred_f) + smooth)\n",
    "        recall = (intersection + smooth) / (torch.sum(y_true_f) + smooth)\n",
    "        self._value = 2 * (precision * recall) / (precision + recall)\n",
    "        return self._value\n",
    "\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "\n",
    "class DiceScore:\n",
    "    def __init__(self) -> None:\n",
    "        self._value = None\n",
    "\n",
    "    def __call__(self, y_true, y_pred, ignore_index=None):\n",
    "        smooth = 1.0\n",
    "        y_true_f = y_true.clone().view(-1)\n",
    "        y_pred_f = y_pred.clone().view(-1)\n",
    "        if ignore_index is not None:\n",
    "            mask = y_true_f == ignore_index\n",
    "            y_true_f[mask] = 0\n",
    "            y_pred_f[mask] = 0\n",
    "        intersection = torch.sum(y_true_f * y_pred_f)\n",
    "        self._value = (2.0 * intersection + smooth) / (\n",
    "            torch.sum(y_true_f) + torch.sum(y_pred_f) + smooth\n",
    "        )\n",
    "        return self._value\n",
    "\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = F.sigmoid(inputs)\n",
    "\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.0 * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "# combination loss out of dice loss and binary cross entropy loss\n",
    "# loss is weighted by counter_weight\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, counter_weight) -> None:\n",
    "        super().__init__()\n",
    "        self.counter_weight = counter_weight\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.bce_loss = nn.BCELoss()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        dice_loss = self.dice_loss(outputs, targets)\n",
    "        bce_loss = self.bce_loss(outputs, targets)\n",
    "        return dice_loss + self.counter_weight * bce_loss\n",
    "\n",
    "# print model information\n",
    "def test_model_(model):\n",
    "    dummy_shape = (\n",
    "        gen_params_train[\"batch_size\"],\n",
    "        model.in_channels,\n",
    "        model.img_size,\n",
    "        model.img_size,\n",
    "    )\n",
    "    dummy = torch.randn(dummy_shape)\n",
    "    out = model(dummy)\n",
    "    print(f\"Output Shape: {out.shape}\")\n",
    "    flops, params = profile(model, inputs=(dummy,))\n",
    "    print(f\"Output Shape: {out.shape}\")\n",
    "    print(f\"Min: {torch.min(out)}, Max: {torch.max(out)}\")\n",
    "    print(f\"Flops: {flops}, Params: {params} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftepRvkIaZxa",
    "outputId": "0a102acb-c19f-4589-8280-3eb7faadf884"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "# write metrics to csv file\n",
    "def write_to_csv(\n",
    "    loss,\n",
    "    metrics,\n",
    "    epoch,\n",
    "    header_written=False,\n",
    "    filename: str = f\"train_{datetime.date.today()}.csv\",\n",
    "):\n",
    "    with open(filename, \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not header_written:\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    \"epoch\",\n",
    "                    \"loss\",\n",
    "                    \"dice_coef\",\n",
    "                    \"f1\",\n",
    "                    \"recall\",\n",
    "                    \"precision\",\n",
    "                    \"dice_score\",\n",
    "                ]\n",
    "            )\n",
    "            header_written = True\n",
    "        writer.writerow(\n",
    "            [\n",
    "                epoch + 1,\n",
    "                loss,\n",
    "                metrics[\"dice_coef\"],\n",
    "                metrics[\"f1\"],\n",
    "                metrics[\"recall\"],\n",
    "                metrics[\"precision\"],\n",
    "                metrics[\"dice_score\"],\n",
    "            ]\n",
    "        )\n",
    "    return header_written\n",
    "\n",
    "# training loop\n",
    "def train_step(\n",
    "    model,\n",
    "    train_generator,\n",
    "    metrics,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    save_path=\"model_epoch_\",\n",
    "    epochs: int = 10,\n",
    "    save: bool = False,\n",
    "    test_after_epoch: bool = False,\n",
    "    test_generator=None,\n",
    "    load_saved_model: bool = False,\n",
    "    saved_model_path: str = None,\n",
    "):\n",
    "    if load_saved_model:\n",
    "        model.load_state_dict(torch.load(saved_model_path))\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    start = time.time()\n",
    "    num_batches = len(train_generator)\n",
    "    loss_checker = []\n",
    "    loss_down = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        batch = 0\n",
    "        total_loss_epoch = 0\n",
    "        total_samples_epoch = 0\n",
    "        average_metrics = []\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\\n-------------------------------\")\n",
    "        for x, y in train_generator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch += 1\n",
    "            if len(loss_checker) > 1:\n",
    "                if loss_down < 6:\n",
    "                    if loss_checker[-1] > loss_checker[-2]:\n",
    "                        print(\n",
    "                            f\"Loss increased from {loss_checker[-2]} to {loss_checker[-1]}\\n\",\n",
    "                            end=\"\",\n",
    "                            flush=True,\n",
    "                        )\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group[\"lr\"] = param_group[\"lr\"] * 0.1\n",
    "                            param_group[\"weight_decay\"] = (\n",
    "                                param_group[\"weight_decay\"] * 0.1\n",
    "                            )\n",
    "                        loss_down += 1\n",
    "                else:\n",
    "                    raise Exception(\"Loss increased too many times\")\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs, y)\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "            total_loss_epoch += loss.item() * batch_size\n",
    "            total_samples_epoch += batch_size\n",
    "\n",
    "            for metric in metrics.values():\n",
    "                metric(outputs, y)\n",
    "\n",
    "            avg_loss = total_loss / total_samples\n",
    "            avg_loss_epoch = total_loss_epoch / total_samples_epoch\n",
    "            metric_values = {\n",
    "                metric_name: metric.value().item()\n",
    "                for metric_name, metric in metrics.items()\n",
    "            }\n",
    "            metric_values = {\n",
    "                metric_name: round(metric_value, 4)\n",
    "                for metric_name, metric_value in metric_values.items()\n",
    "            }\n",
    "            average_metrics.append(metric_values)\n",
    "\n",
    "            current_time = time.time()\n",
    "            elapsed_time = current_time - start\n",
    "            avg_time_per_batch = elapsed_time / batch\n",
    "            remainig_batches = num_batches - batch\n",
    "            remaining_time = remainig_batches * avg_time_per_batch\n",
    "            print(\n",
    "                f\"\\r Batch [{batch}/{num_batches}] Loss: {avg_loss:.4f} Metrics: {metric_values} Elapsed Time: {elapsed_time:.2f}s/{elapsed_time/60:.2f}m Remaining Time (epoch): {remaining_time:.2f}s/{remaining_time/60:.2f}m\",\n",
    "                flush=True,\n",
    "                end=\" \",\n",
    "            )\n",
    "            header_written = write_to_csv(\n",
    "                avg_loss, metric_values, epoch, header_written if batch > 1 else False\n",
    "            )\n",
    "\n",
    "        avg_loss = total_loss / total_samples\n",
    "        avg_loss_epoch = total_loss_epoch / total_samples_epoch\n",
    "        print(avg_loss)\n",
    "        avg_metrics = {\n",
    "            metric_name: sum([metric[metric_name] for metric in average_metrics])\n",
    "            / len(average_metrics)\n",
    "            for metric_name in average_metrics[0].keys()\n",
    "        }\n",
    "        avg_metrics = {\n",
    "            metric_name: round(metric_value, 4)\n",
    "            for metric_name, metric_value in avg_metrics.items()\n",
    "        }\n",
    "        loss_checker.append(avg_loss)\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} finished. \\n Avg Loss: {avg_loss_epoch:.4f} Avg Metrics: {avg_metrics}\"\n",
    "        )\n",
    "        if save:\n",
    "            torch.save(model.state_dict(), f\"{save_path}{epoch + 1}.pth\")\n",
    "            print(f\"Model state dict saved at {save_path}{epoch + 1}.pth\")\n",
    "            torch.save(model, f\"{save_path}{epoch + 1}_cm.pth\")\n",
    "            print(f\"Complete model saved at {save_path}{epoch + 1}_cm.pth\")\n",
    "\n",
    "        # using test_step to test after each epoch\n",
    "        if test_after_epoch:\n",
    "            test_step(model, test_generator, metrics, loss_fn, device)\n",
    "\n",
    "\n",
    "def test_step(\n",
    "    model,\n",
    "    test_generator,\n",
    "    metrics,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    load_saved_model: bool = False,\n",
    "    saved_model_path: str = None,\n",
    "):\n",
    "    if load_saved_model:\n",
    "        model.load_state_dict(torch.load(saved_model_path))\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    avg_metrics = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_generator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs, y)\n",
    "            batch_size = x.size(0)\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            for metric in metrics.values():\n",
    "                metric(outputs, y)\n",
    "\n",
    "            metric_values = {\n",
    "                metric_name: metric.value().item()\n",
    "                for metric_name, metric in metrics.items()\n",
    "            }\n",
    "            metric_values = {\n",
    "                metric_name: round(metric_value, 4)\n",
    "                for metric_name, metric_value in metric_values.items()\n",
    "            }\n",
    "            avg_metrics.append(metric_values)\n",
    "\n",
    "    avg_metrics = {\n",
    "        metric_name: sum([metric[metric_name] for metric in avg_metrics])\n",
    "        / len(avg_metrics)\n",
    "        for metric_name in avg_metrics[0].keys()\n",
    "    }\n",
    "    avg_metrics = {\n",
    "        metric_name: round(metric_value, 4)\n",
    "        for metric_name, metric_value in avg_metrics.items()\n",
    "    }\n",
    "    avg_loss = total_loss / total_samples\n",
    "    print(f\"Test - Avg Loss (Batch): {avg_loss:.4f} Avg Metrics: {avg_metrics}\")\n",
    "    write_to_csv(\n",
    "        avg_loss,\n",
    "        metric_values,\n",
    "        0,\n",
    "        header_written=False,\n",
    "        filename=f\"test_{datetime.date.today()}.csv\",\n",
    "    )\n",
    "\n",
    "# initialize metrics\n",
    "dice_coef = DiceCoef()\n",
    "f1 = F1Score()\n",
    "recall = Recall()\n",
    "precision = Precision()\n",
    "dice_score = DiceScore()\n",
    "\n",
    "# metric library\n",
    "metrics = {\n",
    "    \"dice_coef\": dice_coef,\n",
    "    \"f1\": f1,\n",
    "    \"recall\": recall,\n",
    "    \"precision\": precision,\n",
    "    \"dice_score\": dice_score,  # same as dice_coef because of binary segmentation\n",
    "}\n",
    "\n",
    "\n",
    "model = seg_model(backbone=\"xception\")\n",
    "\n",
    "# test_model_(seg_model)\n",
    "\n",
    "\n",
    "optimizer = Lion(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "# loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss_fn = CombinedLoss(counter_weight=0.5) # 0.5 is the counter weight, meaning same importance for both losses\n",
    "num_epochs = 20\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "train_step(\n",
    "    model,\n",
    "    train_generator,\n",
    "    metrics,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    save=True,\n",
    "    save_path=\"model_epoch_\",\n",
    "    epochs=num_epochs,\n",
    "    test_after_epoch=True,\n",
    "    test_generator=test_generator,\n",
    ")\n",
    "# test_step(model, test_data, metrics, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "3oBGcgrYTpY8",
    "outputId": "5a367f4b-f658-492b-dfe0-b126531cce67"
   },
   "outputs": [],
   "source": [
    "# test already trained model\n",
    "model_path = \"/content/model_epoch_19.pth\"\n",
    "model = seg_model(dropout_ratio=0.1).to(\"cuda\")\n",
    "test_step(\n",
    "    model,\n",
    "    test_generator,\n",
    "    metrics,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    load_saved_model=True,\n",
    "    saved_model_path=model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zB963szwvc4"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# copy model to google drive\n",
    "shutil.copy(\n",
    "    \"/content/model_epoch_19_cm.pth\", \"/content/drive/MyDrive/vitaeocr_eppch_19_cm.pth\"\n",
    ")\n",
    "shutil.copy(\n",
    "    \"/content/model_epoch_19.pth\",\n",
    "    \"/content/drive/MyDrive/vitaeocr_eppch_19_cm_dict.pth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

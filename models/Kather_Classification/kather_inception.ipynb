{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20395,
     "status": "ok",
     "timestamp": 1681059259020,
     "user": {
      "displayName": "Lorenzo",
      "userId": "06748019083251351709"
     },
     "user_tz": -120
    },
    "id": "wr-eBvNPYu0X",
    "outputId": "8a97db1e-108a-4e0f-fccb-58d11276bc2a"
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "!wget https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip?download=1\n",
    "!unzip '/content/Kather_texture_2016_image_tiles_5000.zip?download=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9q1qknr1_AE"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# evaluation metrics for classification\n",
    "def auc(y_true, y_pred):\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "    y_pred = y_pred[:, 1:]\n",
    "\n",
    "    auc_scores = []\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        auc_scores.append(roc_auc_score(y_true, y_pred[:, i]))\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def dice_score(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "\n",
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1, 2))\n",
    "    sum_ = tf.reduce_sum(y_true + y_pred, axis=(1, 2))\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    jd = (1 - jac) * smooth\n",
    "    return tf.reduce_mean(jd)\n",
    "\n",
    "\n",
    "def tf_mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.5):\n",
    "        y_pred_ = tf.cast(y_pred > t, tf.int32)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        prec.append(score)\n",
    "    val = K.mean(K.stack(prec), axis=0)\n",
    "    return [val, up_opt]\n",
    "\n",
    "\n",
    "def cross_entropy_balanced(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "    count_neg = tf.reduce_sum(1.0 - y_true)\n",
    "    count_pos = tf.reduce_sum(y_true)\n",
    "\n",
    "    beta = count_neg / (count_pos + count_neg)\n",
    "\n",
    "    pos_weight = beta / (1 - beta)\n",
    "\n",
    "    cost = tf.nn.weighted_cross_entropy_with_logits(\n",
    "        logits=y_pred, labels=y_true, pos_weight=pos_weight\n",
    "    )\n",
    "\n",
    "    cost = tf.reduce_mean(cost * (1 - beta))\n",
    "\n",
    "    return tf.where(tf.equal(count_pos, 0.0), 0.0, cost)\n",
    "\n",
    "\n",
    "def pixel_error(y_true, y_pred):\n",
    "    pred = tf.cast(tf.greater(y_pred, 0.5), tf.int32)\n",
    "    error = tf.cast(tf.not_equal(pred, tf.cast(y_true, tf.int32)), tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCOI-lEe8l3p"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    load_img,\n",
    "    img_to_array,\n",
    ")\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "MODE = \"MORE\"\n",
    "if not MODE in [\"NORMAL\", \"MORE\", \"FOLD\"]:\n",
    "    raise Exception(f\"MODE needs to be NORMAL, MORE or FOLD not {MODE}\")\n",
    "\n",
    "\"\"\"\n",
    "MORE: augment the data\n",
    "FOLD: split the data into folds\n",
    "NORMAL: split into test and train and nothing els\n",
    "\"\"\"\n",
    "\n",
    "dataset_path = \"/content/Kather_texture_2016_image_tiles_5000\"\n",
    "train_test_path = \"/content/train_test_folder\"\n",
    "train_ratio = 0.8 # Ratio of train images to total images\n",
    "train_aug_factor = 1 # Factor by which train images are augmented\n",
    "\n",
    "train_path = os.path.join(train_test_path, \"train_aug\")\n",
    "test_path = os.path.join(train_test_path, \"test\")\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "\n",
    "if MODE == \"NORMAL\":\n",
    "    # Loop through each class folder in the dataset\n",
    "    for class_folder in os.listdir(dataset_path):\n",
    "        class_folder_path = os.path.join(dataset_path, class_folder)\n",
    "\n",
    "        # Get the list of images in the class folder\n",
    "        images_list = os.listdir(class_folder_path)\n",
    "\n",
    "        # Shuffle the images randomly\n",
    "        random.shuffle(images_list)\n",
    "\n",
    "        # Split the images into train and test based on the train_ratio\n",
    "        train_images_list = images_list[: int(len(images_list) * train_ratio)]\n",
    "        test_images_list = images_list[int(len(images_list) * train_ratio) :]\n",
    "\n",
    "        # Create a separate directory for each class within the train and test directories\n",
    "        train_class_path = os.path.join(train_path, class_folder)\n",
    "        test_class_path = os.path.join(test_path, class_folder)\n",
    "        os.makedirs(train_class_path, exist_ok=True)\n",
    "        os.makedirs(test_class_path, exist_ok=True)\n",
    "\n",
    "        # Copy the train images to the train class directory\n",
    "        for train_image in train_images_list:\n",
    "            train_image_path = os.path.join(class_folder_path, train_image)\n",
    "            train_image_dest_path = os.path.join(train_class_path, train_image)\n",
    "            shutil.copy(train_image_path, train_image_dest_path)\n",
    "\n",
    "        # Copy the test images to the test class directory\n",
    "        for test_image in test_images_list:\n",
    "            test_image_path = os.path.join(class_folder_path, test_image)\n",
    "            test_image_dest_path = os.path.join(test_class_path, test_image)\n",
    "            shutil.copy(test_image_path, test_image_dest_path)\n",
    "\n",
    "elif MODE == \"MORE\":\n",
    "    import math\n",
    "\n",
    "    dataset_path = \"/content/Kather_texture_2016_image_tiles_5000\"\n",
    "    train_test_path = \"/content/train_test_folder\"\n",
    "    train_ratio = 0.7\n",
    "    test_ratio = 0.3\n",
    "\n",
    "    train_path = os.path.join(train_test_path, \"train_aug\")\n",
    "    test_path = os.path.join(train_test_path, \"test\")\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"reflect\",\n",
    "    )\n",
    "\n",
    "    for class_folder in os.listdir(dataset_path):\n",
    "        class_folder_path = os.path.join(dataset_path, class_folder)\n",
    "        images_list = os.listdir(class_folder_path)\n",
    "        random.shuffle(images_list)\n",
    "\n",
    "        num_test_images = math.ceil(len(images_list) * test_ratio)\n",
    "        num_train_images = len(images_list) - num_test_images\n",
    "\n",
    "        test_images_list = random.sample(images_list, num_test_images)\n",
    "        train_images_list = list(set(images_list) - set(test_images_list))\n",
    "\n",
    "        train_class_path = os.path.join(train_path, class_folder)\n",
    "        test_class_path = os.path.join(test_path, class_folder)\n",
    "        os.makedirs(train_class_path, exist_ok=True)\n",
    "        os.makedirs(test_class_path, exist_ok=True)\n",
    "\n",
    "        # Copy original train images to train_aug directory\n",
    "        for train_image in train_images_list:\n",
    "            train_image_path = os.path.join(class_folder_path, train_image)\n",
    "            train_image_dest_path = os.path.join(train_class_path, train_image)\n",
    "            shutil.copy(train_image_path, train_image_dest_path)\n",
    "\n",
    "        # Generate and copy augmented train images to train_aug directory\n",
    "        for train_image in train_images_list:\n",
    "            train_image_path = os.path.join(class_folder_path, train_image)\n",
    "            train_image_name, train_image_ext = os.path.splitext(\n",
    "                train_image\n",
    "            )  # Split filename and extension\n",
    "            for i in range(train_aug_factor):\n",
    "                train_image_copy_path = os.path.join(\n",
    "                    train_class_path, f\"{train_image_name}_copy_{i}{train_image_ext}\"\n",
    "                )  # Add extension to new filename\n",
    "                shutil.copy(train_image_path, train_image_copy_path)\n",
    "                train_image_copy = img_to_array(load_img(train_image_copy_path))\n",
    "                train_image_copy = train_datagen.random_transform(train_image_copy)\n",
    "                train_image_copy = train_image_copy.astype(\"uint8\")\n",
    "                train_image_copy = Image.fromarray(train_image_copy)\n",
    "                train_image_copy.save(train_image_copy_path)\n",
    "\n",
    "        # Copy original test images to test directory\n",
    "        for test_image in test_images_list:\n",
    "            test_image_path = os.path.join(class_folder_path, test_image)\n",
    "            test_image_dest_path = os.path.join(test_class_path, test_image)\n",
    "            shutil.copy(test_image_path, test_image_dest_path)\n",
    "\n",
    "elif MODE == \"FOLD\":\n",
    "    dataset_path = \"/content/Kather_texture_2016_image_tiles_5000\"\n",
    "    output_path = \"/content/folds\"\n",
    "    n_folds = 5\n",
    "\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Define data generator for image augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"reflect\",\n",
    "    )\n",
    "\n",
    "    # Get list of all image files\n",
    "    image_files = []\n",
    "    for class_folder in os.listdir(dataset_path):\n",
    "        class_folder_path = os.path.join(dataset_path, class_folder)\n",
    "        images_list = os.listdir(class_folder_path)\n",
    "        for image_name in images_list:\n",
    "            image_path = os.path.join(class_folder_path, image_name)\n",
    "            image_files.append((image_path, class_folder))\n",
    "\n",
    "    # Shuffle the image files list\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Create KFold splitter\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "\n",
    "    # Split the dataset into n_folds\n",
    "    fold_idx = 1\n",
    "    for train_index, test_index in kf.split(image_files):\n",
    "        # Create output directories for this fold\n",
    "        train_path = os.path.join(output_path, f\"fold_{fold_idx}\", \"train\")\n",
    "        test_path = os.path.join(output_path, f\"fold_{fold_idx}\", \"test\")\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "        os.makedirs(test_path, exist_ok=True)\n",
    "\n",
    "        # Copy train images to output directory and augment them\n",
    "        for idx in train_index:\n",
    "            image_path, class_folder = image_files[idx]\n",
    "            class_path = os.path.join(train_path, class_folder)\n",
    "            os.makedirs(class_path, exist_ok=True)\n",
    "\n",
    "            # Copy original image\n",
    "            image_name = os.path.basename(image_path)\n",
    "            dest_path = os.path.join(class_path, image_name)\n",
    "            shutil.copy(image_path, dest_path)\n",
    "\n",
    "            # Augment image\n",
    "            image = img_to_array(load_img(image_path))\n",
    "            for i in range(train_aug_factor):\n",
    "                aug_image = datagen.random_transform(image)\n",
    "                aug_image = aug_image.astype(\"uint8\")\n",
    "                aug_image = Image.fromarray(aug_image)\n",
    "                aug_image_path = os.path.join(\n",
    "                    class_path,\n",
    "                    f\"{os.path.splitext(image_name)[0]}_aug_{i}{os.path.splitext(image_name)[1]}\",\n",
    "                )\n",
    "                aug_image.save(aug_image_path)\n",
    "\n",
    "        # Copy test images to output directory\n",
    "        for idx in test_index:\n",
    "            image_path, class_folder = image_files[idx]\n",
    "            class_path = os.path.join(test_path, class_folder)\n",
    "            os.makedirs(class_path, exist_ok=True)\n",
    "\n",
    "            # Copy original image\n",
    "            image_name = os.path.basename(image_path)\n",
    "            dest_path = os.path.join(class_path, image_name)\n",
    "            shutil.copy(image_path, dest_path)\n",
    "\n",
    "        # Increment fold index\n",
    "        fold_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdSGbs556_lV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Custom data generator for loading images in batches ram-efficiently\n",
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        directory,\n",
    "        batch_size,\n",
    "        target_size=(150, 150),\n",
    "        shuffle=True,\n",
    "        augmentations=None,\n",
    "    ):\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.target_size = target_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentations = augmentations\n",
    "        self.class_names = sorted(os.listdir(directory))\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.samples = []\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            class_dir = os.path.join(self.directory, class_name)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                self.samples.append((os.path.join(class_dir, filename), i))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.samples) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_samples = self.samples[\n",
    "            idx * self.batch_size : (idx + 1) * self.batch_size\n",
    "        ]\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for sample in batch_samples:\n",
    "            image = cv2.imread(sample[0])\n",
    "            # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, self.target_size)\n",
    "            label = sample[1]\n",
    "            if self.augmentations is not None:\n",
    "                augmented = self.augmentations(image=image)\n",
    "                image = augmented[\"image\"]\n",
    "            batch_images.append(image)\n",
    "            batch_labels.append(label)\n",
    "        return np.array(batch_images) / 255.0, tf.keras.utils.to_categorical(\n",
    "            batch_labels, num_classes=self.num_classes\n",
    "        )\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.samples)\n",
    "\n",
    "# further augmentations if needed\n",
    "train_augmentations = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=(-20, 20), p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=15, p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.3, brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.ColorJitter(p=0.1, brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        A.Blur(p=0.2, blur_limit=(3, 7)),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        # A.CoarseDropout(max_holes=2, max_height=18, max_width=18, min_holes=1, p=0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_gen = CustomDataGenerator(train_path, 32, augmentations=train_augmentations)\n",
    "test_gen = CustomDataGenerator(test_path, 32, augmentations=train_augmentations)\n",
    "\n",
    "\n",
    "batch_size = 24\n",
    "image_size = 200 # both height and width\n",
    "\n",
    "\n",
    "def get_fold_generator(\n",
    "    fold_path,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    shuffle=True,\n",
    "    augmentations=train_augmentations,\n",
    "    mode=\"TRAIN\",\n",
    "):\n",
    "    if mode == \"TRAIN\":\n",
    "        generator = CustomDataGenerator(\n",
    "            directory=fold_path,\n",
    "            batch_size=batch_size,\n",
    "            target_size=target_size,\n",
    "            shuffle=shuffle,\n",
    "            augmentations=augmentations,\n",
    "        )\n",
    "    elif mode == \"VAL\":\n",
    "        generator = CustomDataGenerator(\n",
    "            directory=fold_path,\n",
    "            batch_size=batch_size,\n",
    "            target_size=target_size,\n",
    "            shuffle=shuffle,\n",
    "            augmentations=augmentations,\n",
    "        )\n",
    "    elif mode == \"TEST\":\n",
    "        generator = CustomDataGenerator(\n",
    "            directory=fold_path,\n",
    "            batch_size=batch_size,\n",
    "            target_size=target_size,\n",
    "            shuffle=False,\n",
    "            augmentations=None,\n",
    "        )\n",
    "    return generator\n",
    "\n",
    "\n",
    "# fold creation if set to fold\n",
    "if MODE == \"FOLD\":\n",
    "    f1_t = get_fold_generator(\"/content/folds/fold_1/train\")\n",
    "    f1_tt = get_fold_generator(\"/content/folds/fold_1/test\", mode=\"TEST\")\n",
    "    f2_t = get_fold_generator(\"/content/folds/fold_2/train\")\n",
    "    f2_tt = get_fold_generator(\"/content/folds/fold_2/test\", mode=\"TEST\")\n",
    "    f3_t = get_fold_generator(\"/content/folds/fold_3/train\")\n",
    "    f3_tt = get_fold_generator(\"/content/folds/fold_3/test\", mode=\"TEST\")\n",
    "    f4_t = get_fold_generator(\"/content/folds/fold_4/train\")\n",
    "    f4_tt = get_fold_generator(\"/content/folds/fold_4/test\", mode=\"TEST\")\n",
    "    f5_t = get_fold_generator(\"/content/folds/fold_5/train\")\n",
    "    f5_tt = get_fold_generator(\"/content/folds/fold_5/test\", mode=\"TEST\")\n",
    "    train_gens = [f1_t, f2_t, f3_t, f4_t, f5_t]\n",
    "    test_gens = [f1_tt, f2_tt, f3_tt, f4_tt, f5_tt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4106,
     "status": "ok",
     "timestamp": 1680977713942,
     "user": {
      "displayName": "Lorenzo",
      "userId": "06748019083251351709"
     },
     "user_tz": -120
    },
    "id": "1DWVJYb3bZEL",
    "outputId": "47233fc7-2096-4c81-b661-924a55d25c74"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# checking the data\n",
    "batch_x, batch_y = f1_t.__getitem__(10)\n",
    "batch_x1, batch_y1 = f2_t.__getitem__(10)\n",
    "batch_x2, batch_y2 = f3_t.__getitem__(10)\n",
    "batch_x3, batch_y3 = f4_t.__getitem__(10)\n",
    "batch_x4, batch_y4 = f5_t.__getitem__(10)\n",
    "\n",
    "print(len(f1_t) * batch_size)\n",
    "print(len(f2_t) * batch_size)\n",
    "print(len(f3_t) * batch_size)\n",
    "print(len(f4_t) * batch_size)\n",
    "\n",
    "\n",
    "def check(x, y):\n",
    "    print(f\"shapes: x: {x.shape}, y: {y.shape}\")\n",
    "    print(f\"norms: x: {np.min(x), np.max(x)}, y: {np.min(y), np.max(y)}\")\n",
    "    print(f\"types: x: {type(x)}, y; {type(y)}\")\n",
    "\n",
    "\n",
    "check(batch_x, batch_y)\n",
    "\n",
    "\n",
    "def dis_gen(x, y):\n",
    "    n = len(x) // 8\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=n, figsize=(30, 30))\n",
    "    for i in range(n):\n",
    "        axs[i].imshow(x[i])\n",
    "        axs[i].set_title(f\"Label: {y[i]}\")\n",
    "        axs[i].axis(False)\n",
    "    plt.show()\n",
    "\n",
    "# displaying some samples\n",
    "dis_gen(batch_x, batch_y)\n",
    "dis_gen(batch_x1, batch_y1)\n",
    "dis_gen(batch_x2, batch_y2)\n",
    "dis_gen(batch_x3, batch_y3)\n",
    "dis_gen(batch_x4, batch_y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1681059466885,
     "user": {
      "displayName": "Lorenzo",
      "userId": "06748019083251351709"
     },
     "user_tz": -120
    },
    "id": "31C_3rfl81nc",
    "outputId": "8190da5d-fc03-4666-be76-2129a218a773"
   },
   "outputs": [],
   "source": [
    "print(len(train_gen) * 32)\n",
    "print(len(test_gen) * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "executionInfo": {
     "elapsed": 1101,
     "status": "ok",
     "timestamp": 1680977715036,
     "user": {
      "displayName": "Lorenzo",
      "userId": "06748019083251351709"
     },
     "user_tz": -120
    },
    "id": "2wNA83Ly7otz",
    "outputId": "703f60c2-750b-4282-cdd2-f1004db30dd9"
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = f1_tt.__getitem__(0)\n",
    "print(len(f1_tt) * batch_size)\n",
    "print(len(f2_tt) * batch_size)\n",
    "print(len(f3_tt) * batch_size)\n",
    "\n",
    "check(batch_x, batch_y)\n",
    "dis_gen(batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YTWCqPJEelH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    Concatenate,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Add,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "\n",
    "# Mish activation function\n",
    "class Mish(Activation):\n",
    "    \"\"\"\n",
    "    Mish Activation Function.\n",
    "    .. math::\n",
    "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
    "    Shape:\n",
    "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "        - Output: Same shape as the input.\n",
    "    Examples:\n",
    "        >>> X = Activation('Mish', name=\"conv1_act\")(X_input)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = \"Mish\"\n",
    "\n",
    "\n",
    "def mish(inputs):\n",
    "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
    "\n",
    "# Register Mish activation function\n",
    "get_custom_objects().update({\"Mish\": Mish(mish)})\n",
    "\n",
    "# Model\n",
    "def create_inception(input_shape=(256, 256, 3), num_classes=4, dr=0.0):\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        32,\n",
    "        (3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=\"conv2d_1\",\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(name=\"batch_normalization_1\")(x)\n",
    "    x = Activation(\"Mish\", name=\"activation_1\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = residual_block(x, 32, 0.00004, name=\"1\")\n",
    "    x = attention_block(x, 32, name=\"1\")\n",
    "\n",
    "    x = Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=\"conv2d_1\",\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(name=\"batch_normalization_1\")(x)\n",
    "    x = Activation(\"Mish\", name=\"activation_1\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = residual_block(x, 64, 0.00004, name=\"2\")\n",
    "    x = attention_block(x, 64, name=\"2\")\n",
    "\n",
    "    x = Conv2D(\n",
    "        80,\n",
    "        (3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=\"conv2d_1\",\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(name=\"batch_normalization_1\")(x)\n",
    "    x = Activation(\"Mish\", name=\"activation_1\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = residual_block(x, 80, 0.00004, name=\"3\")\n",
    "    x = attention_block(x, 80, name=\"3\")\n",
    "\n",
    "    x = Conv2D(\n",
    "        192,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"valid\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=\"conv2d_5\",\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=\"batch_normalization_5\")(x)\n",
    "    x = Activation(\"Mish\", name=\"activation_5\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = residual_block(x, 192, 0.00004, name=\"4\")\n",
    "    x = attention_block(x, 192, name=\"4\")\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding=\"valid\", name=\"max_pooling2d_2\")(x)\n",
    "\n",
    "    # Inception blocks\n",
    "    x = inception_block(x, [64, 96, 128, 16, 32, 32], name=\"inception_3a\")\n",
    "    x = inception_block(x, [128, 128, 192, 32, 96, 64], name=\"inception_3b\")\n",
    "    x = inception_block(x, [192, 96, 208, 16, 48, 64], name=\"inception_4a\")\n",
    "    x = inception_block(x, [160, 112, 224, 24, 64, 64], name=\"inception_4b\")\n",
    "    x = inception_block(x, [128, 128, 256, 24, 64, 64], name=\"inception_4c\")\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding=\"valid\", name=\"max_pooling2d_3\")(x)\n",
    "    x = inception_block(x, [256, 160, 320, 32, 128, 128], name=\"inception_5a\")\n",
    "    x = inception_block(x, [384, 192, 384, 48, 128, 128], name=\"inception_5b\")\n",
    "    x = inception_block(x, [576, 240, 576, 72, 192, 192], name=\"inception_5c\")\n",
    "    x = inception_block(x, [864, 360, 864, 108, 288, 288], name=\"inception_5d\", dr_i=dr)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Classification block\n",
    "    x = AveragePooling2D((7, 7), strides=(1, 1), name=\"avg_pooling2d_1\")(x)\n",
    "    x = Flatten(name=\"flatten_1\")(x)\n",
    "    x = Dense(\n",
    "        num_classes,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=\"dense_1\",\n",
    "    )(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(input_tensor, x, name=\"inception_v4\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def inception_block(x, filters, name, dr_i=0.00):\n",
    "    # filters: [in_channels, x1_channels, x3_reduce_channels, x3_channels, x5_reduce_channels, x5_channels]\n",
    "    (\n",
    "        in_channels,\n",
    "        x1_channels,\n",
    "        x3_reduce_channels,\n",
    "        x3_channels,\n",
    "        x5_reduce_channels,\n",
    "        x5_channels,\n",
    "    ) = filters\n",
    "\n",
    "    x1 = Conv2D(\n",
    "        x1_channels,\n",
    "        (1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=name + \"_x1\",\n",
    "    )(x)\n",
    "    x1 = Dropout(dr_i)(x1)\n",
    "    x1 = BatchNormalization(name=name + \"_x1_bn\")(x1)\n",
    "    x1 = Activation(\"Mish\", name=name + \"_x1_act\")(x1)\n",
    "    x1 = Dropout(dr_i)(x1)\n",
    "\n",
    "    x3_reduce = Conv2D(\n",
    "        x3_reduce_channels,\n",
    "        (1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=name + \"_x3_reduce\",\n",
    "    )(x)\n",
    "    x3_reduce = BatchNormalization(name=name + \"_x3_reduce_bn\")(x3_reduce)\n",
    "    x3_reduce = Activation(\"Mish\", name=name + \"_x3_reduce_act\")(x3_reduce)\n",
    "    x3_reduce = Dropout(dr_i)(x3_reduce)\n",
    "    x3 = Conv2D(\n",
    "        x3_channels,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=name + \"_x3\",\n",
    "    )(x3_reduce)\n",
    "    x3 = BatchNormalization(name=name + \"_x3_bn\")(x3)\n",
    "    x3 = Activation(\"Mish\", name=name + \"_x3_act\")(x3)\n",
    "    x3 = Dropout(dr_i)(x3)\n",
    "\n",
    "    x5_reduce = Conv2D(\n",
    "        x5_reduce_channels,\n",
    "        (1, 1),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=name + \"_x5_reduce\",\n",
    "    )(x)\n",
    "    x5_reduce = BatchNormalization(name=name + \"_x5_reduce_bn\")(x5_reduce)\n",
    "    x5_reduce = Activation(\"Mish\", name=name + \"_x5_reduce_act\")(x5_reduce)\n",
    "    x5_reduce = Dropout(dr_i)(x5_reduce)\n",
    "    x5 = Conv2D(\n",
    "        x5_channels,\n",
    "        (5, 5),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(0.00004),\n",
    "        name=name + \"_x5\",\n",
    "    )(x5_reduce)\n",
    "    x5 = BatchNormalization(name=name + \"_x5_bn\")(x5)\n",
    "    x5 = Activation(\"Mish\", name=name + \"_x5_act\")(x5)\n",
    "    x5 = Dropout(dr_i)(x5)\n",
    "\n",
    "    x_out = Concatenate(name=name + \"_concat\")([x1, x3, x5])\n",
    "    return x_out\n",
    "\n",
    "\n",
    "def residual_block(input_tensor, filters, w_decay, name, dr_r=0.0):\n",
    "    x = Conv2D(\n",
    "        filters,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(w_decay),\n",
    "        name=f\"res_conv{name}\",\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(name=f\"batch_res{name}\")(x)\n",
    "    x = Activation(\"Mish\", name=f\"activation_res{name}\")(x)\n",
    "    x = Dropout(dr_r)(x)\n",
    "    x = Conv2D(\n",
    "        filters,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        kernel_regularizer=l2(w_decay),\n",
    "        name=f\"res_conv{name}_1\",\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=f\"batch_res{name}_1\")(x)\n",
    "    x = Activation(\"Mish\", name=f\"activation_res{name}_1\")(x)\n",
    "    x = Dropout(dr_r)(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    return x\n",
    "\n",
    "\n",
    "def attention_block(input_tensor, filters, name, dr=0.0):\n",
    "    x = Conv2D(\n",
    "        filters,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        name=f\"conv_att{name}_1\",\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(name=f\"batch_att{name}_1\")(x)\n",
    "    x = Activation(\"Mish\", name=f\"ac_att{name}_1\")(x)\n",
    "    x = Conv2D(\n",
    "        filters,\n",
    "        (3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        name=f\"conv_att{name}_2\",\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=f\"batch_att{name}_2\")(x)\n",
    "    x = Activation(\"sigmoid\", name=f\"ac_att{name}_2\")(x)\n",
    "    x = Dropout(dr)(x)\n",
    "    x = Multiply()([input_tensor, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8Dv4px7nT6v"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.optimizers import optimizer\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.experimental import AdamW\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "# from tensorflow.keras.utils import array_to_image\n",
    "import csv\n",
    "from keras.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    EarlyStopping,\n",
    "    TensorBoard,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "\n",
    "# Define the callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"accuracy\"),\n",
    "    EarlyStopping(monitor=\"loss\", patience=6),\n",
    "    TensorBoard(log_dir=\"logs\"),\n",
    "    ReduceLROnPlateau(monitor=\"loss\", patience=3, factor=0.1),\n",
    "]\n",
    "\n",
    "\n",
    "def save_eval_results(eval_results, filename):\n",
    "    # Open the file in write mode and write the evaluation results to it\n",
    "    with open(filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(model.metrics_names)\n",
    "        writer.writerow(eval_results)\n",
    "\n",
    "\n",
    "def plot_history(history, call=None):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=len(history.history), figsize=(20, 5))\n",
    "\n",
    "    for i, metric in enumerate(history.history.keys()):\n",
    "        axs[i].plot(history.history[metric])\n",
    "        axs[i].set_title(metric)\n",
    "        axs[i].set_xlabel(\"Epoch\")\n",
    "        axs[i].set_ylabel(metric)\n",
    "    plt.savefig(f\"{str(history)}_{call}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def quick_test(test_generator, model, img_size):\n",
    "    # Get a batch of test data\n",
    "    rand = np.random.randint(0, len(test_generator))\n",
    "    batch_x, batch_y = test_generator.__getitem__(rand)\n",
    "\n",
    "    # Generate predictions for the test data\n",
    "    pred_y = model.predict(batch_x)\n",
    "\n",
    "    # Create a pred folder if it doesn't exist\n",
    "    if not os.path.exists(\"pred\"):\n",
    "        os.makedirs(\"pred\")\n",
    "\n",
    "    # Loop through the test data and save each image and its predicted label to the pred folder\n",
    "    for i in range(batch_x.shape[0]):\n",
    "        # Convert the image array to a PIL image\n",
    "        img = array_to_img(batch_x[i])\n",
    "\n",
    "        # Get the predicted label for the image\n",
    "        pred_label = np.argmax(pred_y[i])\n",
    "\n",
    "        # Save the image with its predicted label as the filename\n",
    "        img.save(f\"pred/{pred_label}_{i}.jpg\")\n",
    "\n",
    "def lerp(start, end, weight):\n",
    "    return start + weight * (end - start)\n",
    "\n",
    "\n",
    "def sparse_lerp(start, end, weight):\n",
    "    # Mathematically equivalent, but you can't subtract a dense Tensor from sparse\n",
    "    # IndexedSlices, so we have to flip it around.\n",
    "    return start + weight * -(start - end)\n",
    "\n",
    "\n",
    "# Lion optimizer\n",
    "class Lion(optimizer.Optimizer):\n",
    "    r\"\"\"Optimizer that implements the Lion algorithm.\n",
    "    Lion was published in the paper \"Symbolic Discovery of Optimization Algorithms\"\n",
    "    which is available at https://arxiv.org/abs/2302.06675\n",
    "    Args:\n",
    "      learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n",
    "        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n",
    "        that takes no arguments and returns the actual value to use. The\n",
    "        learning rate. Defaults to 1e-4.\n",
    "      beta_1: A float value or a constant float tensor, or a callable\n",
    "        that takes no arguments and returns the actual value to use. Factor\n",
    "         used to interpolate the current gradient and the momentum. Defaults to 0.9.\n",
    "      beta_2: A float value or a constant float tensor, or a callable\n",
    "        that takes no arguments and returns the actual value to use. The\n",
    "        exponential decay rate for the momentum. Defaults to 0.99.\n",
    "    Notes:\n",
    "    The sparse implementation of this algorithm (used when the gradient is an\n",
    "    IndexedSlices object, typically because of `tf.gather` or an embedding\n",
    "    lookup in the forward pass) does apply momentum to variable slices even if\n",
    "    they were not used in the forward pass (meaning they have a gradient equal\n",
    "    to zero). Momentum decay (beta2) is also applied to the entire momentum\n",
    "    accumulator. This means that the sparse behavior is equivalent to the dense\n",
    "    behavior (in contrast to some momentum implementations which ignore momentum\n",
    "    unless a variable slice was actually used).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate=1e-4,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.99,\n",
    "        weight_decay=None,\n",
    "        clipnorm=None,\n",
    "        clipvalue=None,\n",
    "        global_clipnorm=None,\n",
    "        jit_compile=True,\n",
    "        name=\"Lion\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            weight_decay=weight_decay,\n",
    "            clipnorm=clipnorm,\n",
    "            clipvalue=clipvalue,\n",
    "            global_clipnorm=global_clipnorm,\n",
    "            jit_compile=jit_compile,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self._learning_rate = self._build_learning_rate(learning_rate)\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "    def build(self, var_list):\n",
    "        \"\"\"Initialize optimizer variables.\n",
    "        var_list: list of model variables to build Lion variables on.\n",
    "        \"\"\"\n",
    "        super().build(var_list)\n",
    "        if hasattr(self, \"_built\") and self._built:\n",
    "            return\n",
    "        self._built = True\n",
    "        self._emas = []\n",
    "        for var in var_list:\n",
    "            self._emas.append(\n",
    "                self.add_variable_from_reference(\n",
    "                    model_variable=var, variable_name=\"ema\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def update_step(self, gradient, variable):\n",
    "        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n",
    "        lr = tf.cast(self.learning_rate, variable.dtype)\n",
    "        beta_1 = tf.constant(self.beta_1, shape=(1,))\n",
    "        beta_2 = tf.constant(self.beta_2, shape=(1,))\n",
    "\n",
    "        var_key = self._var_key(variable)\n",
    "        ema = self._emas[self._index_dict[var_key]]\n",
    "\n",
    "        if isinstance(gradient, tf.IndexedSlices):\n",
    "            # Sparse gradients.\n",
    "            lerp_fn = sparse_lerp\n",
    "        else:\n",
    "            # Dense gradients.\n",
    "            lerp_fn = lerp\n",
    "\n",
    "        update = lerp_fn(ema, gradient, 1 - beta_1)\n",
    "        update = tf.sign(update)\n",
    "        variable.assign_sub(update * lr)\n",
    "\n",
    "        ema.assign(lerp_fn(ema, gradient, 1 - beta_2))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "\n",
    "        config.update(\n",
    "            {\n",
    "                \"learning_rate\": self._serialize_hyperparameter(self._learning_rate),\n",
    "                \"beta_1\": self.beta_1,\n",
    "                \"beta_2\": self.beta_2,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=4.0):\n",
    "    gamma = float(gamma)\n",
    "    alpha = float(alpha)\n",
    "\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"Focal loss for multi-classification\n",
    "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
    "        Notice: y_pred is probability after softmax\n",
    "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
    "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
    "        Focal Loss for Dense Object Detection\n",
    "        https://arxiv.org/abs/1708.02002\n",
    "        Arguments:\n",
    "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
    "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
    "        Keyword Arguments:\n",
    "            gamma {float} -- (default: {2.0})\n",
    "            alpha {float} -- (default: {4.0})\n",
    "        Returns:\n",
    "            [tensor] -- loss.\n",
    "        \"\"\"\n",
    "        epsilon = 1.0e-9\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "\n",
    "        model_out = tf.add(y_pred, epsilon)\n",
    "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
    "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1.0, model_out), gamma))\n",
    "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
    "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
    "        return tf.reduce_mean(reduced_fl)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Lion optimizer\n",
    "opt = Lion(5e-5, weight_decay=5e-6)\n",
    "\n",
    "# training\n",
    "if MODE == \"FOLDS\":\n",
    "    # train on each fold\n",
    "    for i in range(n_folds):\n",
    "        print(f\"At fold {i + 1}\")\n",
    "        model = create_inception(\n",
    "            num_classes=8, input_shape=(image_size, image_size, 3)\n",
    "        )\n",
    "        model.compile(\n",
    "            optimizer=Lion(1e-5),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\n",
    "                \"accuracy\",\n",
    "                f1_m,\n",
    "                recall_m,\n",
    "                precision_m,\n",
    "                tf.keras.metrics.AUC(),\n",
    "                tf.keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "            ],\n",
    "        )\n",
    "        history = model.fit(train_gens[i], epochs=25, callbacks=callbacks)\n",
    "        model.save(f\"kather_fold_{str(i + 1)}.h5\")\n",
    "        eval = model.evaluate(test_gens[i])\n",
    "        save_eval_results(eval, \"Inc_Kather\")\n",
    "\n",
    "        # plotting the history\n",
    "        plot_history(history)\n",
    "\n",
    "        # testing\n",
    "        quick_test(test_gens[i], model, (image_size, image_size))\n",
    "else:\n",
    "    model = create_inception(num_classes=8, input_shape=(image_size, image_size, 3))\n",
    "    model.compile(\n",
    "        optimizer=Lion(1e-5),\n",
    "        loss=focal_loss(),\n",
    "        metrics=[\n",
    "            \"accuracy\",\n",
    "            f1_m,\n",
    "            recall_m,\n",
    "            precision_m,\n",
    "            tf.keras.metrics.AUC(),\n",
    "            tf.keras.metrics.SpecificityAtSensitivity(0.5),\n",
    "        ],\n",
    "    )\n",
    "    history = model.fit(train_gen, epochs=25, callbacks=callbacks)\n",
    "    eval = model.evaluate(test_gen)\n",
    "    save_eval_results(eval, \"Inc_Kather\")\n",
    "    # plotting the history\n",
    "    plot_history(history)\n",
    "\n",
    "    # testing\n",
    "    quick_test(test_gen, model, (image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1680983371063,
     "user": {
      "displayName": "Lorenzo",
      "userId": "06748019083251351709"
     },
     "user_tz": -120
    },
    "id": "xICZ_0XwOULh",
    "outputId": "b914dedf-51db-4060-b4b7-d3784e8c942b"
   },
   "outputs": [],
   "source": [
    "#import shutil\n",
    "\n",
    "#shutil.move(\"kather_fold_1.h5\", \"/content/drive/MyDrive/\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1NmL4a3Y5D1ud_67WImbznRoW_NzZ8Q9a",
     "timestamp": 1680782441462
    },
    {
     "file_id": "1lTHJUDhquEpPqNrGlvereSeMxdoqNR9T",
     "timestamp": 1680625371824
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

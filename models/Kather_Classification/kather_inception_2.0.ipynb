{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr-eBvNPYu0X",
        "outputId": "0a353a9b-464a-4044-d8a8-c61221777245"
      },
      "outputs": [],
      "source": [
        "# get data\n",
        "!wget https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip?download=1\n",
        "!unzip '/content/Kather_texture_2016_image_tiles_5000.zip?download=1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9q1qknr1_AE"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import  numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# metrics\n",
        "def auc(y_true, y_pred):\n",
        "    # First, we need to convert the one-hot encoded labels and predicted probabilities\n",
        "    # into a single label and probability for each sample.\n",
        "    y_true = np.argmax(y_true, axis=1)\n",
        "    y_pred = y_pred[:, 1:]\n",
        "    \n",
        "    # Then we can use the roc_auc_score function to compute the AUC for each class\n",
        "    auc_scores = []\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        auc_scores.append(roc_auc_score(y_true, y_pred[:, i]))\n",
        "    \n",
        "    # Return the average AUC across all classes\n",
        "    return np.mean(auc_scores)\n",
        "\n",
        "def dice_score(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))    \n",
        "\n",
        "def jaccard_distance(y_true, y_pred, smooth=100):\n",
        "    intersection = tf.reduce_sum(y_true * y_pred, axis=(1,2))\n",
        "    sum_ = tf.reduce_sum(y_true + y_pred, axis=(1,2))\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    jd =  (1 - jac) * smooth\n",
        "    return tf.reduce_mean(jd)\n",
        "\n",
        "def tf_mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.5):\n",
        "        y_pred_ = tf.cast(y_pred > t, tf.int32)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        prec.append(score)\n",
        "    val = K.mean(K.stack(prec), axis=0)\n",
        "    return [val, up_opt]\n",
        "\n",
        "def cross_entropy_balanced(y_true, y_pred):\n",
        "\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "    count_neg = tf.reduce_sum(1. - y_true)\n",
        "    count_pos = tf.reduce_sum(y_true)\n",
        "\n",
        "    beta = count_neg/(count_pos + count_neg)\n",
        "\n",
        "    pos_weight = beta/(1 - beta)\n",
        "\n",
        "    cost = tf.nn.weighted_cross_entropy_with_logits(logits=y_pred, labels=y_true, pos_weight=pos_weight)\n",
        "\n",
        "    cost = tf.reduce_mean(cost * (1 - beta))\n",
        "\n",
        "    return tf.where(tf.equal(count_pos, 0.0), 0.0, cost)\n",
        "\n",
        "\n",
        "def pixel_error(y_true, y_pred):\n",
        "    pred = tf.cast(tf.greater(y_pred, 0.5), tf.int32)\n",
        "    error = tf.cast(tf.not_equal(pred, tf.cast(y_true, tf.int32)), tf.float32)\n",
        "\n",
        "    return tf.reduce_mean(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCOI-lEe8l3p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import albumentations as A\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "parent_folder_path = '/content/Kather_texture_2016_image_tiles_5000'\n",
        "\n",
        "num_augmented_images = 1 # number of augmented images per original image\n",
        "target_size = (256,256)\n",
        "test_ratio = 0.3 # ratio compared to the original dataset size\n",
        "\n",
        "# create data structure\n",
        "for class_name in os.listdir(parent_folder_path):\n",
        "    class_folder_path = os.path.join(parent_folder_path, class_name)\n",
        "    if not os.path.isdir(class_folder_path):\n",
        "        continue\n",
        "\n",
        "    test_class_folder_path = os.path.join(parent_folder_path, '..', 'Kather_texture_2016_image_tiles_5000_test', class_name)\n",
        "    os.makedirs(test_class_folder_path, exist_ok=True)\n",
        "\n",
        "    img_names = [img_name for img_name in os.listdir(class_folder_path) if img_name.lower().endswith(('.tif', '.png', '.jpg', '.jpeg'))]\n",
        "    random.shuffle(img_names)\n",
        "    num_test_images = int(len(img_names) * test_ratio)\n",
        "\n",
        "    for img_name in img_names[:num_test_images]:\n",
        "        img = Image.open(os.path.join(class_folder_path, img_name))\n",
        "        img = img.resize(target_size)\n",
        "        img.save(os.path.join(test_class_folder_path, img_name))\n",
        "        os.remove(os.path.join(class_folder_path, img_name))\n",
        "\n",
        "    for img_name in img_names[num_test_images:]:\n",
        "        img = Image.open(os.path.join(class_folder_path, img_name))\n",
        "        img = img.resize(target_size)\n",
        "\n",
        "        transform = A.Compose([\n",
        "            A.Rotate(limit=20),\n",
        "            A.HorizontalFlip(),\n",
        "            A.VerticalFlip(),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
        "            A.OneOf([\n",
        "                    A.ShiftScaleRotate(shift_limit=0.18, scale_limit=0.18, rotate_limit=18, p=0.25),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.18, scale_limit=0.18, rotate_limit=18, \n",
        "                    border_mode=cv2.BORDER_CONSTANT, value=0, interpolation=cv2.INTER_NEAREST, p=0.25),\n",
        "            ], p=0.4),\n",
        "        ])\n",
        "\n",
        "        for i in range(num_augmented_images):\n",
        "            transformed = transform(image=np.array(img))\n",
        "            transformed_image = Image.fromarray(transformed['image'])\n",
        "            transformed_image.save(os.path.join(class_folder_path, f\"aug_{i}_{img_name}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdSGbs556_lV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# data generator following keras.utils.Sequence \n",
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, directory, batch_size, target_size=(150, 150), shuffle=True, augmentations=None):\n",
        "        self.directory = directory\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augmentations = augmentations\n",
        "        self.class_names = sorted(os.listdir(directory))\n",
        "        self.num_classes = len(self.class_names)\n",
        "        self.samples = []\n",
        "        for i, class_name in enumerate(self.class_names):\n",
        "            class_dir = os.path.join(self.directory, class_name)\n",
        "            for filename in os.listdir(class_dir):\n",
        "                self.samples.append((os.path.join(class_dir, filename), i))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.samples) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_samples = self.samples[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "        for sample in batch_samples:\n",
        "            image = cv2.imread(sample[0])\n",
        "           # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            image = cv2.resize(image, self.target_size)\n",
        "            label = sample[1]\n",
        "            if self.augmentations is not None:\n",
        "                augmented = self.augmentations(image=image)\n",
        "                image = augmented['image']\n",
        "            batch_images.append(image)\n",
        "            batch_labels.append(label)\n",
        "        return np.array(batch_images)/255.0, tf.keras.utils.to_categorical(batch_labels, num_classes=self.num_classes)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.samples)\n",
        "\n",
        "# augmentations if needed\n",
        "train_augmentations = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3, brightness_limit=0.2, contrast_limit=0.2),\n",
        "    A.ColorJitter(p=0.2),\n",
        "    A.GaussianBlur(p=0.25, blur_limit=(3, 7)),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=(-20, 20), p=0.5, interpolation=cv2.INTER_NEAREST),\n",
        "    A.OneOf([\n",
        "        A.ShiftScaleRotate(shift_limit=0.20, scale_limit=0.20, rotate_limit=20),\n",
        "    ], p=0.3),\n",
        "    A.RGBShift(p=0.1),\n",
        "])\n",
        "\n",
        "batch_size = 16\n",
        "image_size = 256\n",
        "# get data generators\n",
        "def get_fold_generator(fold_path, batch_size=batch_size, target_size=(image_size, image_size), shuffle=True, augmentations=train_augmentations, mode = 'TRAIN'):\n",
        "    if mode == 'TRAIN':\n",
        "        generator = CustomDataGenerator(directory=fold_path, batch_size=batch_size, target_size=target_size, shuffle=shuffle, augmentations=augmentations)\n",
        "    elif mode == 'VAL':\n",
        "        generator = CustomDataGenerator(directory=fold_path, batch_size=batch_size, target_size=target_size, shuffle=shuffle, augmentations=augmentations)\n",
        "    elif mode == 'TEST':\n",
        "        generator = CustomDataGenerator(directory=fold_path, batch_size=batch_size, target_size=target_size, shuffle=False, augmentations=None)\n",
        "    return generator\n",
        "\n",
        "train_generator = get_fold_generator(\"/content/Kather_texture_2016_image_tiles_5000/\", mode=\"TRAIN\")\n",
        "test_generator = get_fold_generator(\"/content/Kather_texture_2016_image_tiles_5000_test/\", mode=\"TEST\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7rcDAtkYNM6",
        "outputId": "5b8de1b6-a1a6-42ac-d934-133de6c146b8"
      },
      "outputs": [],
      "source": [
        "# data information\n",
        "def check_nums(dataset_path):\n",
        "  class_folders = os.listdir(dataset_path)\n",
        "  for class_folder in class_folders:\n",
        "      class_folder_path = os.path.join(dataset_path, class_folder)\n",
        "      if os.path.isdir(class_folder_path):\n",
        "          num_images = len(os.listdir(class_folder_path))\n",
        "          print(f\"Class {class_folder} has {num_images} images.\")\n",
        "\n",
        "check_nums(\"/content/Kather_texture_2016_image_tiles_5000/\")\n",
        "check_nums(\"/content/Kather_texture_2016_image_tiles_5000_test/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1DWVJYb3bZEL",
        "outputId": "e5a51b4e-7ccf-4841-d214-7676c02478e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# check data integrity\n",
        "batch_x, batch_y = train_generator.__getitem__(10)\n",
        "print(batch_x.shape, batch_y.shape)\n",
        "print(len(train_generator) * batch_size)\n",
        "def check(x, y):\n",
        "    print(f\"shapes: x: {x.shape}, y: {y.shape}\")\n",
        "    print(f\"norms: x: {np.min(x), np.max(x)}, y: {np.min(y), np.max(y)}\")\n",
        "    print(f\"types: x: {type(x)}, y; {type(y)}\")\n",
        "check(batch_x, batch_y)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(len(batch_x)):\n",
        "  plt.imshow(batch_x[i])\n",
        "  plt.title(f'Label {batch_y[i]}')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2wNA83Ly7otz",
        "outputId": "d8c28f0a-eefc-47c4-be77-a2f7e740b9ad"
      },
      "outputs": [],
      "source": [
        "# check data integrity\n",
        "batch_x, batch_y = test_generator.__getitem__(0)\n",
        "print(batch_x.shape, batch_y.shape)\n",
        "print(len(batch_x) * 16)\n",
        "def check(x, y):\n",
        "    print(f\"shapes: x: {x.shape}, y: {y.shape}\")\n",
        "    print(f\"norms: x: {np.min(x), np.max(x)}, y: {np.min(y), np.max(y)}\")\n",
        "    print(f\"types: x: {type(x)}, y; {type(y)}\")\n",
        "check(batch_x, batch_y)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# display test images\n",
        "for i in range(len(batch_x)):\n",
        "  plt.imshow(batch_x[i])\n",
        "  plt.title(f'Label {batch_y[i]}')\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YTWCqPJEelH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Concatenate, BatchNormalization, Activation, Flatten, Dense, Dropout, Add, Multiply\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "\n",
        "class Mish(Activation):\n",
        "    '''\n",
        "    Mish Activation Function.\n",
        "    .. math::\n",
        "        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))\n",
        "    Shape:\n",
        "        - Input: Arbitrary. Use the keyword argument `input_shape`\n",
        "        (tuple of integers, does not include the samples axis)\n",
        "        when using this layer as the first layer in a model.\n",
        "        - Output: Same shape as the input.\n",
        "    Examples:\n",
        "        >>> X = Activation('Mish', name=\"conv1_act\")(X_input)\n",
        "    '''\n",
        "\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(Mish, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'Mish'\n",
        "\n",
        "\n",
        "def mish(inputs):\n",
        "    return inputs * tf.math.tanh(tf.math.softplus(inputs))\n",
        "\n",
        "get_custom_objects().update({'Mish': Mish(mish)})\n",
        "\n",
        "def create_inception_v4(input_shape=(256, 256, 3), num_classes=4, dr=0.0):\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name='conv2d_1')(input_tensor)\n",
        "    x = BatchNormalization(name='batch_normalization_1')(x)\n",
        "    x = Activation('Mish', name='activation_1')(x)\n",
        "    x = Dropout(dr)(x)\n",
        "    x = residual_block(x, 32, 0.00004, name='1')\n",
        "    x = attention_block(x, 32, name='1')\n",
        "    \n",
        "    x = Conv2D(64, (3, 3), strides=(2, 2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name='conv2d_1')(input_tensor)\n",
        "    x = BatchNormalization(name='batch_normalization_1')(x)\n",
        "    x = Activation('Mish', name='activation_1')(x)\n",
        "    x = Dropout(dr)(x)\n",
        "    x = residual_block(x, 64, 0.00004, name='2')\n",
        "    x = attention_block(x, 64, name='2')\n",
        "    \n",
        "    x = Conv2D(80, (3, 3), strides=(2, 2), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name='conv2d_1')(input_tensor)\n",
        "    x = BatchNormalization(name='batch_normalization_1')(x)\n",
        "    x = Activation('Mish', name='activation_1')(x)\n",
        "    x = Dropout(dr)(x)\n",
        "    x = residual_block(x, 80, 0.00004, name='3')\n",
        "    x = attention_block(x, 80, name='3')\n",
        "    \n",
        "    x = Conv2D(192, (3, 3), strides=(1, 1), padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name='conv2d_5')(x)\n",
        "    x = BatchNormalization(name='batch_normalization_5')(x)\n",
        "    x = Activation('Mish', name='activation_5')(x)\n",
        "    x = Dropout(dr)(x)\n",
        "    x = residual_block(x, 192, 0.00004, name='4')\n",
        "    x = attention_block(x, 192, name='4')\n",
        "    \n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='max_pooling2d_2')(x)\n",
        "\n",
        "    # Inception blocks\n",
        "    x = inception_block(x, [64, 96, 128, 16, 32, 32], name='inception_3a')\n",
        "    x = inception_block(x, [128, 128, 192, 32, 96, 64], name='inception_3b')\n",
        "    x = inception_block(x, [192, 96, 208, 16, 48, 64], name='inception_4a')\n",
        "    x = inception_block(x, [160, 112, 224, 24, 64, 64], name='inception_4b')\n",
        "    x = inception_block(x, [128, 128, 256, 24, 64, 64], name='inception_4c')\n",
        "    x = Dropout(0.05)(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='max_pooling2d_3')(x)\n",
        "    x = inception_block(x, [256, 160, 320, 32, 128, 128], name='inception_5a')\n",
        "    x = inception_block(x, [384, 192, 384, 48, 128, 128], name='inception_5b')\n",
        "    x = inception_block(x, [576, 240, 576, 72, 192, 192], name='inception_5c')\n",
        "    x = inception_block(x, [864, 360, 864, 108, 288, 288], name='inception_5d', dr_i=dr)\n",
        "    x = Dropout(0.05)(x)\n",
        "\n",
        "    # Classification block\n",
        "    x = AveragePooling2D((7, 7), strides=(1, 1), name='avg_pooling2d_1')(x)\n",
        "    x = Flatten(name='flatten_1')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.00004), name='dense_1')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(input_tensor, x, name='inception_v4')\n",
        "\n",
        "    return model\n",
        "\n",
        "def inception_block(x, filters, name, dr_i=0.0):\n",
        "    # filters: [in_channels, x1_channels, x3_reduce_channels, x3_channels, x5_reduce_channels, x5_channels]\n",
        "    in_channels, x1_channels, x3_reduce_channels, x3_channels, x5_reduce_channels, x5_channels = filters\n",
        "\n",
        "    x1 = Conv2D(x1_channels, (1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name=name+'_x1')(x)\n",
        "    x1 = Dropout(dr_i)(x1)\n",
        "    x1 = BatchNormalization(name=name+'_x1_bn')(x1)\n",
        "    x1 = Activation('Mish', name=name+'_x1_act')(x1)\n",
        "    x1 = Dropout(dr_i)(x1)\n",
        "\n",
        "    x3_reduce = Conv2D(x3_reduce_channels, (1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name=name+'_x3_reduce')(x)\n",
        "    x3_reduce = BatchNormalization(name=name+'_x3_reduce_bn')(x3_reduce)\n",
        "    x3_reduce = Activation('Mish', name=name+'_x3_reduce_act')(x3_reduce)\n",
        "    x3 = Dropout(dr_i)(x3_reduce)\n",
        "    x3 = Conv2D(x3_channels, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name=name+'_x3')(x3_reduce)\n",
        "    x3 = BatchNormalization(name=name+'_x3_bn')(x3)\n",
        "    x3 = Activation('Mish', name=name+'_x3_act')(x3)\n",
        "    x3 = Dropout(dr_i)(x3)\n",
        "\n",
        "    x5_reduce = Conv2D(x5_reduce_channels, (1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name=name+'_x5_reduce')(x)\n",
        "    x5_reduce = BatchNormalization(name=name+'_x5_reduce_bn')(x5_reduce)\n",
        "    x5_reduce = Activation('Mish', name=name+'_x5_reduce_act')(x5_reduce)\n",
        "    x5_reduce = Dropout(dr_i)(x5_reduce)\n",
        "    x5 = Conv2D(x5_channels, (5, 5), strides=(1, 1), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.00004), name=name+'_x5')(x5_reduce)\n",
        "    x5 = Dropout(dr_i)(x5)\n",
        "    x5 = BatchNormalization(name=name+'_x5_bn')(x5)\n",
        "    x5 = Activation('Mish', name=name+'_x5_act')(x5)\n",
        "    x5 = Dropout(dr_i)(x5)\n",
        "\n",
        "    x_out = Concatenate(name=name+'_concat')([x1, x3, x5])\n",
        "    return x_out\n",
        "\n",
        "def residual_block(input_tensor, filters, w_decay, name,dr_r=0.0):\n",
        "    x = Conv2D(filters, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(w_decay), name=f'res_conv{name}')(input_tensor)\n",
        "    x = BatchNormalization(name=f'batch_res{name}')(x)\n",
        "    x = Activation('Mish', name=f'activation_res{name}')(x)\n",
        "    x = Dropout(dr_r)(x)\n",
        "    x = Conv2D(filters, (3, 3), padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(w_decay), name=f'res_conv{name}_1')(x)\n",
        "    x = BatchNormalization(name=f'batch_res{name}_1')(x)\n",
        "    x = Activation('Mish', name=f'activation_res{name}_1')(x)\n",
        "    x = Dropout(dr_r)(x)\n",
        "    x = Add()([x, input_tensor])\n",
        "    return x\n",
        "\n",
        "def attention_block(input_tensor, filters,name, dr=0.0):\n",
        "    x = Conv2D(filters, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', name=f\"conv_att{name}_1\")(input_tensor)\n",
        "    x = BatchNormalization(name=f\"batch_att{name}_1\")(x)\n",
        "    x = Activation('Mish', name=f\"ac_att{name}_1\")(x)\n",
        "    x = Conv2D(filters, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', name=f\"conv_att{name}_2\")(x)\n",
        "    x = BatchNormalization(name=f\"batch_att{name}_2\")(x)\n",
        "    x = Activation('sigmoid', name=f\"ac_att{name}_2\")(x)\n",
        "    x = Dropout(dr)(x)\n",
        "    x = Multiply()([input_tensor, x])\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8Dv4px7nT6v",
        "outputId": "b78762f6-2094-4474-bdbf-b5272f8e5693"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.optimizers.experimental import AdamW\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
        "from keras.optimizers import optimizer\n",
        "from keras.models import load_model\n",
        "\n",
        "def lerp(start, end, weight):\n",
        "    return start + weight * (end - start)\n",
        "\n",
        "\n",
        "def sparse_lerp(start, end, weight):\n",
        "    # Mathematically equivalent, but you can't subtract a dense Tensor from sparse\n",
        "    # IndexedSlices, so we have to flip it around.\n",
        "    return start + weight * -(start - end)\n",
        "\n",
        "\n",
        "class Lion(optimizer.Optimizer):\n",
        "    r\"\"\"Optimizer that implements the Lion algorithm.\n",
        "    Lion was published in the paper \"Symbolic Discovery of Optimization Algorithms\"\n",
        "    which is available at https://arxiv.org/abs/2302.06675\n",
        "    Args:\n",
        "      learning_rate: A `tf.Tensor`, floating point value, a schedule that is a\n",
        "        `tf.keras.optimizers.schedules.LearningRateSchedule`, or a callable\n",
        "        that takes no arguments and returns the actual value to use. The\n",
        "        learning rate. Defaults to 1e-4.\n",
        "      beta_1: A float value or a constant float tensor, or a callable\n",
        "        that takes no arguments and returns the actual value to use. Factor\n",
        "         used to interpolate the current gradient and the momentum. Defaults to 0.9.\n",
        "      beta_2: A float value or a constant float tensor, or a callable\n",
        "        that takes no arguments and returns the actual value to use. The\n",
        "        exponential decay rate for the momentum. Defaults to 0.99.\n",
        "    Notes:\n",
        "    The sparse implementation of this algorithm (used when the gradient is an\n",
        "    IndexedSlices object, typically because of `tf.gather` or an embedding\n",
        "    lookup in the forward pass) does apply momentum to variable slices even if\n",
        "    they were not used in the forward pass (meaning they have a gradient equal\n",
        "    to zero). Momentum decay (beta2) is also applied to the entire momentum\n",
        "    accumulator. This means that the sparse behavior is equivalent to the dense\n",
        "    behavior (in contrast to some momentum implementations which ignore momentum\n",
        "    unless a variable slice was actually used).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        learning_rate=1e-4,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.99,\n",
        "        weight_decay=None,\n",
        "        clipnorm=None,\n",
        "        clipvalue=None,\n",
        "        global_clipnorm=None,\n",
        "        jit_compile=True,\n",
        "        name=\"Lion\",\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(\n",
        "            name=name,\n",
        "            weight_decay=weight_decay,\n",
        "            clipnorm=clipnorm,\n",
        "            clipvalue=clipvalue,\n",
        "            global_clipnorm=global_clipnorm,\n",
        "            jit_compile=jit_compile,\n",
        "            **kwargs\n",
        "        )\n",
        "        self._learning_rate = self._build_learning_rate(learning_rate)\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    def build(self, var_list):\n",
        "        \"\"\"Initialize optimizer variables.\n",
        "          var_list: list of model variables to build Lion variables on.\n",
        "        \"\"\"\n",
        "        super().build(var_list)\n",
        "        if hasattr(self, \"_built\") and self._built:\n",
        "            return\n",
        "        self._built = True\n",
        "        self._emas = []\n",
        "        for var in var_list:\n",
        "            self._emas.append(\n",
        "                self.add_variable_from_reference(\n",
        "                    model_variable=var, variable_name=\"ema\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def update_step(self, gradient, variable):\n",
        "        \"\"\"Update step given gradient and the associated model variable.\"\"\"\n",
        "        lr = tf.cast(self.learning_rate, variable.dtype)\n",
        "        beta_1 = tf.constant(self.beta_1, shape=(1,))\n",
        "        beta_2 = tf.constant(self.beta_2, shape=(1,))\n",
        "\n",
        "        var_key = self._var_key(variable)\n",
        "        ema = self._emas[self._index_dict[var_key]]\n",
        "\n",
        "        if isinstance(gradient, tf.IndexedSlices):\n",
        "            # Sparse gradients.\n",
        "            lerp_fn = sparse_lerp\n",
        "        else:\n",
        "            # Dense gradients.\n",
        "            lerp_fn = lerp\n",
        "\n",
        "        update = lerp_fn(ema, gradient, 1 - beta_1)\n",
        "        update = tf.sign(update)\n",
        "        variable.assign_sub(update * lr)\n",
        "\n",
        "        ema.assign(lerp_fn(ema, gradient, 1 - beta_2))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "\n",
        "        config.update(\n",
        "            {\n",
        "                \"learning_rate\": self._serialize_hyperparameter(\n",
        "                    self._learning_rate\n",
        "                ),\n",
        "                \"beta_1\": self.beta_1,\n",
        "                \"beta_2\": self.beta_2,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "def focal_loss(gamma=2., alpha=4.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "# Define the callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor=\"accuracy\"),\n",
        "    EarlyStopping(monitor='loss', patience=2),\n",
        "    TensorBoard(log_dir='logs'),\n",
        "    ReduceLROnPlateau(monitor='loss', patience=1, factor=0.1)\n",
        "]\n",
        "\n",
        "''' train_dir = \"/content/Kather_texture_2016_image_tiles_5000/\"\n",
        "num_classes = len(os.listdir(train_dir))\n",
        "train_class_counts = {}\n",
        "for class_folder in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_folder)\n",
        "    train_class_counts[class_folder] = len(os.listdir(class_path))\n",
        "\n",
        "train_class_weights_dict = {}\n",
        "for class_folder in os.listdir(train_dir):\n",
        "    class_weight = sum(train_class_counts.values()) / (num_classes * train_class_counts[class_folder])\n",
        "    train_class_weights_dict[class_folder] = class_weight\n",
        "\n",
        "print(train_class_weights_dict)\n",
        "train_class_weights = list(train_class_weights_dict.values())\n",
        "train_class_weights = np.array(train_class_weights) / sum(train_class_weights)\n",
        "print(train_class_weights)\n",
        "\n",
        " '''\n",
        "#model = create_inception_v4(num_classes=8, input_shape=(256, 256,3), dr=0.0)\n",
        "def load_m(model_name):\n",
        "    model = load_model(model_name, custom_objects={'focal_loss_fixed': focal_loss, 'Lion': Lion,'mish': Mish(mish), 'f1_m': f1_m, 'precision_m': precision_m, 'recall_m': recall_m})\n",
        "    return model\n",
        "\n",
        "# training\n",
        "model = load_m(\"/content/kather.h5\")\n",
        "model.compile(optimizer=Lion(learning_rate=1e-5), loss=focal_loss(), metrics=[\"accuracy\", f1_m, recall_m, precision_m, tf.keras.metrics.AUC(), tf.keras.metrics.SpecificityAtSensitivity(0.5)])\n",
        "history = model.fit(train_generator, epochs=10, callbacks=callbacks)\n",
        "model.save(\"kather.h5\")\n",
        "eval = model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gchprxw-OgiH",
        "outputId": "e606c217-b403-4067-b888-52ba3d2ae821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xICZ_0XwOULh",
        "outputId": "e24522f0-4f11-4231-a94c-e13b22180e5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/kather.h5'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "shutil.copy(\"kather.h5\", \"/content/drive/MyDrive/kather.h5\")\n",
        "#shutil.move(\"best_model.h5\", \"/content/drive/MyDrive/best_kather\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "jWNZiqnWQWtX",
        "outputId": "82b00ada-2d74-425b-d023-e2936c1d45ae"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "#from tensorflow.keras.utils import array_to_image\n",
        "import csv\n",
        "# save the evaluation results to a csv file\n",
        "def save_eval_results(eval_results, filename):\n",
        "    # Open the file in write mode and write the evaluation results to it\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(model.metrics_names)\n",
        "        writer.writerow(eval_results)\n",
        "\n",
        "# plot the training history as a graph\n",
        "def plot_history(history, call=None):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=len(history.history), figsize=(20, 5))\n",
        "\n",
        "    for i, metric in enumerate(history.history.keys()):\n",
        "        axs[i].plot(history.history[metric])\n",
        "        axs[i].set_title(metric)\n",
        "        axs[i].set_xlabel('Epoch')\n",
        "        axs[i].set_ylabel(metric)\n",
        "    plt.savefig(f'{str(history)}_{call}.png')\n",
        "    plt.show()\n",
        "\n",
        "# generate predictions for a batch of test data and save the images with their predicted labels\n",
        "def quick_test(test_generator, model, img_size):\n",
        "    # Get a batch of test data\n",
        "    batch_x, batch_y = test_generator.__getitem__(0)\n",
        "    \n",
        "    # Generate predictions for the test data\n",
        "    pred_y = model.predict(batch_x)\n",
        "    \n",
        "    # Create a pred folder if it doesn't exist\n",
        "    if not os.path.exists(\"pred\"):\n",
        "        os.makedirs(\"pred\")\n",
        "    \n",
        "    # Loop through the test data and save each image and its predicted label to the pred folder\n",
        "    for i in range(batch_x.shape[0]):\n",
        "        # Convert the image array to a PIL image\n",
        "        img = array_to_img(batch_x[i])\n",
        "        \n",
        "        # Get the predicted label for the image\n",
        "        pred_label = np.argmax(pred_y[i])\n",
        "        \n",
        "        # Save the image with its predicted label as the filename\n",
        "        img.save(f\"pred/{pred_label}_{i}.jpg\")\n",
        "\n",
        "save_eval_results(eval, \"Inc_Kather\")\n",
        "plot_history(history)\n",
        "quick_test(test_generator, model, (256,256))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

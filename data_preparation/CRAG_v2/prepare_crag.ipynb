{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from boxx import *\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.cm import hsv\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "\n",
    "def generate_colormap(number_of_distinct_colors: int = 80):\n",
    "    if number_of_distinct_colors == 0:\n",
    "        number_of_distinct_colors = 80\n",
    "\n",
    "    number_of_shades = 7\n",
    "    number_of_distinct_colors_with_multiply_of_shades = int(\n",
    "        math.ceil(number_of_distinct_colors / number_of_shades) * number_of_shades\n",
    "    )\n",
    "\n",
    "    # Create an array with uniformly drawn floats taken from <0, 1) partition\n",
    "    linearly_distributed_nums = (\n",
    "        np.arange(number_of_distinct_colors_with_multiply_of_shades)\n",
    "        / number_of_distinct_colors_with_multiply_of_shades\n",
    "    )\n",
    "\n",
    "    # We are going to reorganise monotonically growing numbers in such way that there will be single array with saw-like pattern\n",
    "    #     but each saw tooth is slightly higher than the one before\n",
    "    # First divide linearly_distributed_nums into number_of_shades sub-arrays containing linearly distributed numbers\n",
    "    arr_by_shade_rows = linearly_distributed_nums.reshape(\n",
    "        number_of_shades,\n",
    "        number_of_distinct_colors_with_multiply_of_shades // number_of_shades,\n",
    "    )\n",
    "\n",
    "    # Transpose the above matrix (columns become rows) - as a result each row contains saw tooth with values slightly higher than row above\n",
    "    arr_by_shade_columns = arr_by_shade_rows.T\n",
    "\n",
    "    # Keep number of saw teeth for later\n",
    "    number_of_partitions = arr_by_shade_columns.shape[0]\n",
    "\n",
    "    # Flatten the above matrix - join each row into single array\n",
    "    nums_distributed_like_rising_saw = arr_by_shade_columns.reshape(-1)\n",
    "\n",
    "    # HSV colour map is cyclic (https://matplotlib.org/tutorials/colors/colormaps.html#cyclic), we'll use this property\n",
    "    initial_cm = hsv(nums_distributed_like_rising_saw)\n",
    "\n",
    "    lower_partitions_half = number_of_partitions // 2\n",
    "    upper_partitions_half = number_of_partitions - lower_partitions_half\n",
    "\n",
    "    # Modify lower half in such way that colours towards beginning of partition are darker\n",
    "    # First colours are affected more, colours closer to the middle are affected less\n",
    "    lower_half = lower_partitions_half * number_of_shades\n",
    "    for i in range(3):\n",
    "        initial_cm[0:lower_half, i] *= np.arange(0.2, 1, 0.8 / lower_half)\n",
    "\n",
    "    # Modify second half in such way that colours towards end of partition are less intense and brighter\n",
    "    # Colours closer to the middle are affected less, colours closer to the end are affected more\n",
    "    for i in range(3):\n",
    "        for j in range(upper_partitions_half):\n",
    "            modifier = (\n",
    "                np.ones(number_of_shades)\n",
    "                - initial_cm[\n",
    "                    lower_half\n",
    "                    + j * number_of_shades : lower_half\n",
    "                    + (j + 1) * number_of_shades,\n",
    "                    i,\n",
    "                ]\n",
    "            )\n",
    "            modifier = j * modifier / upper_partitions_half\n",
    "            initial_cm[\n",
    "                lower_half\n",
    "                + j * number_of_shades : lower_half\n",
    "                + (j + 1) * number_of_shades,\n",
    "                i,\n",
    "            ] += modifier\n",
    "\n",
    "    return ListedColormap(initial_cm)\n",
    "\n",
    "\n",
    "#!https://stackoverflow.com/questions/42697933/colormap-with-maximum-distinguishable-colours\n",
    "\n",
    "\n",
    "N = 100\n",
    "cmap = generate_colormap(N)\n",
    "colors = cmap(np.linspace(0, 1, N))\n",
    "colors = np.array(colors[:, :3]) * 255\n",
    "colors = colors.astype(np.uint8).tolist()\n",
    "colors.insert(0, [0, 0, 0])  # background is black, can be any color\n",
    "\n",
    "# augmentations for the object detection task\n",
    "# these are very light augmentations, because the models used for object detection seem to be very sensitive to changes\n",
    "seq_json = iaa.Sequential(\n",
    "    [\n",
    "        iaa.CoarseDropout(0.001, size_percent=0.002),\n",
    "        iaa.Crop(percent=(0, 0.002)),\n",
    "        iaa.Sharpen((0, 0.5)),\n",
    "        iaa.Sometimes(\n",
    "            0.3,\n",
    "            iaa.GaussianBlur(sigma=(0, 0.05)),\n",
    "            iaa.AdditiveGaussianNoise(scale=(0, 2)),\n",
    "        ),\n",
    "        iaa.Affine(rotate=(-180, 180), shear=(-20, 20)),\n",
    "        iaa.Sometimes(\n",
    "            0.15,\n",
    "            iaa.WithHueAndSaturation(iaa.WithChannels(0, iaa.Add((-7, 7)))),\n",
    "            iaa.AddToBrightness((-10, 10)),\n",
    "        ),\n",
    "        #    iaa.Sometimes(\n",
    "        #                0.05,\n",
    "        #                iaa.ChangeColorTemperature((1000, 25000)),)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# augmentations for the segmentation task\n",
    "seq_bin = iaa.Sequential(\n",
    "    [\n",
    "        iaa.CoarseDropout(0.001, size_percent=0.002),\n",
    "        iaa.Crop(percent=(0, 0.002)),\n",
    "        iaa.Sharpen((0, 0.5)),\n",
    "        iaa.Sometimes(\n",
    "            0.3,\n",
    "            iaa.GaussianBlur(sigma=(0, 3)),\n",
    "            iaa.AdditiveGaussianNoise(scale=(0, 10)),\n",
    "        ),\n",
    "        iaa.Sometimes(\n",
    "            0.2,\n",
    "            iaa.SomeOf((0, 2), [iaa.LinearContrast((0.5, 1.2)), iaa.Add((-10, 10))]),\n",
    "        ),\n",
    "        iaa.Affine(rotate=(-180, 180), shear=(-20, 20)),\n",
    "        iaa.Sometimes(\n",
    "            0.15,\n",
    "            iaa.WithHueAndSaturation(iaa.WithChannels(0, iaa.Add((-20, 20)))),\n",
    "            iaa.AddToBrightness((-20, 20)),\n",
    "        ),\n",
    "        iaa.Sometimes(\n",
    "            0.05,\n",
    "            iaa.ChangeColorTemperature((1000, 25000)),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# augmentation pipeline\n",
    "def augment_crag(\n",
    "    image_folder: str,\n",
    "    annotation_folder: str,\n",
    "    number_of_augmentations: int = 20,\n",
    "    resize: bool = False,\n",
    "    resize_shape: tuple = (256, 256),\n",
    "    transforms=None,\n",
    "    mode: str = \"test\",\n",
    "):\n",
    "    \"\"\"\n",
    "    image_folder: folder with images\n",
    "    annotation_folder: folder with annotations\n",
    "    number_of_augmentations: number of augmentations per image\n",
    "    resize: resize images and annotations to resize_shape\n",
    "    resize_shape: shape to resize to (makes the process faster)\n",
    "    transforms: imgaug transforms\n",
    "    mode: test or train (test does not augment)\n",
    "    \"\"\"\n",
    "    ia.seed(1)\n",
    "    assert mode in [\"train\", \"test\"]\n",
    "    if mode == \"test\":\n",
    "        for base_name in tqdm(os.listdir(image_folder)):\n",
    "            if base_name.endswith(\".png\"):\n",
    "                image_name = os.path.join(image_folder, base_name)\n",
    "                annotation_name = os.path.join(annotation_folder, base_name)\n",
    "                image = imageio.imread(image_name)\n",
    "                annotation = imageio.imread(annotation_name)\n",
    "                if resize:\n",
    "                    image = cv2.resize(\n",
    "                        image, resize_shape, interpolation=cv2.INTER_NEAREST\n",
    "                    )\n",
    "                    annotation = cv2.resize(\n",
    "                        annotation, resize_shape, interpolation=cv2.INTER_NEAREST\n",
    "                    )\n",
    "                annotation = SegmentationMapsOnImage(annotation, shape=annotation.shape)\n",
    "                imageio.imwrite(image_name, image)\n",
    "                imageio.imwrite(annotation_name, annotation.draw(colors=colors)[0])\n",
    "        return\n",
    "    else:\n",
    "        assert transforms is not None\n",
    "        for base_name in tqdm(os.listdir(image_folder)):\n",
    "            if base_name.endswith(\".png\"):\n",
    "                image_name = os.path.join(image_folder, base_name)\n",
    "                annotation_name = os.path.join(annotation_folder, base_name)\n",
    "                image = imageio.imread(image_name)\n",
    "                annotation = imageio.imread(annotation_name)\n",
    "                if resize:\n",
    "                    image = cv2.resize(\n",
    "                        image, resize_shape, interpolation=cv2.INTER_NEAREST\n",
    "                    )  # without interpolation change, the annotations get messed up\n",
    "                    annotation = cv2.resize(\n",
    "                        annotation, resize_shape, interpolation=cv2.INTER_NEAREST\n",
    "                    )\n",
    "                    imageio.imwrite(image_name, image)\n",
    "                annotation = SegmentationMapsOnImage(annotation, shape=annotation.shape)\n",
    "                for kind in range(number_of_augmentations):\n",
    "                    new_base_name = base_name[:-4] + \"_aug_\" + str(kind) + \".png\"\n",
    "                    new_image_name = os.path.join(image_folder, new_base_name)\n",
    "                    new_annotation_name = os.path.join(annotation_folder, new_base_name)\n",
    "                    image_aug, annotation_aug = transforms(\n",
    "                        image=image, segmentation_maps=annotation\n",
    "                    )\n",
    "                    imageio.imwrite(new_image_name, image_aug)\n",
    "                    imageio.imwrite(\n",
    "                        new_annotation_name, annotation_aug.draw(colors=colors)[0]\n",
    "                    )\n",
    "                # also put color on base annotation\n",
    "                imageio.imwrite(annotation_name, annotation.draw(colors=colors)[0])\n",
    "\n",
    "\n",
    "augment_crag(\n",
    "    \"/path/to/Images\",\n",
    "    \"/path/to/Annotations\",\n",
    "    13,\n",
    "    resize=True,\n",
    "    resize_shape=(256, 256),\n",
    "    mode=\"test\",\n",
    "    transforms=seq_bin,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# https://github.com/XiaoyuZHK/CRAG-Dataset_Aug_ToCOCO\n",
    "# @XiaoyuZHK https://github.com/XiaoyuZHK\n",
    "\n",
    "# extract masks from the labels\n",
    "def rgb2masks(label_name, local, bg_color=(0, 0, 0)):\n",
    "    lbl_id = os.path.splitext(os.path.basename(label_name))[0]\n",
    "    lbl = cv2.imread(label_name, cv2.IMREAD_COLOR)\n",
    "    h, w = lbl.shape[:2]\n",
    "    cell_dict = {}\n",
    "    idx = 0\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            color = tuple(lbl[i][j])\n",
    "            if color in cell_dict or color == bg_color:\n",
    "                continue\n",
    "            cell_dict[color] = idx\n",
    "            mask = (lbl == color).all(-1)\n",
    "            mask_name = os.path.join(local, f\"{lbl_id}_cell_{idx}.png\")\n",
    "            cv2.imwrite(\n",
    "                mask_name, mask.astype(np.uint8) * 255\n",
    "            )  # Save the mask directly without using white_mask\n",
    "            idx += 1\n",
    "\n",
    "\n",
    "label_dir = \"/path/to/Annotations\"\n",
    "label_list = glob.glob(os.path.join(label_dir, \"*.png\"))\n",
    "\n",
    "local = \"/path/to/save_folder\"\n",
    "os.makedirs(local, exist_ok=True)\n",
    "\n",
    "trainsum = 0\n",
    "for label_name in tqdm(label_list):\n",
    "    rgb2masks(label_name, local, bg_color=(0, 0, 0))\n",
    "    trainsum += 1\n",
    "\n",
    "print(trainsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import pycococreatortools\n",
    "import pycocotools\n",
    "from PIL.Image import Image\n",
    "from boxx import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "INFO = {\n",
    "    \"description\": \"Example Dataset\",\n",
    "    \"url\": \"https://github.com/waspinator/pycococreator\",\n",
    "    \"version\": \"0.1.0\",\n",
    "    \"year\": 2018,\n",
    "    \"contributor\": \"waspinator\",\n",
    "    \"date_created\": datetime.datetime.utcnow().isoformat(\" \"),\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "        \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\",\n",
    "    }\n",
    "]\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"cell\",\n",
    "        \"supercategory\": \"cell\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def filter_for_jpeg(root, files):\n",
    "    file_types = [\"*.jpeg\", \"*.jpg\", \"*.png\"]\n",
    "    file_types = r\"|\".join([fnmatch.translate(x) for x in file_types])\n",
    "    files = [os.path.join(root, f) for f in files]\n",
    "    files = [f for f in files if re.match(file_types, f)]\n",
    "    return files\n",
    "\n",
    "\n",
    "def filter_for_annotations(root, files, image_filename):\n",
    "    file_types = [\"*.png\"]\n",
    "    file_types = r\"|\".join([fnmatch.translate(x) for x in file_types])\n",
    "    basename_no_extension = os.path.splitext(os.path.basename(image_filename))[0]\n",
    "    file_name_prefix = basename_no_extension + \".*\"\n",
    "    files = [os.path.join(root, f) for f in files]\n",
    "    files = [f for f in files if re.match(file_types, f)]\n",
    "    files = [\n",
    "        f\n",
    "        for f in files\n",
    "        if re.match(file_name_prefix, os.path.splitext(os.path.basename(f))[0])\n",
    "    ]\n",
    "    return files\n",
    "\n",
    "\n",
    "def translate(ROOT_DIR, IMAGE_DIR, ANNOTATION_DIR):\n",
    "    coco_output = {\n",
    "        \"info\": INFO,\n",
    "        \"licenses\": LICENSES,\n",
    "        \"categories\": CATEGORIES,\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "    }\n",
    "    i = 0\n",
    "    image_id = 1\n",
    "    segmentation_id = 1\n",
    "\n",
    "    # filter for jpeg images\n",
    "    for root, _, files in tqdm(os.walk(IMAGE_DIR)):\n",
    "        # 所有图片\n",
    "        image_files = filter_for_jpeg(root, files)\n",
    "        # tree-image_files\n",
    "        finish = []\n",
    "        # go through each image\n",
    "        for image_filename in image_files:\n",
    "            image = Image.open(image_filename)\n",
    "            i += 1\n",
    "            #             image_filename_json = image_filename.split('cell')\n",
    "\n",
    "            #             image_filename_json = image_filename_json[0][:-1]+'.png'\n",
    "            #             print(image_filename_json)\n",
    "            # 创建image_info,这个其实就是每张图放进去而不是每个实例\n",
    "            #             if image_filename_json not in finish:\n",
    "            image_info = pycococreatortools.create_image_info(\n",
    "                image_id, os.path.basename(image_filename), image.size\n",
    "            )\n",
    "            coco_output[\"images\"].append(image_info)\n",
    "            #             finish.append(image_filename_json)\n",
    "\n",
    "            # filter for associated png annotations\n",
    "            for root, _, files in os.walk(ANNOTATION_DIR):\n",
    "                annotation_files = filter_for_annotations(root, files, image_filename)\n",
    "\n",
    "                # go through each associated annotation\n",
    "                for annotation_filename in annotation_files:\n",
    "                    annotation_filename_json = annotation_filename.split(\"cell\")\n",
    "\n",
    "                    annotation_filename_json = annotation_filename_json[0][:-1] + \".png\"\n",
    "\n",
    "                    print(\n",
    "                        \"image_filename:\",\n",
    "                        image_filename,\n",
    "                        \"\\nannotation_filename:\",\n",
    "                        annotation_filename,\n",
    "                        \"\\n\",\n",
    "                        \"annotation_filename_json:\",\n",
    "                        annotation_filename_json,\n",
    "                        \"\\n\",\n",
    "                    )\n",
    "\n",
    "                    image_filename_compare = image_filename.split(\"/\")[-1]\n",
    "                    annotation_filename_json_compare = annotation_filename_json.split(\n",
    "                        \"/\"\n",
    "                    )[-1]\n",
    "\n",
    "                    if annotation_filename_json_compare == image_filename_compare:\n",
    "                        print(\"!!!!!\")\n",
    "                        class_id = [\n",
    "                            x[\"id\"]\n",
    "                            for x in CATEGORIES\n",
    "                            if x[\"name\"] in annotation_filename\n",
    "                        ][0]\n",
    "\n",
    "                        tree - class_id\n",
    "\n",
    "                        category_info = {\n",
    "                            \"id\": class_id,\n",
    "                            \"is_crowd\": \"crowd\" in image_filename,\n",
    "                        }\n",
    "                        binary_mask = np.asarray(\n",
    "                            Image.open(annotation_filename).convert(\"1\")\n",
    "                        ).astype(np.uint8)\n",
    "\n",
    "                        annotation_info = pycococreatortools.create_annotation_info(\n",
    "                            segmentation_id,\n",
    "                            image_id,\n",
    "                            category_info,\n",
    "                            binary_mask,\n",
    "                            image.size,\n",
    "                            tolerance=2,\n",
    "                        )\n",
    "\n",
    "                        if annotation_info is not None:\n",
    "                            coco_output[\"annotations\"].append(annotation_info)\n",
    "\n",
    "                        segmentation_id = segmentation_id + 1\n",
    "            image_id = image_id + 1\n",
    "\n",
    "    with open(\"{}/instances_test.json\".format(ANNOTATION_DIR), \"w\") as output_json_file:\n",
    "        json.dump(coco_output, output_json_file)\n",
    "    print(i)\n",
    "\n",
    "\n",
    "# create a .json file in coco format out of the annotations\n",
    "def main():\n",
    "    ROOT_DIR = \"/path/to/main_folder\"\n",
    "    IMAGE_DIR = os.path.join(ROOT_DIR, \"Images\")\n",
    "    ANNOTATION_DIR = os.path.join(ROOT_DIR, \"Annotations_\")\n",
    "\n",
    "    translate(ROOT_DIR, IMAGE_DIR, ANNOTATION_DIR)\n",
    "\n",
    "    translate(ROOT_DIR, IMAGE_DIR, ANNOTATION_DIR)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# check data integrity by displaying images with annotations\n",
    "def check_coco(\n",
    "    instance_folder: str,\n",
    "    image_folder: str,\n",
    "    dataset: dict,\n",
    "    annotations_style: str = \"coco\",\n",
    "    amount: int = 10,\n",
    "    show_agumetned_only: bool = False,\n",
    "):\n",
    "    assert annotations_style in [\"coco\", \"circle\"]\n",
    "    check = 0\n",
    "    print(\"Amount of images: \", len(dataset[\"images\"]))\n",
    "    if annotations_style == \"coco\":\n",
    "        for image_info in dataset[\"images\"]:\n",
    "            if show_agumetned_only:\n",
    "                if len(image_info[\"file_name\"].split(\"_\")) < 3:\n",
    "                    continue\n",
    "\n",
    "            print(image_info[\"file_name\"])\n",
    "            image = cv2.imread(os.path.join(image_folder, image_info[\"file_name\"]))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            annotations = [\n",
    "                ann\n",
    "                for ann in dataset[\"annotations\"]\n",
    "                if ann[\"image_id\"] == image_info[\"id\"]\n",
    "            ]\n",
    "\n",
    "            for ann in annotations:\n",
    "                bbox = ann[\"bbox\"]\n",
    "                x, y, w, h = int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3])\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "            for instance in os.listdir(instance_folder):\n",
    "                if instance.split(\".\")[0] == image_info[\"file_name\"].split(\".\")[0]:\n",
    "                    instance = cv2.imread(os.path.join(instance_folder, instance))\n",
    "                    instance = cv2.cvtColor(instance, cv2.COLOR_BGR2RGB)\n",
    "                    # brighten the instance to better evaluate the results\n",
    "                    instance = instance * 255\n",
    "                    plt.imshow(instance)\n",
    "                    plt.show()\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            check += 1\n",
    "            if check == amount:\n",
    "                break\n",
    "    else:\n",
    "        for image_info in dataset[\"images\"]:\n",
    "            print(image_info[\"file_name\"])\n",
    "            image = cv2.imread(os.path.join(image_folder, image_info[\"file_name\"]))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            annotations = [\n",
    "                ann\n",
    "                for ann in dataset[\"annotations\"]\n",
    "                if ann[\"image_id\"] == image_info[\"id\"]\n",
    "            ]\n",
    "\n",
    "            for ann in annotations:\n",
    "                x, y, r = (\n",
    "                    ann[\"circle_center\"][0],\n",
    "                    ann[\"circle_center\"][1],\n",
    "                    ann[\"circle_radius\"],\n",
    "                )\n",
    "                cv2.circle(image, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "\n",
    "            for instance in os.listdir(instance_folder):\n",
    "                if instance.split(\".\")[0] == image_info[\"file_name\"].split(\".\")[0]:\n",
    "                    instance = cv2.imread(os.path.join(instance_folder, instance))\n",
    "                    instance = cv2.cvtColor(instance, cv2.COLOR_BGR2RGB)\n",
    "                    # brighten the instance to better evaluate the results\n",
    "                    instance = instance * 255\n",
    "                    plt.imshow(instance)\n",
    "                    plt.show()\n",
    "\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "            check += 1\n",
    "            if check == amount:\n",
    "                break\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_folder = \"/home/lorenz/JF/new_data/CRAG_v2/CRAG/test/Images\"\n",
    "    instance_folder = \"/home/lorenz/JF/new_data/CRAG_v2/CRAG/test/Annotation\"\n",
    "    with open(\n",
    "        \"/home/lorenz/JF/new_data/CRAG_v2/CRAG/test/JSON/instances_test.json\", \"r\"\n",
    "    ) as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    check_coco(\n",
    "        instance_folder,\n",
    "        image_folder,\n",
    "        dataset,\n",
    "        annotations_style=\"coco\",\n",
    "        amount=10,\n",
    "        show_agumetned_only=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
